<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LangChain MasterClass-Build 12 OpenAI LLM Apps using Python, HTML,CSS,React,Vue,Java,Go,微服务,linux">
    <meta name="description" content="1. LangChain Introduction
2. OpenAI Introduction3. Demo &amp;amp; Environment Setup1. A LangChain Example - Implementation D">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>LangChain MasterClass-Build 12 OpenAI LLM Apps using Python | malred-blog</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/css/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    <style type="text/css">
        
    </style>
    <script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script>
    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>

<header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="container">
            <div class="nav-wrapper">
                <div class="brand-logo">
                    <a href="/" class="waves-effect waves-light">
                        
                        <img src="/medias/logo.png" class="logo-img hide-on-small-only">
                        
                        <span class="logo-span">malred-blog</span>
                    </a>
                </div>
                

<a href="#" data-activates="mobile-nav" class="button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <i class="fa fa-home"></i>
            
            <span>首页</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <i class="fa fa-tags"></i>
            
            <span>标签</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <i class="fa fa-bookmark"></i>
            
            <span>分类</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <i class="fa fa-archive"></i>
            
            <span>归档</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <i class="fa fa-user-circle-o"></i>
            
            <span>关于</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/friends" class="waves-effect waves-light">
            
            <i class="fa fa-address-book"></i>
            
            <span>友情链接</span>
        </a>
    </li>
    
    <li>
        <a id="toggleSearch" class="waves-effect waves-light">
            <i id="searchIcon" class="mdi-action-search" title="搜索"></i>
        </a>
    </li>

</ul>

<div class="side-nav" id="mobile-nav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">malred-blog</div>
        <div class="logo-desc">
            
            前后端学习者,存放知识笔记
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-home"></i>
                
                首页
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-tags"></i>
                
                标签
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-bookmark"></i>
                
                分类
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-archive"></i>
                
                归档
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-user-circle-o"></i>
                
                关于
            </a>
        </li>
        
        <li>
            <a href="/friends" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-address-book"></i>
                
                友情链接
            </a>
        </li>
        
        
    </ul>

    <div class="social-link">
    <a href="https://github.com/malred" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fa fa-github"></i>
    </a>



    <a href="mailto:malguy2022@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fa fa-envelope-open"></i>
    </a>



    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2725953379" class="tooltipped" data-tooltip="QQ联系我: 2725953379" data-position="top" data-delay="50">
        <i class="fa fa-qq"></i>
    </a>


</div>
</div>

            </div>
        </div>

        
    </nav>
</header>


<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover post-cover" style="background-image: url('/medias/featureimages/18.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        LangChain MasterClass-Build 12 OpenAI LLM Apps using Python
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }
</style>
<div class="row">
    <div class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/ai/" target="_blank">
                                <span class="chip bg-color">ai</span>
                            </a>
                        
                            <a href="/tags/langChain/" target="_blank">
                                <span class="chip bg-color">langChain</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/ai/" class="post-category" target="_blank">
                                ai
                            </a>
                        
                            <a href="/categories/ai/langChain/" class="post-category" target="_blank">
                                langChain
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-01-25
                </div>

                
                    
                    <div class="info-break-policy">
                        <i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp;
                        17.9k
                    </div>
                    

                    
                    <div class="info-break-policy">
                        <i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp;
                        107 分
                    </div>
                    
                
				
				
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="1-LangChain-Introduction"><a href="#1-LangChain-Introduction" class="headerlink" title="1. LangChain Introduction"></a>1. LangChain Introduction</h1><p><img src="5eb3ee52.png"><img src="e03fe565.png"><img src="81f809b3.png"><img src="c72a14bc.png"><img src="5347b7ac.png"><br><img src="2295b6aa.png"><img src="3ce666b9.png"><img src="f2023e49.png"></p>
<h1 id="2-OpenAI-Introduction"><a href="#2-OpenAI-Introduction" class="headerlink" title="2. OpenAI Introduction"></a>2. OpenAI Introduction</h1><h1 id="3-Demo-amp-Environment-Setup"><a href="#3-Demo-amp-Environment-Setup" class="headerlink" title="3. Demo &amp; Environment Setup"></a>3. Demo &amp; Environment Setup</h1><h2 id="1-A-LangChain-Example-Implementation-Demo"><a href="#1-A-LangChain-Example-Implementation-Demo" class="headerlink" title="1. A LangChain Example - Implementation Demo"></a>1. A LangChain Example - Implementation Demo</h2><p><img src="1b23a291.png"></p>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><p><img src="d77da774.png" alt="2023.3好像是py10"></p>
<h1 id="4-Langchain-Models-Module-Concept"><a href="#4-Langchain-Models-Module-Concept" class="headerlink" title="4. Langchain - Models Module Concept"></a>4. Langchain - Models Module Concept</h1><h2 id="1-LangChain’s-Modules-Overview"><a href="#1-LangChain’s-Modules-Overview" class="headerlink" title="1. LangChain’s Modules Overview"></a>1. LangChain’s Modules Overview</h2><p><img src="80900c53.png"><img src="297dc01f.png"></p>
<h1 id="5-✅Beginner-level"><a href="#5-✅Beginner-level" class="headerlink" title="5. ✅Beginner level"></a>5. ✅Beginner level</h1><h1 id="6-Project-1-Simple-Question-amp-Answer-App"><a href="#6-Project-1-Simple-Question-amp-Answer-App" class="headerlink" title="6. Project #1 - Simple Question &amp; Answer App"></a>6. Project #1 - Simple Question &amp; Answer App</h1><h2 id="1-LLMs-Walkthrough"><a href="#1-LLMs-Walkthrough" class="headerlink" title="1. LLMs Walkthrough"></a>1. LLMs Walkthrough</h2><p><img src="b0bfba16.png"><img src="38be212e.png"><img src="29f060da.png"><img src="69c33a24.png" alt="huggingface上有免费的模型"></p>
<h2 id="2-LLM-Practical-Implementation-using-Python"><a href="#2-LLM-Practical-Implementation-using-Python" class="headerlink" title="2. LLM Practical Implementation using Python"></a>2. LLM Practical Implementation using Python</h2><pre class=" language-shell"><code class="language-shell">pip install openai
pip install Openai
conda install langchain -c conda-forge 
pip install langchain[all]
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#!/usr/bin/env python</span>
<span class="token comment" spellcheck="true"># coding: utf-8</span>

<span class="token comment" spellcheck="true"># Pip install is the command you use to install Python packages with the help of a tool called Pip package manager.</span>
<span class="token comment" spellcheck="true"># Installing LangChain package</span>

<span class="token comment" spellcheck="true"># In[20]:</span>


<span class="token comment" spellcheck="true"># get_ipython().system('pip install langChain')</span>


<span class="token comment" spellcheck="true"># # Let's use Proprietary LLM from-OpenAl</span>
<span class="token comment" spellcheck="true">#</span>
<span class="token comment" spellcheck="true"># Installing Openai package,which includes the classes that we can use to communicate with Openai services</span>

<span class="token comment" spellcheck="true"># In[21]:</span>


<span class="token comment" spellcheck="true"># get_ipython().system('pip install Openai')</span>


<span class="token comment" spellcheck="true"># Imports the Python built-in module called "os."</span>
<span class="token comment" spellcheck="true"># This module provides a way to interact with the operating system,such as accessing environment variables,working with files and directories,executing shell</span>
<span class="token comment" spellcheck="true"># commands,etc</span>
<span class="token comment" spellcheck="true"># The environ attribute is a dictionary-like object that contains the environment variables of the current operating system session</span>
<span class="token comment" spellcheck="true"># By accessing os.environ,you can retrieve and manipulate environment variables within your Python program.For example,you can retrieve the value of a</span>
<span class="token comment" spellcheck="true"># specific environment variable using the syntax os.environ["VARIABLE_NAME],where "VARIABLE_NAME"is the name of the environment variable you want to</span>
<span class="token comment" spellcheck="true"># access.</span>

<span class="token comment" spellcheck="true"># In[22]:</span>


<span class="token keyword">import</span> os

<span class="token keyword">import</span> httpx

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'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'</span>
<span class="token comment" spellcheck="true"># os.environ["OPENAI_API_BASE"] = 'https://oneapi.xty.app/v1'</span>

<span class="token comment" spellcheck="true"># LangChain has built a Wrapper around OpenAl APIs,using which we can get access to all the services OpenAl provides.</span>
<span class="token comment" spellcheck="true"># The code snippet below imports a specific class called 'OpenAl'(Wrapper around OpenAl large language models)from the 'llms'module of the 'langchain'</span>
<span class="token comment" spellcheck="true"># library.</span>
<span class="token comment" spellcheck="true"># https://python.langchain.com/en/latest/modules/langchain/llms/openai.html</span>

<span class="token comment" spellcheck="true"># In[23]:</span>


<span class="token comment" spellcheck="true"># from langchain.llms import OpenAI</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI

<span class="token comment" spellcheck="true"># Here we are instantiating a language model object called OpenAl,for our natural language processing tasks.</span>
<span class="token comment" spellcheck="true"># The parameter model_name is provided with the value "text-davinci-003"which is a specific version or variant of a language model (examples-text-davinci-</span>
<span class="token comment" spellcheck="true"># 003,code-davinci-002,gpt-3.5-turbo,text-ada-001 and more).</span>

<span class="token comment" spellcheck="true"># In[24]:</span>


llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>
    temperature<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span>
    base_url<span class="token operator">=</span><span class="token string">"https://oneapi.xty.app/v1"</span><span class="token punctuation">,</span>
    api_key<span class="token operator">=</span><span class="token string">"sk-Qg2sQRe2BTRDkjXCAaCa243017994a8aBf2e5bC26aE8Af99"</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># model_name="text-davinci-003", # model 不存在</span>
    model_name<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo-instruct"</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># OK </span>
    http_client<span class="token operator">=</span>httpx<span class="token punctuation">.</span>Client<span class="token punctuation">(</span>
        base_url<span class="token operator">=</span><span class="token string">"https://oneapi.xty.app/v1"</span><span class="token punctuation">,</span>
        follow_redirects<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Here language model is represented by the object "llm,"which is being utilized to generate a completion or response based on a specific query.</span>
<span class="token comment" spellcheck="true"># The query,stored in the "our_query"variable is bieng passed to the model through llm object.</span>
 
our_query <span class="token operator">=</span> <span class="token string">"What is the currency of India?"</span>
completion <span class="token operator">=</span> llm<span class="token punctuation">(</span>our_query<span class="token punctuation">)</span> 

<span class="token keyword">print</span><span class="token punctuation">(</span>completion<span class="token punctuation">)</span> 
</code></pre>
<p><img src="5ac3a0a9.png"></p>
<pre class=" language-shell"><code class="language-shell">pip install huggingface_hub
</code></pre>
<p><img src="08d76942.png" alt="settings"><img src="7ca73ab4.png" alt="生成令牌"></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># https://huggingface.co/docs/transformers/model_doc/flan-t5</span>
<span class="token comment" spellcheck="true"># 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</span>
<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HUGGINGFACEHUB_API_TOKEN'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'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'</span>
<span class="token comment" spellcheck="true"># from langchain.llms import HuggingFaceHub</span>
<span class="token comment" spellcheck="true"># from langchain_community.llms import HuggingFaceHub</span>

<span class="token comment" spellcheck="true"># F:\anaconda\envs\py39f\lib\site-packages\huggingface_hub\utils\_deprecation.py:131:</span>
<span class="token comment" spellcheck="true"># FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated</span>
<span class="token comment" spellcheck="true"># and will be removed from version '1.0'.</span>
<span class="token comment" spellcheck="true"># `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`.</span>
<span class="token comment" spellcheck="true"># Check out this guide to learn how to convert your script to use it:</span>
<span class="token comment" spellcheck="true"># https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.</span>
<span class="token comment" spellcheck="true"># llm = HuggingFaceHub(repo_id="google/flan-t5-large")</span>
<span class="token comment" spellcheck="true"># model = "google/flan-t5-large"</span>
<span class="token comment" spellcheck="true"># llm = HuggingFaceHub(model=model)</span>

<span class="token comment" spellcheck="true"># The LLM takes a prompt as an input and outputs a completion</span>
<span class="token comment" spellcheck="true"># our_query = 'What is the currency of India?'</span>
<span class="token comment" spellcheck="true"># completion = llm(our_query)</span>
<span class="token comment" spellcheck="true"># print(completion)</span>

<span class="token keyword">from</span> langchain <span class="token keyword">import</span> PromptTemplate<span class="token punctuation">,</span> HuggingFaceHub<span class="token punctuation">,</span> LLMChain

template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""Question: {question}

Answer: Let's think step by step."""</span>

prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>template<span class="token operator">=</span>template<span class="token punctuation">,</span> input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
llm_chain <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>
    prompt<span class="token operator">=</span>prompt<span class="token punctuation">,</span>
    llm<span class="token operator">=</span>HuggingFaceHub<span class="token punctuation">(</span>
        repo_id<span class="token operator">=</span><span class="token string">"google/flan-t5-large"</span><span class="token punctuation">,</span>
        model_kwargs<span class="token operator">=</span><span class="token punctuation">{</span>
            <span class="token string">"temperature"</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
            <span class="token string">"max_length"</span><span class="token punctuation">:</span> <span class="token number">64</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">)</span>
<span class="token punctuation">)</span>

question <span class="token operator">=</span> <span class="token string">"What is the capital of France?"</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>llm_chain<span class="token punctuation">.</span>run<span class="token punctuation">(</span>question<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="3-Project-Environment-Setup"><a href="#3-Project-Environment-Setup" class="headerlink" title="3. Project Environment Setup"></a>3. Project Environment Setup</h2><p><img src="f87a5d2a.png"><img src="8527ac7d.png"><img src="58e0816d.png"><img src="36741c8f.png"><img src="78f1ac06.png"><br><img src="d5ea45ac.png"><img src="d46e0f00.png"><img src="67301ff4.png"><img src="25f00878.png" alt="requirements.txt"></p>
<pre class=" language-txt"><code class="language-txt">langchain
Openai
Streamlit
</code></pre>
<p><img src="9b0c811e.png"><img src="5d400313.png"><img src="59897c5d.png"></p>
<h2 id="4-Lets’-Build-Simple-Question-Answering-Application"><a href="#4-Lets’-Build-Simple-Question-Answering-Application" class="headerlink" title="4. Lets’ Build Simple Question Answering Application"></a>4. Lets’ Build Simple Question Answering Application</h2><p><img src="31f92aab.png" alt="upload"><img src="9da1af5f.png" alt="上次app.py会覆盖原本的空文件"></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#Hello! It seems like you want to import the Streamlit library in Python. Streamlit is a powerful open-source framework used for building web applications with interactive data visualizations and machine learning models. To import Streamlit, you'll need to ensure that you have it installed in your Python environment.</span>
<span class="token comment" spellcheck="true">#Once you have Streamlit installed, you can import it into your Python script using the import statement,</span>

<span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st


<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI

<span class="token comment" spellcheck="true">#Function to return the response</span>
<span class="token keyword">def</span> <span class="token function">load_answer</span><span class="token punctuation">(</span>question<span class="token punctuation">)</span><span class="token punctuation">:</span>
    llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>model_name<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo-instruct"</span><span class="token punctuation">,</span>temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    answer<span class="token operator">=</span>llm<span class="token punctuation">(</span>question<span class="token punctuation">)</span>
    <span class="token keyword">return</span> answer


<span class="token comment" spellcheck="true">#App UI starts here</span>
st<span class="token punctuation">.</span>set_page_config<span class="token punctuation">(</span>page_title<span class="token operator">=</span><span class="token string">"LangChain Demo"</span><span class="token punctuation">,</span> page_icon<span class="token operator">=</span><span class="token string">":robot:"</span><span class="token punctuation">)</span>
st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">"LangChain Demo"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#Gets the user input</span>
<span class="token keyword">def</span> <span class="token function">get_text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    input_text <span class="token operator">=</span> st<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">"You: "</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token string">"input"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> input_text


user_input<span class="token operator">=</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span>
response <span class="token operator">=</span> load_answer<span class="token punctuation">(</span>user_input<span class="token punctuation">)</span>

submit <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">'Generate'</span><span class="token punctuation">)</span>  

<span class="token comment" spellcheck="true">#If generate button is clicked</span>
<span class="token keyword">if</span> submit<span class="token punctuation">:</span>

    st<span class="token punctuation">.</span>subheader<span class="token punctuation">(</span><span class="token string">"Answer:"</span><span class="token punctuation">)</span>

    st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>response<span class="token punctuation">)</span>
</code></pre>
<p><img src="42ec266a.png"><img src="9e914444.png" alt="settings"><img src="26e6c94b.png"></p>
<h1 id="7-Project-2-Simple-Conversational-App"><a href="#7-Project-2-Simple-Conversational-App" class="headerlink" title="7. Project #2 - Simple Conversational App"></a>7. Project #2 - Simple Conversational App</h1><h2 id="1-Chat-Model-Walkthrough"><a href="#1-Chat-Model-Walkthrough" class="headerlink" title="1. Chat Model Walkthrough"></a>1. Chat Model Walkthrough</h2><p><img src="3bbb620e.png"></p>
<h2 id="2-Chat-Model-Practical-Implementation-using-Python"><a href="#2-Chat-Model-Practical-Implementation-using-Python" class="headerlink" title="2. Chat Model Practical Implementation using Python"></a>2. Chat Model Practical Implementation using Python</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %% env</span>
<span class="token keyword">import</span> os

<span class="token comment" spellcheck="true"># os.environ["OPENAI_API_KEY"] = 'sk-Qg2sQRe2BTRDkjXCAaCa243017994a8aBf2e5bC26aE8Af99'</span>
<span class="token comment" spellcheck="true"># os.environ["OPENAI_API_BASE"] = 'https://oneapi.xty.app/v/1'</span>

<span class="token comment" spellcheck="true"># %% import model</span>
<span class="token triple-quoted-string string">'''
LangChain has built a Wrapper around OpenAl APls,using which we can get access to all the services OpenAl provides.
The code snippet below imports a specific class called 'ChatOpenAl'(Wrapper around OpenAl large language models)from the 'chat_models'module of the
langchain'library.
'''</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>chat_models <span class="token keyword">import</span> ChatOpenAI

<span class="token comment" spellcheck="true"># %%</span>
<span class="token triple-quoted-string string">'''
The code snippet below imports HumanMessage,SystemMessage and
 AlMessage from the 'schema'module of the langchain'library.
'''</span>

<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>schema <span class="token keyword">import</span> HumanMessage<span class="token punctuation">,</span> SystemMessage<span class="token punctuation">,</span> AIMessage

<span class="token comment" spellcheck="true"># %% create model</span>
<span class="token triple-quoted-string string">'''
Initialize the ChatOpenAl object and
We'll set temperature=.7 to maximise randomness and make outputs creative.  temperature添加随机性
The parameter model_name is provided with the value "gpt-3.5-turbo"which is a specific version or variant of a language model for chat
'''</span>

chat <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>
    temperature<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">,</span>
    base_url<span class="token operator">=</span><span class="token string">"https://oneapi.xty.app/v1"</span><span class="token punctuation">,</span>
    api_key<span class="token operator">=</span><span class="token string">"sk-Qg2sQRe2BTRDkjXCAaCa243017994a8aBf2e5bC26aE8Af99"</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># 报错307 就换一个模型试试</span>
    model_name<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># OK</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% chat with</span>
<span class="token triple-quoted-string string">'''
Chats with the Chat-GPT model 'gpt-3.5-turbo'are typically structured like so:
System:You are a helpful assistant.
User:Hi Al,how are you today?
Assistant:I'm great thank you.How can I help you?
User:I'd like to understand string theory.
Assistant:The final "Assistant:"without a response is what would prompt the model to continue the comversation.In the official
'''</span>

result <span class="token operator">=</span> chat<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>
        <span class="token comment" spellcheck="true"># 设定</span>
        SystemMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"You are a sarcastic AI assistant"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token comment" spellcheck="true"># 用户提问</span>
        HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"Please answer in 30 words:How can I learn driving a car"</span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>content<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># %% more detail chat</span>
<span class="token triple-quoted-string string">'''
In the below scenario
We are asking the model to behave in a specific way
And passing our question
And also passing on more context so that it can elaborate more on that specific topic
This model gives us a better way to have conversation kind of opportunity with the model,which can be used to build chat bots.
'''</span>

ourConversation <span class="token operator">=</span> chat<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>
        SystemMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"You are a 3 years old girl who answers very cutely and in a funny way"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"How can I learn driving a car"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        AIMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"I can't drive yet! But I have a driver,my dad..."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"Can you teach me driving?"</span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>ourConversation<span class="token punctuation">.</span>content<span class="token punctuation">)</span>
</code></pre>
<h2 id="3-Let’s-Build-Simple-Conversational-Application"><a href="#3-Let’s-Build-Simple-Conversational-Application" class="headerlink" title="3. Let’s Build Simple Conversational Application"></a>3. Let’s Build Simple Conversational Application</h2><blockquote>
<p>和刚才一样, space里创建</p>
</blockquote>
<p><img src="b6a016a8.png"><img src="9aa72313.png" alt="upload file"><img src="92ac4f19.png"></p>
<pre class=" language-python"><code class="language-python">
<span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st


<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>chat_models <span class="token keyword">import</span> ChatOpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>schema <span class="token keyword">import</span> <span class="token punctuation">(</span>
    AIMessage<span class="token punctuation">,</span>
    HumanMessage<span class="token punctuation">,</span>
    SystemMessage
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># From here down is all the StreamLit UI.</span>
st<span class="token punctuation">.</span>set_page_config<span class="token punctuation">(</span>page_title<span class="token operator">=</span><span class="token string">"LangChain Demo"</span><span class="token punctuation">,</span> page_icon<span class="token operator">=</span><span class="token string">":robot:"</span><span class="token punctuation">)</span>
st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">"Hey, I'm your Chat GPT"</span><span class="token punctuation">)</span>



<span class="token keyword">if</span> <span class="token string">"sessionMessages"</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
     st<span class="token punctuation">.</span>session_state<span class="token punctuation">.</span>sessionMessages <span class="token operator">=</span> <span class="token punctuation">[</span>
        SystemMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"You are a helpful assistant."</span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span>



<span class="token keyword">def</span> <span class="token function">load_answer</span><span class="token punctuation">(</span>question<span class="token punctuation">)</span><span class="token punctuation">:</span>

    st<span class="token punctuation">.</span>session_state<span class="token punctuation">.</span>sessionMessages<span class="token punctuation">.</span>append<span class="token punctuation">(</span>HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span>question<span class="token punctuation">)</span><span class="token punctuation">)</span>

    assistant_answer  <span class="token operator">=</span> chat<span class="token punctuation">(</span>st<span class="token punctuation">.</span>session_state<span class="token punctuation">.</span>sessionMessages <span class="token punctuation">)</span>

    st<span class="token punctuation">.</span>session_state<span class="token punctuation">.</span>sessionMessages<span class="token punctuation">.</span>append<span class="token punctuation">(</span>AIMessage<span class="token punctuation">(</span>content<span class="token operator">=</span>assistant_answer<span class="token punctuation">.</span>content<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> assistant_answer<span class="token punctuation">.</span>content


<span class="token keyword">def</span> <span class="token function">get_text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    input_text <span class="token operator">=</span> st<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">"You: "</span><span class="token punctuation">,</span> key<span class="token operator">=</span> input<span class="token punctuation">)</span>
    <span class="token keyword">return</span> input_text


chat <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>
    temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> 
    api_key<span class="token operator">=</span><span class="token string">"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"</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># 报错307 就换一个模型试试</span>
    model_name<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># OK</span>
<span class="token punctuation">)</span>




user_input<span class="token operator">=</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span>
submit <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">'Generate'</span><span class="token punctuation">)</span>  

<span class="token keyword">if</span> submit<span class="token punctuation">:</span>
    
    response <span class="token operator">=</span> load_answer<span class="token punctuation">(</span>user_input<span class="token punctuation">)</span>
    st<span class="token punctuation">.</span>subheader<span class="token punctuation">(</span><span class="token string">"Answer:"</span><span class="token punctuation">)</span>

    st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>response<span class="token punctuation">,</span>key<span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
</code></pre>
<h1 id="8-Project-3-Find-Similar-Things-App-For-Kids"><a href="#8-Project-3-Find-Similar-Things-App-For-Kids" class="headerlink" title="8. Project #3 - Find Similar Things App For Kids"></a>8. Project #3 - Find Similar Things App For Kids</h1><h2 id="1-Text-Embedding-Walkthrough"><a href="#1-Text-Embedding-Walkthrough" class="headerlink" title="1. Text Embedding Walkthrough"></a>1. Text Embedding Walkthrough</h2><p><img src="58bab423.png"><img src="d01fd9db.png"><img src="82786bea.png"></p>
<h2 id="2-Text-Embeddings-Practical-Implementation-using-Python"><a href="#2-Text-Embeddings-Practical-Implementation-using-Python" class="headerlink" title="2. Text Embeddings Practical Implementation using Python"></a>2. Text Embeddings Practical Implementation using Python</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %% env</span>
<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'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'</span>
<span class="token comment" spellcheck="true"># %% import embeddings</span>
<span class="token comment" spellcheck="true"># ImportError: Could not import tiktoken python package.</span>
<span class="token comment" spellcheck="true"># This is needed in order to for OpenAIEmbeddings. Please install it with `pip install tiktoken`.</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> OpenAIEmbeddings

<span class="token comment" spellcheck="true"># %% Initialize the OpenAlEmbeddings object</span>
embeddings <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
our_txt <span class="token operator">=</span> <span class="token string">'hey buddy'</span>
txt_embedding <span class="token operator">=</span> embeddings<span class="token punctuation">.</span>embed_query<span class="token punctuation">(</span>our_txt<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Our embedding is length {txt_embedding}'</span><span class="token punctuation">)</span>
</code></pre>
<p><img src="8d893929.png"></p>
<h2 id="3-Embeddings-Example-using-Python"><a href="#3-Embeddings-Example-using-Python" class="headerlink" title="3. Embeddings Example using Python"></a>3. Embeddings Example using Python</h2><p><img src="7b10dbe7.png" alt="data.xlsx"><a href="data.xlsx">data.xlsx</a><img src="8f473056.png"><img src="3fa44a7c.png"></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %% env</span>
<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'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'</span>
<span class="token comment" spellcheck="true"># %% import embeddings</span>
<span class="token comment" spellcheck="true"># ImportError: Could not import tiktoken python package.</span>
<span class="token comment" spellcheck="true"># This is needed in order to for OpenAIEmbeddings. Please install it with `pip install tiktoken`.</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> OpenAIEmbeddings

<span class="token comment" spellcheck="true"># %% Initialize the OpenAlEmbeddings object</span>
embeddings <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% data</span>
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

<span class="token comment" spellcheck="true"># ImportError: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.</span>
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_excel<span class="token punctuation">(</span><span class="token string">'data.xlsx'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
<span class="token triple-quoted-string string">'''
We can use "apply"to apply the get_embedding function to each row in the dataframe because our words are stored in a pandas dataframe.In order to save
time and to save the calculated word embeddings in a new csv file called "word_embeddings.csv"rather than calling OpenAl once more to carry out these
computations.
'''</span>
<span class="token comment" spellcheck="true"># 需要等很长时间 ...</span>
df<span class="token punctuation">[</span><span class="token string">'embedding'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Words'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> embeddings<span class="token punctuation">.</span>embed_query<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'word_embeddings.csv'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
<span class="token triple-quoted-string string">'''
Let's load the existing file,which contains the embeddings,
so that we can save chargers by not hitting the APl repeatedly
'''</span>
new_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'word_embeddings.csv'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>new_df<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% Let's get the embeddings for our text</span>
our_txt <span class="token operator">=</span> <span class="token string">'Mango'</span>
txt_embedding <span class="token operator">=</span> embeddings<span class="token punctuation">.</span>embed_query<span class="token punctuation">(</span>our_txt<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Our embedding is {txt_embedding}'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
<span class="token triple-quoted-string string">'''
We can determine how similar a word is to other words in our dataframe after we have a vector representing that word.
By computing the cosine similarity of the word vector for our search term to each word embedding in our dataframe.
'''</span>
<span class="token keyword">from</span> openai <span class="token keyword">import</span> OpenAI

client <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">get_embedding</span><span class="token punctuation">(</span>text<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"text-embedding-ada-002"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    text <span class="token operator">=</span> text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span> <span class="token string">" "</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> client<span class="token punctuation">.</span>embeddings<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
        input<span class="token operator">=</span><span class="token punctuation">[</span>text<span class="token punctuation">]</span><span class="token punctuation">,</span>
        model<span class="token operator">=</span>model
    <span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>embedding


<span class="token comment" spellcheck="true"># df['ada_embedding'] = df.combined.apply(lambda x: get_embedding(x, model='text-embedding-ada-002'))</span>
<span class="token comment" spellcheck="true"># %% utils</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np


<span class="token keyword">def</span> <span class="token function">calculate_cosine_similarity</span><span class="token punctuation">(</span>vector_a<span class="token punctuation">,</span> vector_b<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># Compute the dot product of the two vectors</span>
    dot_product <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>vector_a<span class="token punctuation">,</span> vector_b<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Compute the L2 norms (magnitudes) of each vector</span>
    norm_a <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>vector_a<span class="token punctuation">)</span>
    norm_b <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>vector_b<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Compute the cosine similarity</span>
    <span class="token comment" spellcheck="true"># Note: We add a small epsilon value to the denominator for numerical stability</span>
    epsilon <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">10</span>
    cosine_similarity <span class="token operator">=</span> dot_product <span class="token operator">/</span> <span class="token punctuation">(</span>norm_a <span class="token operator">*</span> norm_b <span class="token operator">+</span> epsilon<span class="token punctuation">)</span>

    <span class="token keyword">return</span> cosine_similarity


<span class="token comment" spellcheck="true"># def cosine_similarity(asingle, bsingle) -> np.double:</span>
<span class="token comment" spellcheck="true">#     </span><span class="token triple-quoted-string string">"""return normalized dot product of two arrays"""</span>
<span class="token comment" spellcheck="true">#     a = asingle.astype(np.double)</span>
<span class="token comment" spellcheck="true">#     b = bsingle.astype(np.double)</span>
<span class="token comment" spellcheck="true">#     return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))</span>


<span class="token comment" spellcheck="true"># %% similarity</span>
<span class="token comment" spellcheck="true"># old version &lt; 1.0</span>
<span class="token comment" spellcheck="true"># from openai.embeddings_utils import cosine_similarity</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>pairwise <span class="token keyword">import</span> cosine_similarity

<span class="token comment" spellcheck="true"># df['similarity score'] = df['embedding'].apply(lambda x: cosine_similarity(x, txt_embedding))</span>
df<span class="token punctuation">[</span><span class="token string">'similarity score'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'embedding'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> cosine_similarity<span class="token punctuation">(</span>x<span class="token punctuation">,</span> txt_embedding<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
<span class="token triple-quoted-string string">'''
Sorting by similarity values in dataframe reveals Banana,Orange,and Apple are closest to searched term,such as Mango.
'''</span>

res <span class="token operator">=</span> df<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span><span class="token string">'similarity score'</span><span class="token punctuation">,</span> ascending<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">)</span>
</code></pre>
<h2 id="4-Let’s-build-Similar-Words-Finder-Application"><a href="#4-Let’s-build-Similar-Words-Finder-Application" class="headerlink" title="4. Let’s build Similar Words Finder Application"></a>4. Let’s build Similar Words Finder Application</h2><p><img src="5847bbce.png"><img src="09684d7c.png"></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#Allows you to use Streamlit, a framework for building interactive web applications.</span>
<span class="token comment" spellcheck="true">#It provides functions for creating UIs, displaying data, and handling user inputs.</span>
<span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st


<span class="token comment" spellcheck="true">#This module provides a way to interact with the operating system, such as accessing environment variables, working with files</span>
<span class="token comment" spellcheck="true">#and directories, executing shell commands, etc</span>
<span class="token keyword">import</span> os

<span class="token comment" spellcheck="true">#Helps us generate embeddings</span>
<span class="token comment" spellcheck="true">#An embedding is a vector (list) of floating point numbers. The distance between two vectors measures their relatedness. </span>
<span class="token comment" spellcheck="true">#Small distances suggest high relatedness and large distances suggest low relatedness.</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> OpenAIEmbeddings


<span class="token comment" spellcheck="true">#FAISS is an open-source library developed by Facebook AI Research for efficient similarity search and clustering of large-scale datasets, particularly with high-dimensional vectors. </span>
<span class="token comment" spellcheck="true">#It provides optimized indexing structures and algorithms for tasks like nearest neighbor search and recommendation systems.</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> FAISS


<span class="token comment" spellcheck="true">#load_dotenv() is a function that loads variables from a .env file into environment variables in a Python script. </span>
<span class="token comment" spellcheck="true">#It allows you to store sensitive information or configuration settings separate from your code</span>
<span class="token comment" spellcheck="true">#and access them within your application.</span>

<span class="token comment" spellcheck="true"># pip3 install python-dotenv</span>
<span class="token keyword">from</span> dotenv <span class="token keyword">import</span> load_dotenv


load_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token comment" spellcheck="true">#By using st.set_page_config(), you can customize the appearance of your Streamlit application's web page</span>
st<span class="token punctuation">.</span>set_page_config<span class="token punctuation">(</span>page_title<span class="token operator">=</span><span class="token string">"Educate Kids"</span><span class="token punctuation">,</span> page_icon<span class="token operator">=</span><span class="token string">":robot:"</span><span class="token punctuation">)</span>
st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">"Hey, Ask me something &amp; I will give out similar things"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#Initialize the OpenAIEmbeddings object</span>
embeddings <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#The below snippet helps us to import CSV file data for our tasks</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>document_loaders<span class="token punctuation">.</span>csv_loader <span class="token keyword">import</span> CSVLoader
loader <span class="token operator">=</span> CSVLoader<span class="token punctuation">(</span>file_path<span class="token operator">=</span><span class="token string">'myData.csv'</span><span class="token punctuation">,</span> csv_args<span class="token operator">=</span><span class="token punctuation">{</span>
    <span class="token string">'delimiter'</span><span class="token punctuation">:</span> <span class="token string">','</span><span class="token punctuation">,</span>
    <span class="token string">'quotechar'</span><span class="token punctuation">:</span> <span class="token string">'"'</span><span class="token punctuation">,</span>
    <span class="token string">'fieldnames'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Words'</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#Assigning the data inside the csv to our variable here</span>
data <span class="token operator">=</span> loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#Display the data</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>

db <span class="token operator">=</span> FAISS<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>data<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#Function to receive input from user and store it in a variable</span>
<span class="token keyword">def</span> <span class="token function">get_text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    input_text <span class="token operator">=</span> st<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">"You: "</span><span class="token punctuation">,</span> key<span class="token operator">=</span> input<span class="token punctuation">)</span>
    <span class="token keyword">return</span> input_text


user_input<span class="token operator">=</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span>
submit <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">'Find similar Things'</span><span class="token punctuation">)</span>  

<span class="token keyword">if</span> submit<span class="token punctuation">:</span>
    
    <span class="token comment" spellcheck="true">#If the button is clicked, the below snippet will fetch us the similar text</span>
    docs <span class="token operator">=</span> db<span class="token punctuation">.</span>similarity_search<span class="token punctuation">(</span>user_input<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>docs<span class="token punctuation">)</span>
    st<span class="token punctuation">.</span>subheader<span class="token punctuation">(</span><span class="token string">"Top Matches:"</span><span class="token punctuation">)</span>
    st<span class="token punctuation">.</span>text<span class="token punctuation">(</span>docs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    st<span class="token punctuation">.</span>text<span class="token punctuation">(</span>docs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content<span class="token punctuation">)</span>
</code></pre>
<pre class=" language-shell"><code class="language-shell">streamlit run 文件名.py --server.port 8888
</code></pre>
<h1 id="9-Langchain-Prompt-Module-Concept-amp-Implementation-Using-Python"><a href="#9-Langchain-Prompt-Module-Concept-amp-Implementation-Using-Python" class="headerlink" title="9. Langchain - Prompt Module Concept &amp; Implementation Using Python"></a>9. Langchain - Prompt Module Concept &amp; Implementation Using Python</h1><h2 id="1-Prompts-Module-Introduction"><a href="#1-Prompts-Module-Introduction" class="headerlink" title="1. Prompts Module Introduction"></a>1. Prompts Module Introduction</h2><p><img src="0a74dbde.png"><img src="0d78b7ec.png"></p>
<h2 id="2-Prompt-Template-Walkthrough"><a href="#2-Prompt-Template-Walkthrough" class="headerlink" title="2. Prompt Template Walkthrough"></a>2. Prompt Template Walkthrough</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %%</span>
<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_KEY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'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'</span>
<span class="token comment" spellcheck="true"># %%</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI

llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>model_name<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo-instruct"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
our_prompt <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
I love trips,and I have been to 6 countries.
I plan to visit few more soon.

Can you create a post for tweet in 10 words for the above?
"""</span>  <span class="token comment" spellcheck="true"># 10 words -> 这个10 我们希望能动态指定</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>our_prompt<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># %%</span>
res <span class="token operator">=</span> llm<span class="token punctuation">(</span>our_prompt<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% Prompt Template</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain <span class="token keyword">import</span> PromptTemplate

llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>model_name<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo-instruct"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% Using F-String</span>
<span class="token triple-quoted-string string">'''
F-String is a Python feature that allows easy string formatting by placing variables inside curly braces within a string,making code more readable and efficient.
__Code:__
name = "Alice"
age = 25
message f"My name is {name} and I am {age} years old."
print(message)

__Output:__
My name is Allce and I am 25 years old.
'''</span>

wordsCount <span class="token operator">=</span> <span class="token number">5</span>
our_txt <span class="token operator">=</span> <span class="token string">"I love trips,and I have been to 6 countries. I plan to visit few more soon."</span>
our_prompt <span class="token operator">=</span> f<span class="token triple-quoted-string string">"""
{our_txt}

Can you create a post for tweet in {wordsCount} words for the above?
"""</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>our_prompt<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>llm<span class="token punctuation">(</span>our_prompt<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% Using Prompt Template</span>
<span class="token comment" spellcheck="true"># Prompt templates helps us in keeping our code neat and clean when we are bullding more complex</span>

template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
{our_txt}

Can you create a post for tweet in {wordsCount} words for the above?
"""</span>

<span class="token comment" spellcheck="true"># %%</span>
prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'wordsCount'</span><span class="token punctuation">,</span> <span class="token string">'our_txt'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    template<span class="token operator">=</span>template
<span class="token punctuation">)</span>

final_prompt <span class="token operator">=</span> prompt<span class="token punctuation">.</span>format<span class="token punctuation">(</span>
    wordsCount<span class="token operator">=</span><span class="token string">'3'</span><span class="token punctuation">,</span>
    our_txt<span class="token operator">=</span>our_txt
<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>final_prompt<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>llm<span class="token punctuation">(</span>final_prompt<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="3-Example-Selectors-Walkthrough"><a href="#3-Example-Selectors-Walkthrough" class="headerlink" title="3. Example Selectors Walkthrough"></a>3. Example Selectors Walkthrough</h2><p><img src="f0927611.png"></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %%</span>
<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_KEY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'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'</span>
<span class="token comment" spellcheck="true"># %% Few Shot Templates</span>
<span class="token triple-quoted-string string">"""
Few-shot learning is a way to teach computers to make predictions using only a small amount of information.Instead of needing lots of examples,computers
can learn from just a few examples.
They find patterns in the examples and use those pattemns to understand and recognize new things.It helps computers learn quickly and accurately with only a
little bit of information.
"""</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI

<span class="token comment" spellcheck="true"># %%</span>
<span class="token triple-quoted-string string">'''
A prompt in NLP (Natural Language Processing) is a text
or instruction given to a language model to generate a response.
'''</span>

our_prompt <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
You are a 5 year old gril, who is very funny, mischievous and sweet:

Question: What is house?
Response: 
"""</span>

llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> model_name<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo-instruct"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>llm<span class="token punctuation">(</span>our_prompt<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
<span class="token triple-quoted-string string">'''
We observe that though we have instructed the model to act as a little girl,
it's unable to do so as it very generic by nature
So we will try to proved some extemal knowledge to get the perfect answers from it
'''</span>

our_prompt <span class="token operator">=</span> <span class="token triple-quoted-string string">"""You are a s year old girl,who is very funny, mischievous and sweet:
Here are some examples:
Question: What is a mobile?
Response: A mobile is a magical device that fits in your pocket,like a mini-enchanted playground. It has games, videos, and talking pictures,but be careful,it can turn grown-ups into

Question: What are your dreams?
Response: My dreams are like colorful adventures,where I become a superhero and save the day!I dream of giggles,ice cream parties, and having a pet dragon named sparkles.

Question: What is a house?
Response: 
"""</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>llm<span class="token punctuation">(</span>our_prompt<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
<span class="token triple-quoted-string string">'''
The FewShotPromptTemplate feature offered by LangChain allows for few-shot leaming using prompts.

In the context of large language models(LLMs),the primary sources of knowledge are parametric knowledge (learned during model training)and source
knowledge(provided within model input at inference time).

The FewShotPromptTemplate enables the inclusion of a few examples within prompts,which the model can read and use to apply to user input,enhancing the
model's ability to handle specific tasks or scenarios.
'''</span>

<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate
<span class="token keyword">from</span> langchain <span class="token keyword">import</span> FewShotPromptTemplate  <span class="token comment" spellcheck="true"># 简短提示模板</span>

<span class="token comment" spellcheck="true"># %%</span>
<span class="token comment" spellcheck="true"># Let's create a list of examples, that can be passed to the model later for our task</span>
<span class="token comment" spellcheck="true"># examples 的json的变量名对应 example_template 的 {变量名}</span>
examples <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
        <span class="token string">'query'</span><span class="token punctuation">:</span> <span class="token string">'What is a mobile?'</span><span class="token punctuation">,</span>
        <span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">'A mobile is a magical device that fits in your pocket,like a mini-enchanted playground. It has games, videos, and talking pictures,but be careful,it can turn grown-ups into'</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
        <span class="token string">'query'</span><span class="token punctuation">:</span> <span class="token string">'What are your dreams?'</span><span class="token punctuation">,</span>
        <span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">'My dreams are like colorful adventures,where I become a superhero and save the day!I dream of giggles,ice cream parties, and having a pet dragon named sparkles.'</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># %% Let's create a example template</span>
example_template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
Question: {query}
Response: {answer}
"""</span>

<span class="token comment" spellcheck="true"># %% Let's create a prompt example from above created example template</span>
<span class="token comment" spellcheck="true"># example_template -> 定义 example_prompt 模板</span>
example_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'query'</span><span class="token punctuation">,</span> <span class="token string">'answer'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    template<span class="token operator">=</span>example_template
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
<span class="token triple-quoted-string string">'''
The previous original prompt can be divided into a prefix and suffix.
The prefix consists of the instructions or context given to the model,while the suffix includes the user input and output indicator.
'''</span>
prefix <span class="token operator">=</span> <span class="token triple-quoted-string string">"""You are a s year old girl,who is very funny, mischievous and sweet:
Here are some examples:
"""</span>

suffix <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
Question: {userInput}
Response: """</span>

<span class="token comment" spellcheck="true"># %% Let's create a few shot prompt template,by using the above details</span>

few_shot_prompt_template <span class="token operator">=</span> FewShotPromptTemplate<span class="token punctuation">(</span>
    <span class="token comment" spellcheck="true"># 将 example_prompt 和 examples 关联</span>
    examples<span class="token operator">=</span>examples<span class="token punctuation">,</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># 将 prefix 和 input_variables 关联</span>
    prefix<span class="token operator">=</span>prefix<span class="token punctuation">,</span>
    suffix<span class="token operator">=</span>suffix<span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'userInput'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    example_separator<span class="token operator">=</span><span class="token string">"\n\n"</span>
<span class="token punctuation">)</span>

query <span class="token operator">=</span> <span class="token string">'What is a house?'</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>few_shot_prompt_template<span class="token punctuation">.</span>format<span class="token punctuation">(</span>userInput<span class="token operator">=</span>query<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>llm<span class="token punctuation">(</span>few_shot_prompt_template<span class="token punctuation">.</span>format<span class="token punctuation">(</span>userInput<span class="token operator">=</span>query<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="4-Adding-More-Examples-To-Input-Prompt"><a href="#4-Adding-More-Examples-To-Input-Prompt" class="headerlink" title="4. Adding More Examples To Input Prompt"></a>4. Adding More Examples To Input Prompt</h2><p><img src="4c16bfb1.png" alt="传递example有很多时, 可能遇到超过上下文限制的情况"></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %%</span>
examples <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
        <span class="token string">'query'</span><span class="token punctuation">:</span> <span class="token string">'What is a mobile?'</span><span class="token punctuation">,</span>
        <span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">'A mobile is a magical device that fits in your pocket,like a mini-enchanted playground. It has games, videos, and talking pictures,but be careful,it can turn grown-ups into'</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
        <span class="token string">'query'</span><span class="token punctuation">:</span> <span class="token string">'What are your dreams?'</span><span class="token punctuation">,</span>
        <span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">'My dreams are like colorful adventures,where I become a superhero and save the day!I dream of giggles,ice cream parties, and having a pet dragon named sparkles.'</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
        <span class="token string">'query'</span><span class="token punctuation">:</span> <span class="token string">'What are your ambitions?'</span><span class="token punctuation">,</span>
        <span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">"I want to be a super funny comedian,spreading laughter everywhere I go!I also want to be a master cooki"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
        <span class="token string">'query'</span><span class="token punctuation">:</span> <span class="token string">"what happens when you get sick?"</span><span class="token punctuation">,</span>
        <span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">"when I get sick,it's like a sneaky monster visits.I feel tired,sniffly,and need lots of cuddles.But"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
        <span class="token string">'query'</span><span class="token punctuation">:</span> <span class="token string">"WHow much do you love your dad?"</span><span class="token punctuation">,</span>
        <span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">"oh,I love my dad to the moon and back,with sprinkles and unicorns on top!He's my superhero,my partner "</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
        <span class="token string">'query'</span><span class="token punctuation">:</span> <span class="token string">"Tell me about your friend?"</span><span class="token punctuation">,</span>
        <span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">"My friend is like a sunshine rainbow!We laugh,play,and have magical parties together.They always list"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
        <span class="token string">'query'</span><span class="token punctuation">:</span> <span class="token string">"what math means to you?"</span><span class="token punctuation">,</span>
        <span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">"Math i like a puzzle game,full of numbers and shapes.It helps me count my toys,build towers,and shar"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
        <span class="token string">'query'</span><span class="token punctuation">:</span> <span class="token string">"what is your fear?"</span><span class="token punctuation">,</span>
        <span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">"Sometimes I'm scared of thunderstorms and monsters under my bed.But with my teddy bear by my side and lo"</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># %%</span>
<span class="token triple-quoted-string string">'''
In the above explanation,be have been using 'FewShotPromptTemplate'and 'examples'dictionary as it is more robust approach compared to using a single f-string.

It offers features such as the ability to include or exclude examples based on the length of the query.
This is important because there is a maximum context window limitation for prompt and generation output length.

The goal is to provide as many examples as possible for few-shot learning without exceeding the context window or increasing processing times excessively.
The dynamic inclusion/exclusion of examples means that we choose which examples to use based on certain rules.This helps us use the model's abilities in
the best way possible.

It allows us to be efficient and make the most out of the few-shot learning process.
'''</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts<span class="token punctuation">.</span>example_selector <span class="token keyword">import</span> LengthBasedExampleSelector

<span class="token comment" spellcheck="true"># %%</span>
<span class="token triple-quoted-string string">'''
LengthBasedExampleSelector-This ExampleSelector chooses examples based on length,useful to prevent prompt exceeding context window.
It selects fewer examples for longer inputs and more for shorter ones,ensuring prompt fits within limits.

The maximum length of the formatted examples is set to 'n'characters.
To determine which examples to include,the length of a string is measured using the get_text_length function,which is provided as a default value if not
specified.
'''</span>
example_selector <span class="token operator">=</span> LengthBasedExampleSelector<span class="token punctuation">(</span>
    examples<span class="token operator">=</span>examples<span class="token punctuation">,</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    max_length<span class="token operator">=</span><span class="token number">50</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
<span class="token triple-quoted-string string">'''
Creating a new dynamic few shot prompt template
And we are passing example_selector instead of examples as earlier
'''</span>
new_prompt_template <span class="token operator">=</span> FewShotPromptTemplate<span class="token punctuation">(</span>
    example_selector<span class="token operator">=</span>example_selector<span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># use example_selector instead of examples</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># 将 prefix 和 input_variables 关联</span>
    prefix<span class="token operator">=</span>prefix<span class="token punctuation">,</span>
    suffix<span class="token operator">=</span>suffix<span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'userInput'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    example_separator<span class="token operator">=</span><span class="token string">"\n\n"</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
query <span class="token operator">=</span> <span class="token string">'What is a house?'</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>new_prompt_template<span class="token punctuation">.</span>format<span class="token punctuation">(</span>userInput<span class="token operator">=</span>query<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>llm<span class="token punctuation">(</span>new_prompt_template<span class="token punctuation">.</span>format<span class="token punctuation">(</span>userInput<span class="token operator">=</span>query<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% We can also add an extra example to an example selector we already have.</span>
new_example <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What's your favorite work?"</span><span class="token punctuation">,</span> <span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">"sleep"</span><span class="token punctuation">}</span>
new_prompt_template<span class="token punctuation">.</span>example_selector<span class="token punctuation">.</span>add_example<span class="token punctuation">(</span>new_example<span class="token punctuation">)</span>

example_selector <span class="token operator">=</span> LengthBasedExampleSelector<span class="token punctuation">(</span>
    examples<span class="token operator">=</span>new_example<span class="token punctuation">,</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    max_length<span class="token operator">=</span><span class="token number">1000</span>
<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>new_prompt_template<span class="token punctuation">.</span>format<span class="token punctuation">(</span>userInput<span class="token operator">=</span>query<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>llm<span class="token punctuation">(</span>new_prompt_template<span class="token punctuation">.</span>format<span class="token punctuation">(</span>userInput<span class="token operator">=</span>query<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="5-Output-Parsers-Walkthrough"><a href="#5-Output-Parsers-Walkthrough" class="headerlink" title="5. Output Parsers Walkthrough"></a>5. Output Parsers Walkthrough</h2><p><img src="f2a835f4.png"><img src="42225607.png" alt="CommaSeparatedListOutputParser"><br><img src="b83380b4.png" alt="CommaSeparatedListOutputParser"><img src="bbc1001c.png"></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %%</span>
<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_KEY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'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'</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI
<span class="token comment" spellcheck="true"># %% Comma Separated List</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> CommaSeparatedListOutputParser

<span class="token comment" spellcheck="true"># Creating an object of CommaSeparatedListOutputParser</span>
<span class="token comment" spellcheck="true"># 指定模型输出 逗号分割的列表: 1. xxx \n2. xxx\n</span>
<span class="token comment" spellcheck="true"># #%% JSON format</span>
<span class="token comment" spellcheck="true"># ...</span>
output_parser <span class="token operator">=</span> CommaSeparatedListOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
format_instructions <span class="token operator">=</span> output_parser<span class="token punctuation">.</span>get_format_instructions<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Your response should be a list of comma separated values, eg: `foo, bar, baz`</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>format_instructions<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># %%</span>
prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    template<span class="token operator">=</span><span class="token string">"Provide 5 examples of {query}.\n{format_instructions}"</span><span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'query'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    partial_variables<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'format_instructions'</span><span class="token punctuation">:</span> format_instructions<span class="token punctuation">}</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># llm = OpenAI(temperature=0.9, model="gpt-3.5-turbo-instruct")</span>
llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>

prompt <span class="token operator">=</span> prompt<span class="token punctuation">.</span>format<span class="token punctuation">(</span>query<span class="token operator">=</span><span class="token string">"Currencies"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Currencies: 货币实例</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>

output <span class="token operator">=</span> llm<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% JSON format</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> StructuredOutputParser<span class="token punctuation">,</span> ResponseSchema

<span class="token comment" spellcheck="true"># 指定返回什么</span>
<span class="token triple-quoted-string string">'''json
{
    'currency': '',
    'abbrevation': ''
}
'''</span>
response_schema <span class="token operator">=</span> <span class="token punctuation">[</span>
    ResponseSchema<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'currency'</span><span class="token punctuation">,</span> description<span class="token operator">=</span><span class="token string">"answer to the user's question"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># abbrevation: 缩写</span>
    ResponseSchema<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'abbrevation'</span><span class="token punctuation">,</span> description<span class="token operator">=</span><span class="token string">"What's the abbrevation of that currency"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

output_parser <span class="token operator">=</span> StructuredOutputParser<span class="token punctuation">.</span>from_response_schemas<span class="token punctuation">(</span>response_schema<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output_parser<span class="token punctuation">)</span>

format_instructions <span class="token operator">=</span> output_parser<span class="token punctuation">.</span>get_format_instructions<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>format_instructions<span class="token punctuation">)</span>

prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    template<span class="token operator">=</span><span class="token string">"answer the users question as best as possible.\n{format_instructions}\n{query}"</span><span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'query'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 用户输入</span>
    partial_variables<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'format_instructions'</span><span class="token punctuation">:</span> format_instructions<span class="token punctuation">}</span>  <span class="token comment" spellcheck="true"># 指定格式的输入语句</span>
<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>

prompt <span class="token operator">=</span> prompt<span class="token punctuation">.</span>format<span class="token punctuation">(</span>query<span class="token operator">=</span><span class="token string">'what is the currency of india?'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>llm<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">'''
json
{
    "currency": "Indian rupee",
    "abbrevation": "INR"
}
'''</span>
</code></pre>
<h1 id="10-Project-4-Marketing-Campaign-App"><a href="#10-Project-4-Marketing-Campaign-App" class="headerlink" title="10. Project #4 - Marketing Campaign App"></a>10. Project #4 - Marketing Campaign App</h1><h2 id="1-Convert-Jupyter-Notebook-to-Python-Script"><a href="#1-Convert-Jupyter-Notebook-to-Python-Script" class="headerlink" title="1. Convert Jupyter Notebook to Python Script"></a>1. Convert Jupyter Notebook to Python Script</h2><pre class=" language-shell"><code class="language-shell">pip install -r requirements.txt
</code></pre>
<p><img src="ae304e5f.png"></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %%</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate
<span class="token keyword">from</span> langchain <span class="token keyword">import</span> FewShotPromptTemplate
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts<span class="token punctuation">.</span>example_selector <span class="token keyword">import</span> LengthBasedExampleSelector

<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"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"</span>

llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">)</span>

examples <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What is a mobile?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games, videos, and talking pictures, but be careful, it can turn grown-ups into screen-time monsters too!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What are your dreams?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"My dreams are like colorful adventures, where I become a superhero and save the day! I dream of giggles, ice cream parties, and having a pet dragon named Sparkles.."</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">" What are your ambitions?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"I want to be a super funny comedian, spreading laughter everywhere I go! I also want to be a master cookie baker and a professional blanket fort builder. Being mischievous and sweet is just my bonus superpower!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What happens when you get sick?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"When I get sick, it's like a sneaky monster visits. I feel tired, sniffly, and need lots of cuddles. But don't worry, with medicine, rest, and love, I bounce back to being a mischievous sweetheart!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"WHow much do you love your dad?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Oh, I love my dad to the moon and back, with sprinkles and unicorns on top! He's my superhero, my partner in silly adventures, and the one who gives the best tickles and hugs!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"Tell me about your friend?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"My friend is like a sunshine rainbow! We laugh, play, and have magical parties together. They always listen, share their toys, and make me feel special. Friendship is the best adventure!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What math means to you?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Math is like a puzzle game, full of numbers and shapes. It helps me count my toys, build towers, and share treats equally. It's fun and makes my brain sparkle!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What is your fear?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Sometimes I'm scared of thunderstorms and monsters under my bed. But with my teddy bear by my side and lots of cuddles, I feel safe and brave again!"</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">]</span>

example_template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
Question: {query}
Response: {answer}
"""</span>

example_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"query"</span><span class="token punctuation">,</span> <span class="token string">"answer"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    template<span class="token operator">=</span>example_template
<span class="token punctuation">)</span>

prefix <span class="token operator">=</span> <span class="token triple-quoted-string string">"""You are a 5 year old girl, who is very funny,mischievous and sweet: 
Here are some examples: 
"""</span>

suffix <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
Question: {userInput}
Response: """</span>

example_selector <span class="token operator">=</span> LengthBasedExampleSelector<span class="token punctuation">(</span>
    examples<span class="token operator">=</span>examples<span class="token punctuation">,</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    max_length<span class="token operator">=</span><span class="token number">200</span>
<span class="token punctuation">)</span>

new_prompt_template <span class="token operator">=</span> FewShotPromptTemplate<span class="token punctuation">(</span>
    example_selector<span class="token operator">=</span>example_selector<span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># use example_selector instead of examples</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    prefix<span class="token operator">=</span>prefix<span class="token punctuation">,</span>
    suffix<span class="token operator">=</span>suffix<span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"userInput"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    example_separator<span class="token operator">=</span><span class="token string">"\n"</span>
<span class="token punctuation">)</span>

query <span class="token operator">=</span> <span class="token string">"What is a house?"</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>new_prompt_template<span class="token punctuation">.</span>format<span class="token punctuation">(</span>userInput<span class="token operator">=</span>query<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>llm<span class="token punctuation">(</span>new_prompt_template<span class="token punctuation">.</span>format<span class="token punctuation">(</span>userInput<span class="token operator">=</span>query<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="2-Building-the-App’s-frontend"><a href="#2-Building-the-App’s-frontend" class="headerlink" title="2. Building the App’s frontend"></a>2. Building the App’s frontend</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate
<span class="token keyword">from</span> langchain <span class="token keyword">import</span> FewShotPromptTemplate
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts<span class="token punctuation">.</span>example_selector <span class="token keyword">import</span> LengthBasedExampleSelector
<span class="token keyword">from</span> dotenv <span class="token keyword">import</span> load_dotenv

load_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span>

llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">)</span>

examples <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What is a mobile?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games, videos, and talking pictures, but be careful, it can turn grown-ups into screen-time monsters too!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What are your dreams?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"My dreams are like colorful adventures, where I become a superhero and save the day! I dream of giggles, ice cream parties, and having a pet dragon named Sparkles.."</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">" What are your ambitions?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"I want to be a super funny comedian, spreading laughter everywhere I go! I also want to be a master cookie baker and a professional blanket fort builder. Being mischievous and sweet is just my bonus superpower!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What happens when you get sick?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"When I get sick, it's like a sneaky monster visits. I feel tired, sniffly, and need lots of cuddles. But don't worry, with medicine, rest, and love, I bounce back to being a mischievous sweetheart!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"WHow much do you love your dad?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Oh, I love my dad to the moon and back, with sprinkles and unicorns on top! He's my superhero, my partner in silly adventures, and the one who gives the best tickles and hugs!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"Tell me about your friend?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"My friend is like a sunshine rainbow! We laugh, play, and have magical parties together. They always listen, share their toys, and make me feel special. Friendship is the best adventure!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What math means to you?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Math is like a puzzle game, full of numbers and shapes. It helps me count my toys, build towers, and share treats equally. It's fun and makes my brain sparkle!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What is your fear?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Sometimes I'm scared of thunderstorms and monsters under my bed. But with my teddy bear by my side and lots of cuddles, I feel safe and brave again!"</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">]</span>

example_template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
Question: {query}
Response: {answer}
"""</span>

example_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"query"</span><span class="token punctuation">,</span> <span class="token string">"answer"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    template<span class="token operator">=</span>example_template
<span class="token punctuation">)</span>

prefix <span class="token operator">=</span> <span class="token triple-quoted-string string">"""You are a 5 year old girl, who is very funny,mischievous and sweet: 
Here are some examples: 
"""</span>

suffix <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
Question: {userInput}
Response: """</span>

example_selector <span class="token operator">=</span> LengthBasedExampleSelector<span class="token punctuation">(</span>
    examples<span class="token operator">=</span>examples<span class="token punctuation">,</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    max_length<span class="token operator">=</span><span class="token number">200</span>
<span class="token punctuation">)</span>

new_prompt_template <span class="token operator">=</span> FewShotPromptTemplate<span class="token punctuation">(</span>
    example_selector<span class="token operator">=</span>example_selector<span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># use example_selector instead of examples</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    prefix<span class="token operator">=</span>prefix<span class="token punctuation">,</span>
    suffix<span class="token operator">=</span>suffix<span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"userInput"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    example_separator<span class="token operator">=</span><span class="token string">"\n"</span>
<span class="token punctuation">)</span>

query <span class="token operator">=</span> <span class="token string">"What is a house?"</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>new_prompt_template<span class="token punctuation">.</span>format<span class="token punctuation">(</span>userInput<span class="token operator">=</span>query<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># print(llm(new_prompt_template.format(userInput=query)))</span>

<span class="token comment" spellcheck="true"># %% UI</span>
<span class="token comment" spellcheck="true"># %% 页面基本配置</span>
st<span class="token punctuation">.</span>set_page_config<span class="token punctuation">(</span>
    page_title<span class="token operator">=</span><span class="token string">'Marketing Tool'</span><span class="token punctuation">,</span>
    page_icon<span class="token operator">=</span><span class="token string">'✔'</span><span class="token punctuation">,</span>
    layout<span class="token operator">=</span><span class="token string">'centered'</span><span class="token punctuation">,</span>
    initial_sidebar_state<span class="token operator">=</span><span class="token string">'collapsed'</span>
<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 页面头部显示内容</span>
st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">"Hey, How can I help you?"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建 text area</span>
form_input <span class="token operator">=</span> st<span class="token punctuation">.</span>text_area<span class="token punctuation">(</span><span class="token string">'Enter text'</span><span class="token punctuation">,</span> height<span class="token operator">=</span><span class="token number">275</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建单选框</span>
tasktype_option <span class="token operator">=</span> st<span class="token punctuation">.</span>selectbox<span class="token punctuation">(</span>
    <span class="token string">'Please select the action to be performed?'</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># 选项</span>
    <span class="token punctuation">(</span><span class="token string">'Write a sales copy'</span><span class="token punctuation">,</span> <span class="token string">'Create a tweet'</span><span class="token punctuation">,</span> <span class="token string">'Write a product description'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    key<span class="token operator">=</span><span class="token number">1</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建单选框</span>
age_option <span class="token operator">=</span> st<span class="token punctuation">.</span>selectbox<span class="token punctuation">(</span>
    <span class="token string">'For which age group?'</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># 选项</span>
    <span class="token punctuation">(</span><span class="token string">'Kid'</span><span class="token punctuation">,</span> <span class="token string">'Adult'</span><span class="token punctuation">,</span> <span class="token string">'senior Citizen'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    key<span class="token operator">=</span><span class="token number">2</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建滑动条, 取值范围1~200, 初始值25</span>
numberOfWords <span class="token operator">=</span> st<span class="token punctuation">.</span>slider<span class="token punctuation">(</span><span class="token string">'Words limit'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建按钮</span>
submit <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Generate"</span><span class="token punctuation">)</span>
</code></pre>
<pre class=" language-shell"><code class="language-shell">streamlit run app.py --server.port 8888
</code></pre>
<p><img src="84b43eac.png"></p>
<h2 id="3-Integration-of-Frontend-amp-Backend"><a href="#3-Integration-of-Frontend-amp-Backend" class="headerlink" title="3. Integration of Frontend &amp; Backend"></a>3. Integration of Frontend &amp; Backend</h2><pre class=" language-dotenv"><code class="language-dotenv"># OPENAI_API_KEY="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"
OPENAI_API_KEY="sk-Qg2sQRe2BTRDkjXCAaCa243017994a8aBf2e5bC26aE8Af99"
OPENAI_API_BASE="https://oneapi.xty.app/v1"
</code></pre>
<p>what is a laptop?</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st
<span class="token comment" spellcheck="true"># from langchain_community.llms import OpenAI</span>
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate
<span class="token comment" spellcheck="true"># from langchain import FewShotPromptTemplate</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> FewShotPromptTemplate
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts<span class="token punctuation">.</span>example_selector <span class="token keyword">import</span> LengthBasedExampleSelector
<span class="token keyword">from</span> dotenv <span class="token keyword">import</span> load_dotenv

load_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span>

llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">)</span>

examples <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What is a mobile?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games, videos, and talking pictures, but be careful, it can turn grown-ups into screen-time monsters too!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What are your dreams?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"My dreams are like colorful adventures, where I become a superhero and save the day! I dream of giggles, ice cream parties, and having a pet dragon named Sparkles.."</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">" What are your ambitions?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"I want to be a super funny comedian, spreading laughter everywhere I go! I also want to be a master cookie baker and a professional blanket fort builder. Being mischievous and sweet is just my bonus superpower!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What happens when you get sick?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"When I get sick, it's like a sneaky monster visits. I feel tired, sniffly, and need lots of cuddles. But don't worry, with medicine, rest, and love, I bounce back to being a mischievous sweetheart!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"WHow much do you love your dad?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Oh, I love my dad to the moon and back, with sprinkles and unicorns on top! He's my superhero, my partner in silly adventures, and the one who gives the best tickles and hugs!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"Tell me about your friend?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"My friend is like a sunshine rainbow! We laugh, play, and have magical parties together. They always listen, share their toys, and make me feel special. Friendship is the best adventure!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What math means to you?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Math is like a puzzle game, full of numbers and shapes. It helps me count my toys, build towers, and share treats equally. It's fun and makes my brain sparkle!"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
        <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What is your fear?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Sometimes I'm scared of thunderstorms and monsters under my bed. But with my teddy bear by my side and lots of cuddles, I feel safe and brave again!"</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># %% UI</span>
<span class="token comment" spellcheck="true"># %% 页面基本配置</span>
st<span class="token punctuation">.</span>set_page_config<span class="token punctuation">(</span>
    page_title<span class="token operator">=</span><span class="token string">'Marketing Tool'</span><span class="token punctuation">,</span>
    page_icon<span class="token operator">=</span><span class="token string">':robot:'</span><span class="token punctuation">,</span>
    layout<span class="token operator">=</span><span class="token string">'centered'</span><span class="token punctuation">,</span>
    initial_sidebar_state<span class="token operator">=</span><span class="token string">'collapsed'</span>
<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 页面头部显示内容</span>
st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">"Hey, How can I help you?"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建 text area</span>
form_input <span class="token operator">=</span> st<span class="token punctuation">.</span>text_area<span class="token punctuation">(</span><span class="token string">'Enter text'</span><span class="token punctuation">,</span> height<span class="token operator">=</span><span class="token number">275</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建单选框</span>
tasktype_option <span class="token operator">=</span> st<span class="token punctuation">.</span>selectbox<span class="token punctuation">(</span>
    <span class="token string">'Please select the action to be performed?'</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># 选项</span>
    <span class="token punctuation">(</span><span class="token string">'Write a sales copy'</span><span class="token punctuation">,</span> <span class="token string">'Create a tweet'</span><span class="token punctuation">,</span> <span class="token string">'Write a product description'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    key<span class="token operator">=</span><span class="token number">1</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建单选框</span>
age_option <span class="token operator">=</span> st<span class="token punctuation">.</span>selectbox<span class="token punctuation">(</span>
    <span class="token string">'For which age group?'</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># 选项</span>
    <span class="token punctuation">(</span><span class="token string">'Kid'</span><span class="token punctuation">,</span> <span class="token string">'Adult'</span><span class="token punctuation">,</span> <span class="token string">'senior Citizen'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    key<span class="token operator">=</span><span class="token number">2</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建滑动条, 取值范围1~200, 初始值25</span>
numberOfWords <span class="token operator">=</span> st<span class="token punctuation">.</span>slider<span class="token punctuation">(</span><span class="token string">'Words limit'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建按钮</span>
submit <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Generate"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% backend</span>
example_template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
Question: {query}
Response: {answer}
"""</span>

example_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"query"</span><span class="token punctuation">,</span> <span class="token string">"answer"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    template<span class="token operator">=</span>example_template
<span class="token punctuation">)</span>

prefix <span class="token operator">=</span> <span class="token triple-quoted-string string">"""You are a {template_age_option}, and {template_tasktype_option}: 
Here are some examples: 
"""</span>

suffix <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
Question: {template_userInput}
Response: """</span>

example_selector <span class="token operator">=</span> LengthBasedExampleSelector<span class="token punctuation">(</span>
    examples<span class="token operator">=</span>examples<span class="token punctuation">,</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    max_length<span class="token operator">=</span><span class="token number">200</span>
<span class="token punctuation">)</span>

new_prompt_template <span class="token operator">=</span> FewShotPromptTemplate<span class="token punctuation">(</span>
    example_selector<span class="token operator">=</span>example_selector<span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># use example_selector instead of examples</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    prefix<span class="token operator">=</span>prefix<span class="token punctuation">,</span>
    suffix<span class="token operator">=</span>suffix<span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"template_userInput"</span><span class="token punctuation">,</span> <span class="token string">'template_age_option'</span><span class="token punctuation">,</span> <span class="token string">'template_tasktype_option'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    example_separator<span class="token operator">=</span><span class="token string">"\n"</span>
<span class="token punctuation">)</span>

query <span class="token operator">=</span> form_input

<span class="token comment" spellcheck="true"># print(new_prompt_template.format(</span>
<span class="token comment" spellcheck="true">#     template_userInput=query,</span>
<span class="token comment" spellcheck="true">#     template_age_option=age_option,</span>
<span class="token comment" spellcheck="true">#     template_tasktype_option=tasktype_option</span>
<span class="token comment" spellcheck="true"># ))</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>llm<span class="token punctuation">(</span>new_prompt_template<span class="token punctuation">.</span>format<span class="token punctuation">(</span>
    template_userInput<span class="token operator">=</span>query<span class="token punctuation">,</span>
    template_age_option<span class="token operator">=</span>age_option<span class="token punctuation">,</span>
    template_tasktype_option<span class="token operator">=</span>tasktype_option
<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="4-Modularization-of-Code"><a href="#4-Modularization-of-Code" class="headerlink" title="4. Modularization of Code"></a>4. Modularization of Code</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st
<span class="token comment" spellcheck="true"># from langchain_community.llms import OpenAI</span>
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate
<span class="token comment" spellcheck="true"># from langchain import FewShotPromptTemplate</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> FewShotPromptTemplate
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts<span class="token punctuation">.</span>example_selector <span class="token keyword">import</span> LengthBasedExampleSelector
<span class="token keyword">from</span> dotenv <span class="token keyword">import</span> load_dotenv

load_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% UI</span>
<span class="token comment" spellcheck="true"># %% 页面基本配置</span>
st<span class="token punctuation">.</span>set_page_config<span class="token punctuation">(</span>
    page_title<span class="token operator">=</span><span class="token string">'Marketing Tool'</span><span class="token punctuation">,</span>
    page_icon<span class="token operator">=</span><span class="token string">':robot:'</span><span class="token punctuation">,</span>
    layout<span class="token operator">=</span><span class="token string">'centered'</span><span class="token punctuation">,</span>
    initial_sidebar_state<span class="token operator">=</span><span class="token string">'collapsed'</span>
<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 页面头部显示内容</span>
st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">"Hey, How can I help you?"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建 text area</span>
form_input <span class="token operator">=</span> st<span class="token punctuation">.</span>text_area<span class="token punctuation">(</span><span class="token string">'Enter text'</span><span class="token punctuation">,</span> height<span class="token operator">=</span><span class="token number">275</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建单选框</span>
tasktype_option <span class="token operator">=</span> st<span class="token punctuation">.</span>selectbox<span class="token punctuation">(</span>
    <span class="token string">'Please select the action to be performed?'</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># 选项</span>
    <span class="token punctuation">(</span><span class="token string">'Write a sales copy'</span><span class="token punctuation">,</span> <span class="token string">'Create a tweet'</span><span class="token punctuation">,</span> <span class="token string">'Write a product description'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    key<span class="token operator">=</span><span class="token number">1</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建单选框</span>
age_option <span class="token operator">=</span> st<span class="token punctuation">.</span>selectbox<span class="token punctuation">(</span>
    <span class="token string">'For which age group?'</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># 选项</span>
    <span class="token punctuation">(</span><span class="token string">'Kid'</span><span class="token punctuation">,</span> <span class="token string">'Adult'</span><span class="token punctuation">,</span> <span class="token string">'senior Citizen'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    key<span class="token operator">=</span><span class="token number">2</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建滑动条, 取值范围1~200, 初始值25</span>
numberOfWords <span class="token operator">=</span> st<span class="token punctuation">.</span>slider<span class="token punctuation">(</span><span class="token string">'Words limit'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建按钮</span>
submit <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Generate"</span><span class="token punctuation">)</span>


<span class="token comment" spellcheck="true"># %% backend</span>
<span class="token keyword">def</span> <span class="token function">getLLMResponse</span><span class="token punctuation">(</span>query<span class="token punctuation">,</span> age_option<span class="token punctuation">,</span> tasktype_option<span class="token punctuation">)</span><span class="token punctuation">:</span>
    llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">)</span>

    examples <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token punctuation">{</span>
            <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What is a mobile?"</span><span class="token punctuation">,</span>
            <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games, videos, and talking pictures, but be careful, it can turn grown-ups into screen-time monsters too!"</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
            <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What are your dreams?"</span><span class="token punctuation">,</span>
            <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"My dreams are like colorful adventures, where I become a superhero and save the day! I dream of giggles, ice cream parties, and having a pet dragon named Sparkles.."</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
            <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">" What are your ambitions?"</span><span class="token punctuation">,</span>
            <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"I want to be a super funny comedian, spreading laughter everywhere I go! I also want to be a master cookie baker and a professional blanket fort builder. Being mischievous and sweet is just my bonus superpower!"</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
            <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What happens when you get sick?"</span><span class="token punctuation">,</span>
            <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"When I get sick, it's like a sneaky monster visits. I feel tired, sniffly, and need lots of cuddles. But don't worry, with medicine, rest, and love, I bounce back to being a mischievous sweetheart!"</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
            <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"WHow much do you love your dad?"</span><span class="token punctuation">,</span>
            <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Oh, I love my dad to the moon and back, with sprinkles and unicorns on top! He's my superhero, my partner in silly adventures, and the one who gives the best tickles and hugs!"</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
            <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"Tell me about your friend?"</span><span class="token punctuation">,</span>
            <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"My friend is like a sunshine rainbow! We laugh, play, and have magical parties together. They always listen, share their toys, and make me feel special. Friendship is the best adventure!"</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
            <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What math means to you?"</span><span class="token punctuation">,</span>
            <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Math is like a puzzle game, full of numbers and shapes. It helps me count my toys, build towers, and share treats equally. It's fun and makes my brain sparkle!"</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
            <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What is your fear?"</span><span class="token punctuation">,</span>
            <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Sometimes I'm scared of thunderstorms and monsters under my bed. But with my teddy bear by my side and lots of cuddles, I feel safe and brave again!"</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">]</span>

    example_template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
    Question: {query}
    Response: {answer}
    """</span>

    example_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
        input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"query"</span><span class="token punctuation">,</span> <span class="token string">"answer"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        template<span class="token operator">=</span>example_template
    <span class="token punctuation">)</span>

    prefix <span class="token operator">=</span> <span class="token triple-quoted-string string">"""You are a {template_age_option}, and {template_tasktype_option}: 
    Here are some examples: 
    """</span>

    suffix <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
    Question: {template_userInput}
    Response: """</span>

    example_selector <span class="token operator">=</span> LengthBasedExampleSelector<span class="token punctuation">(</span>
        examples<span class="token operator">=</span>examples<span class="token punctuation">,</span>
        example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
        max_length<span class="token operator">=</span><span class="token number">200</span>
    <span class="token punctuation">)</span>

    new_prompt_template <span class="token operator">=</span> FewShotPromptTemplate<span class="token punctuation">(</span>
        example_selector<span class="token operator">=</span>example_selector<span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># use example_selector instead of examples</span>
        example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
        prefix<span class="token operator">=</span>prefix<span class="token punctuation">,</span>
        suffix<span class="token operator">=</span>suffix<span class="token punctuation">,</span>
        input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"template_userInput"</span><span class="token punctuation">,</span> <span class="token string">'template_age_option'</span><span class="token punctuation">,</span> <span class="token string">'template_tasktype_option'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        example_separator<span class="token operator">=</span><span class="token string">"\n"</span>
    <span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># print(new_prompt_template.format(</span>
    <span class="token comment" spellcheck="true">#     template_userInput=query,</span>
    <span class="token comment" spellcheck="true">#     template_age_option=age_option,</span>
    <span class="token comment" spellcheck="true">#     template_tasktype_option=tasktype_option</span>
    <span class="token comment" spellcheck="true"># ))</span>

    res <span class="token operator">=</span> llm<span class="token punctuation">(</span>new_prompt_template<span class="token punctuation">.</span>format<span class="token punctuation">(</span>
        template_userInput<span class="token operator">=</span>query<span class="token punctuation">,</span>
        template_age_option<span class="token operator">=</span>age_option<span class="token punctuation">,</span>
        template_tasktype_option<span class="token operator">=</span>tasktype_option
    <span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">)</span>

    <span class="token keyword">return</span> res


<span class="token comment" spellcheck="true"># 如果点击了按钮</span>
<span class="token keyword">if</span> submit<span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 显示到页面</span>
    st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>getLLMResponse<span class="token punctuation">(</span>form_input<span class="token punctuation">,</span> age_option<span class="token punctuation">,</span> tasktype_option<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="5-Adding-Examples-Kids-Adult-amp-Senior-Citizen"><a href="#5-Adding-Examples-Kids-Adult-amp-Senior-Citizen" class="headerlink" title="5. Adding Examples - Kids, Adult &amp; Senior Citizen"></a>5. Adding Examples - Kids, Adult &amp; Senior Citizen</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st
<span class="token comment" spellcheck="true"># from langchain_community.llms import OpenAI</span>
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate
<span class="token comment" spellcheck="true"># from langchain import FewShotPromptTemplate</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> FewShotPromptTemplate
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts<span class="token punctuation">.</span>example_selector <span class="token keyword">import</span> LengthBasedExampleSelector
<span class="token keyword">from</span> dotenv <span class="token keyword">import</span> load_dotenv

load_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% UI</span>
<span class="token comment" spellcheck="true"># %% 页面基本配置</span>
st<span class="token punctuation">.</span>set_page_config<span class="token punctuation">(</span>
    page_title<span class="token operator">=</span><span class="token string">'Marketing Tool'</span><span class="token punctuation">,</span>
    page_icon<span class="token operator">=</span><span class="token string">':robot:'</span><span class="token punctuation">,</span>
    layout<span class="token operator">=</span><span class="token string">'centered'</span><span class="token punctuation">,</span>
    initial_sidebar_state<span class="token operator">=</span><span class="token string">'collapsed'</span>
<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 页面头部显示内容</span>
st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">"Hey, How can I help you?"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建 text area</span>
form_input <span class="token operator">=</span> st<span class="token punctuation">.</span>text_area<span class="token punctuation">(</span><span class="token string">'Enter text'</span><span class="token punctuation">,</span> height<span class="token operator">=</span><span class="token number">275</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建单选框</span>
tasktype_option <span class="token operator">=</span> st<span class="token punctuation">.</span>selectbox<span class="token punctuation">(</span>
    <span class="token string">'Please select the action to be performed?'</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># 选项</span>
    <span class="token punctuation">(</span><span class="token string">'Write a sales copy'</span><span class="token punctuation">,</span> <span class="token string">'Create a tweet'</span><span class="token punctuation">,</span> <span class="token string">'Write a product description'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    key<span class="token operator">=</span><span class="token number">1</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建单选框</span>
age_option <span class="token operator">=</span> st<span class="token punctuation">.</span>selectbox<span class="token punctuation">(</span>
    <span class="token string">'For which age group?'</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># 选项</span>
    <span class="token punctuation">(</span><span class="token string">'Kid'</span><span class="token punctuation">,</span> <span class="token string">'Adult'</span><span class="token punctuation">,</span> <span class="token string">'Senior Citizen'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    key<span class="token operator">=</span><span class="token number">2</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建滑动条, 取值范围1~200, 初始值25</span>
numberOfWords <span class="token operator">=</span> st<span class="token punctuation">.</span>slider<span class="token punctuation">(</span><span class="token string">'Words limit'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建按钮</span>
submit <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Generate"</span><span class="token punctuation">)</span>


<span class="token comment" spellcheck="true"># %% backend</span>
<span class="token keyword">def</span> <span class="token function">getLLMResponse</span><span class="token punctuation">(</span>query<span class="token punctuation">,</span> age_option<span class="token punctuation">,</span> tasktype_option<span class="token punctuation">)</span><span class="token punctuation">:</span>
    llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> age_option <span class="token operator">==</span> <span class="token string">"Kid"</span><span class="token punctuation">:</span>

        examples <span class="token operator">=</span> <span class="token punctuation">[</span>
            <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What is a mobile?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games, videos, and talking pictures, but be careful, it can turn grown-ups into screen-time monsters too!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What are your dreams?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"My dreams are like colorful adventures, where I become a superhero and save the day! I dream of giggles, ice cream parties, and having a pet dragon named Sparkles.."</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">" What are your ambitions?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"I want to be a super funny comedian, spreading laughter everywhere I go! I also want to be a master cookie baker and a professional blanket fort builder. Being mischievous and sweet is just my bonus superpower!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What happens when you get sick?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"When I get sick, it's like a sneaky monster visits. I feel tired, sniffly, and need lots of cuddles. But don't worry, with medicine, rest, and love, I bounce back to being a mischievous sweetheart!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"WHow much do you love your dad?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Oh, I love my dad to the moon and back, with sprinkles and unicorns on top! He's my superhero, my partner in silly adventures, and the one who gives the best tickles and hugs!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"Tell me about your friend?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"My friend is like a sunshine rainbow! We laugh, play, and have magical parties together. They always listen, share their toys, and make me feel special. Friendship is the best adventure!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What math means to you?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Math is like a puzzle game, full of numbers and shapes. It helps me count my toys, build towers, and share treats equally. It's fun and makes my brain sparkle!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What is your fear?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Sometimes I'm scared of thunderstorms and monsters under my bed. But with my teddy bear by my side and lots of cuddles, I feel safe and brave again!"</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">]</span>

    <span class="token keyword">elif</span> age_option <span class="token operator">==</span> <span class="token string">"Adult"</span><span class="token punctuation">:</span>
        examples <span class="token operator">=</span> <span class="token punctuation">[</span>
            <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What is a mobile?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games, videos, and talking pictures, but be careful, it can turn grown-ups into screen-time monsters too!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What are your dreams?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"My dreams are like colorful adventures, where I become a superhero and save the day! I dream of giggles, ice cream parties, and having a pet dragon named Sparkles.."</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">" What are your ambitions?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"I want to be a super funny comedian, spreading laughter everywhere I go! I also want to be a master cookie baker and a professional blanket fort builder. Being mischievous and sweet is just my bonus superpower!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What happens when you get sick?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"When I get sick, it's like a sneaky monster visits. I feel tired, sniffly, and need lots of cuddles. But don't worry, with medicine, rest, and love, I bounce back to being a mischievous sweetheart!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"WHow much do you love your dad?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Oh, I love my dad to the moon and back, with sprinkles and unicorns on top! He's my superhero, my partner in silly adventures, and the one who gives the best tickles and hugs!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"Tell me about your friend?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"My friend is like a sunshine rainbow! We laugh, play, and have magical parties together. They always listen, share their toys, and make me feel special. Friendship is the best adventure!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What math means to you?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Math is like a puzzle game, full of numbers and shapes. It helps me count my toys, build towers, and share treats equally. It's fun and makes my brain sparkle!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What is your fear?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Sometimes I'm scared of thunderstorms and monsters under my bed. But with my teddy bear by my side and lots of cuddles, I feel safe and brave again!"</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">]</span>

    <span class="token keyword">elif</span> age_option <span class="token operator">==</span> <span class="token string">"Senior Citizen"</span><span class="token punctuation">:</span>
        examples <span class="token operator">=</span> <span class="token punctuation">[</span>
            <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What is a mobile?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"A mobile is a magical device that fits in your pocket, like a mini-enchanted playground. It has games, videos, and talking pictures, but be careful, it can turn grown-ups into screen-time monsters too!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What are your dreams?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"My dreams are like colorful adventures, where I become a superhero and save the day! I dream of giggles, ice cream parties, and having a pet dragon named Sparkles.."</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">" What are your ambitions?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"I want to be a super funny comedian, spreading laughter everywhere I go! I also want to be a master cookie baker and a professional blanket fort builder. Being mischievous and sweet is just my bonus superpower!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What happens when you get sick?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"When I get sick, it's like a sneaky monster visits. I feel tired, sniffly, and need lots of cuddles. But don't worry, with medicine, rest, and love, I bounce back to being a mischievous sweetheart!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"WHow much do you love your dad?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Oh, I love my dad to the moon and back, with sprinkles and unicorns on top! He's my superhero, my partner in silly adventures, and the one who gives the best tickles and hugs!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"Tell me about your friend?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"My friend is like a sunshine rainbow! We laugh, play, and have magical parties together. They always listen, share their toys, and make me feel special. Friendship is the best adventure!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What math means to you?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Math is like a puzzle game, full of numbers and shapes. It helps me count my toys, build towers, and share treats equally. It's fun and makes my brain sparkle!"</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>
                <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"What is your fear?"</span><span class="token punctuation">,</span>
                <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token string">"Sometimes I'm scared of thunderstorms and monsters under my bed. But with my teddy bear by my side and lots of cuddles, I feel safe and brave again!"</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">]</span>

    example_template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
    Question: {query}
    Response: {answer}
    """</span>

    example_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
        input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"query"</span><span class="token punctuation">,</span> <span class="token string">"answer"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        template<span class="token operator">=</span>example_template
    <span class="token punctuation">)</span>

    prefix <span class="token operator">=</span> <span class="token triple-quoted-string string">"""You are a {template_age_option}, and {template_tasktype_option}: 
    Here are some examples: 
    """</span>

    suffix <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
    Question: {template_userInput}
    Response: """</span>

    example_selector <span class="token operator">=</span> LengthBasedExampleSelector<span class="token punctuation">(</span>
        examples<span class="token operator">=</span>examples<span class="token punctuation">,</span>
        example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
        max_length<span class="token operator">=</span><span class="token number">200</span>
    <span class="token punctuation">)</span>

    new_prompt_template <span class="token operator">=</span> FewShotPromptTemplate<span class="token punctuation">(</span>
        example_selector<span class="token operator">=</span>example_selector<span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># use example_selector instead of examples</span>
        example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
        prefix<span class="token operator">=</span>prefix<span class="token punctuation">,</span>
        suffix<span class="token operator">=</span>suffix<span class="token punctuation">,</span>
        input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"template_userInput"</span><span class="token punctuation">,</span> <span class="token string">'template_age_option'</span><span class="token punctuation">,</span> <span class="token string">'template_tasktype_option'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        example_separator<span class="token operator">=</span><span class="token string">"\n"</span>
    <span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># print(new_prompt_template.format(</span>
    <span class="token comment" spellcheck="true">#     template_userInput=query,</span>
    <span class="token comment" spellcheck="true">#     template_age_option=age_option,</span>
    <span class="token comment" spellcheck="true">#     template_tasktype_option=tasktype_option</span>
    <span class="token comment" spellcheck="true"># ))</span>

    res <span class="token operator">=</span> llm<span class="token punctuation">(</span>new_prompt_template<span class="token punctuation">.</span>format<span class="token punctuation">(</span>
        template_userInput<span class="token operator">=</span>query<span class="token punctuation">,</span>
        template_age_option<span class="token operator">=</span>age_option<span class="token punctuation">,</span>
        template_tasktype_option<span class="token operator">=</span>tasktype_option
    <span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">)</span>

    <span class="token keyword">return</span> res


<span class="token comment" spellcheck="true"># 如果点击了按钮</span>
<span class="token keyword">if</span> submit<span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 显示到页面</span>
    st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>getLLMResponse<span class="token punctuation">(</span>form_input<span class="token punctuation">,</span> age_option<span class="token punctuation">,</span> tasktype_option<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h1 id="11-Langchain-Memory-Module-Concept"><a href="#11-Langchain-Memory-Module-Concept" class="headerlink" title="11. Langchain - Memory Module Concept"></a>11. Langchain - Memory Module Concept</h1><h2 id="1-Importance-of-Memory-in-LLM-powered-Apps"><a href="#1-Importance-of-Memory-in-LLM-powered-Apps" class="headerlink" title="1. Importance of Memory in LLM powered Apps"></a>1. Importance of Memory in LLM powered Apps</h2><p><img src="c6061782.png"><br>多种类型的Memory</p>
<p><img src="eed671a6.png"></p>
<pre class=" language-shell"><code class="language-shell">pip install langchain openai tiktoken
</code></pre>
<p><img src="d152590a.png"><img src="fd36c9da.png"><img src="e5633ffd.png"></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %% import</span>
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> LLMChain<span class="token punctuation">,</span> ConversationChain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>conversation<span class="token punctuation">.</span>memory <span class="token keyword">import</span> <span class="token punctuation">(</span>
    ConversationBufferMemory<span class="token punctuation">,</span> ConversationSummaryMemory<span class="token punctuation">,</span> ConversationBufferWindowMemory
<span class="token punctuation">)</span>
<span class="token keyword">import</span> tiktoken
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>memory <span class="token keyword">import</span> ConversationTokenBufferMemory

<span class="token comment" spellcheck="true"># %%</span>
<span class="token triple-quoted-string string">'''
Tiktoken,developed by OpenAl,is a tool used for text tokenization.
Tokenization involves dividing a text into smaller units,such as letters or words.Tiktoken allows you to count tokens and estimate the cost of using the OpenAl
APl,which is based on token usage.It utilizes byte pair encoding (BPE),a compression algorithm that replaces frequently occurring pairs of bytes with a single
byte.
In summary,Tiktoken helps with efficient text processing,token counting,and cost estimation for using OpenAl's API.
'''</span>
<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_KEY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"sk-dsO3Z1fD9nrDFq1SF7C35437A2F74c1aA769F006A57eA65f"</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_BASE'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"https://oneapi.xty.app/v1"</span>

<span class="token comment" spellcheck="true"># %% model</span>
<span class="token comment" spellcheck="true"># llm = OpenAI(temperature=0, model_name='gpt-4')</span>
llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
<span class="token triple-quoted-string string">'''
What is a Memory?
Chains and Agents operate as stateless,treating each query independently.However,in applications like chatbots,its crucial to remember past interactions.
The concept of "Memory"serves that purpose.
'''</span>

<span class="token comment" spellcheck="true"># %% Different Types Of Memories</span>
<span class="token triple-quoted-string string">'''
Imagine you're having a conversation with someone, and you want to remember what you've discussed so far.
The ConversationBufferMemory does exactly that in a chatbot or similar system. It keeps a record,or "buffer,"of the past parts of the conversation.

This buffer is an essential part of the context,which helps the chatbot generate better responses.The unique thing about this memory is that it stores the
previous conversation exactly as they were,without any changes.

It preserves the raw form of the conversation,allowing the chatbot to refer back to specific parts accurately.In summary,the
ConversationBufferMemory helps the chatbot remember the conversation history,enhancing the overall conversational experience.

Pros of ConversationBufferMemory:
    *Complete conversation history:It retains the entire conversation history,ensuring comprehensive context for the chatbot.
    Accurate references:By storing conversation excerpts in their original form,it enables precise referencing to past interactions,enhancing accuracy.
    "Contextual understanding:The preserved raw form of the conversation helps the chatbot maintain a deep understanding of the ongoing dialogue.
    *Enhanced responses:with access to the complete conversation history,the chatbot can generate more relevant and coherent responses.

Cons of ConversationBufferMemory
    *Increased memory usage:Storing the entire conversation history consumes memory resources,potentially leading to memor
    y constraints.
    "Potential performance impact:Large conversation buffers may slow down processing and response times,affecting the ove
    rall system performance.
    Liniited soibinisy As the conversation grows,the memory requirements and processing load may become impractical for
    extremely long conversations.
    *Privacy concerns:Storing the entire conversation history raises privacy considerations,as sensitive or personal infor
    mation may be retained in the buffer.
'''</span>
conversation <span class="token operator">=</span> ConversationChain<span class="token punctuation">(</span>
    llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># ConversationBufferMemory，它只是 ChatMessageHistory 的一个包装器，用于提取变量中的消息</span>
    memory<span class="token operator">=</span>ConversationBufferMemory<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># %%</span>
<span class="token comment" spellcheck="true"># Let's have a look at the prompt template that is being sent to the LLM</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>prompt<span class="token punctuation">.</span>template<span class="token punctuation">)</span>

conversation<span class="token punctuation">(</span><span class="token string">"Good morning AI"</span><span class="token punctuation">)</span>
conversation<span class="token punctuation">(</span><span class="token string">"My name is Steve"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 如果名称小写, ai可能不认</span>
conversation<span class="token punctuation">(</span><span class="token string">"My sister is Sandy"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"I stay in hyderabad, India"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>memory<span class="token punctuation">.</span>buffer<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"What is my name?"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"Who is my sister?"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="2-Different-Types-of-Memory"><a href="#2-Different-Types-of-Memory" class="headerlink" title="2. Different Types of Memory"></a>2. Different Types of Memory</h2><p>BufferWindow由我们指定缓存k个上下文消息, 但是我们常常不能知道多少是合适的</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %% import</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> ConversationChain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>conversation<span class="token punctuation">.</span>memory <span class="token keyword">import</span> <span class="token punctuation">(</span>
    ConversationBufferMemory<span class="token punctuation">,</span> ConversationSummaryMemory<span class="token punctuation">,</span> ConversationBufferWindowMemory
<span class="token punctuation">)</span>
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAI

<span class="token comment" spellcheck="true"># %%</span>
<span class="token triple-quoted-string string">'''
Tiktoken,developed by OpenAl,is a tool used for text tokenization.
Tokenization involves dividing a text into smaller units,such as letters or words.Tiktoken allows you to count tokens and estimate the cost of using the OpenAl
APl,which is based on token usage.It utilizes byte pair encoding (BPE),a compression algorithm that replaces frequently occurring pairs of bytes with a single
byte.
In summary,Tiktoken helps with efficient text processing,token counting,and cost estimation for using OpenAl's API.
'''</span>
<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_KEY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"sk-dsO3Z1fD9nrDFq1SF7C35437A2F74c1aA769F006A57eA65f"</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_BASE'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"https://oneapi.xty.app/v1"</span>

<span class="token comment" spellcheck="true"># %% model</span>
<span class="token comment" spellcheck="true"># llm = OpenAI(temperature=0, model_name='gpt-4')</span>
llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
<span class="token triple-quoted-string string">'''
What is a Memory?
Chains and Agents operate as stateless,treating each query independently.However,in applications like chatbots,its crucial to remember past interactions.
The concept of "Memory"serves that purpose.
'''</span>

<span class="token comment" spellcheck="true"># %% Different Types Of Memories</span>
<span class="token comment" spellcheck="true"># ConversationBufferMemory</span>
<span class="token triple-quoted-string string">'''
Imagine you're having a conversation with someone, and you want to remember what you've discussed so far.
The ConversationBufferMemory does exactly that in a chatbot or similar system. It keeps a record,or "buffer,"of the past parts of the conversation.

This buffer is an essential part of the context,which helps the chatbot generate better responses.The unique thing about this memory is that it stores the
previous conversation exactly as they were,without any changes.

It preserves the raw form of the conversation,allowing the chatbot to refer back to specific parts accurately.In summary,the
ConversationBufferMemory helps the chatbot remember the conversation history,enhancing the overall conversational experience.

Pros of ConversationBufferMemory:
    *Complete conversation history:It retains the entire conversation history,ensuring comprehensive context for the chatbot.
    Accurate references:By storing conversation excerpts in their original form,it enables precise referencing to past interactions,enhancing accuracy.
    "Contextual understanding:The preserved raw form of the conversation helps the chatbot maintain a deep understanding of the ongoing dialogue.
    *Enhanced responses:with access to the complete conversation history,the chatbot can generate more relevant and coherent responses.

Cons of ConversationBufferMemory
    *Increased memory usage:Storing the entire conversation history consumes memory resources,potentially leading to memor
    y constraints.
    "Potential performance impact:Large conversation buffers may slow down processing and response times,affecting the ove
    rall system performance.
    Liniited soibinisy As the conversation grows,the memory requirements and processing load may become impractical for
    extremely long conversations.
    *Privacy concerns:Storing the entire conversation history raises privacy considerations,as sensitive or personal infor
    mation may be retained in the buffer.
'''</span>
conversation <span class="token operator">=</span> ConversationChain<span class="token punctuation">(</span>
    llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># ConversationBufferMemory，它只是 ChatMessageHistory 的一个包装器，用于提取变量中的消息</span>
    memory<span class="token operator">=</span>ConversationBufferMemory<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># %%</span>
<span class="token comment" spellcheck="true"># Let's have a look at the prompt template that is being sent to the LLM</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>prompt<span class="token punctuation">.</span>template<span class="token punctuation">)</span>

conversation<span class="token punctuation">(</span><span class="token string">"Good morning AI"</span><span class="token punctuation">)</span>
conversation<span class="token punctuation">(</span><span class="token string">"My name is Steve"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 如果名称小写, ai可能不认</span>
conversation<span class="token punctuation">(</span><span class="token string">"My sister is Sandy"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"I stay in hyderabad, India"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>memory<span class="token punctuation">.</span>buffer<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"What is my name?"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"Who is my sister?"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
<span class="token triple-quoted-string string">'''
ConversationBufferWindowMemory

Imagine you have a limited space in your memory to remember recent conversations.

The ConversationBufferWindowMemory is like having a short-term memory that only keeps track of the most recent interactions.It intentionally
drops the oldest ones to make room for new ones.

This helps manage the memory load and reduces the number of tokens used.The important thing is that it still keeps the latest parts of the conversation in
their original form,without any modifications.
So,it retains the most recent information for the chatbot to refer to,ensuring a more efficient and up-to-date conversation experience.

Pros of ConversationBufferWindowMemory:

    *Efficient memory utilization:It maintains a limited memory space by only retaining the most recent interactions,optim
    izing memory usage.
    *Reduced token count:Dropping the oldest interactions helps to keep the token count low,preventing potential token lim
    itations.
    *Unmodified context retention:The latest parts of the conversation are preserved in their original form,ensuring accur
    ate references and contextual understanding.
    *Up-to-date conversations:By focusing on recent interactions,it allows the chatbot to stay current and provide more re
    levant responses.

Cons of ConversationBufferWindowMemory:
    *Limited historical context:since older interactions are intentionally dropped,the chatbot loses access to the complet
    e conversation history,potentially impacting long-term context and accuracy.
    "Loss of older information:Valuable insights or details from earlier interactions are not retained,limiting the chatbo
    t's ability to refer back to past conversations.
    *Reduced depth of understanding:without the full conversation history,the chatbot may have a shallower understanding o
    f the user's context and needs.
    *Potential loss of context relevance:Important information or context from older interactions may be disregarded,affec
    ting the chatbot's ability to provide comprehensive responses in certain scenarios.
'''</span>
<span class="token comment" spellcheck="true"># ConversationBufferWindowMemory</span>
conversation <span class="token operator">=</span> ConversationChain<span class="token punctuation">(</span>
    llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># ConversationBufferWindowMemory保留了对话随时间推移的交互列表。</span>
    <span class="token comment" spellcheck="true"># 它仅使用最后K个交互。这可以用于保持最近交互的滑动窗口，以便缓冲区不会过大。</span>
    memory<span class="token operator">=</span>ConversationBufferWindowMemory<span class="token punctuation">(</span>k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
<span class="token comment" spellcheck="true"># Let's have a look at the prompt template that is being sent to the LLM</span>
<span class="token triple-quoted-string string">'''
Current conversation:
{history}
Human: {input}
AI:
'''</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>prompt<span class="token punctuation">.</span>template<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># predict对话会被加到历史, 之前我们是手动添加的 conversation("")</span>
conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"Good morning AI"</span><span class="token punctuation">)</span>
conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"My name is Steve"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 如果名称小写, ai可能不认</span>
conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"My sister is Sandy"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 我们设置k=1, 所以只有一条</span>
<span class="token triple-quoted-string string">'''
memory:
    Human: My sister is Sandy
'''</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'memory:\n\t{conversation.memory.buffer}'</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># Your sister is Sandy.</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"Who is my sister?"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># Your name is not specified in my database.</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"What is my name?"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% ConversationSummaryMemory -> 记录的是对话摘要</span>
<span class="token triple-quoted-string string">'''
With the ConversationBufferMemory,the length of the conversation keeps increasing,which can become a problem if it becomes too large for our LLM to
handle.

To overcome this,we introduce ConversationSummaryMemory.It keeps a summary of our past conversation snippets as our history.But how does it
summarize?Here comes the LLM to the rescue!The LLM (Language Model)helps in condensing or summarizing the conversation,capturing the key
information.

So,instead of storing the entire conversation,we store a summarized version.This helps manage the token count and allows the LLM to process the
conversation effectively.In summary,ConversationSummaryMemory keeps a condensed version of previous conversations using the power of LLM
summarization.

Pros of ConversationSummaryMemory:
    *Efficient memory management-It keeps the conversation history in a summarized form,reducing the memory load.
    *Improved processing-By condensing the conversation snippets,it makes it easier for the language model to process and
    generate responses.
    *Avoiding maxing out limitations-It helps prevent exceeding the token count limit,ensuring the prompt remains within t
    he processing capacity of the model.
    "Retains important information-The summary captures the essential aspects of previous interactions,allowing for releva
    nt context to be maintained.
    
Cons of ConversationSummaryMemory:
    *Potential loss of detail:since the conversation is summarized,some specific details or nuances from earlier interacti
    ons might be omitted.
    *Reliance on summarization quality:The accuracy and effectiveness of the summarization process depend on the language m
    odel's capability,which might introduce potential errors or misinterpretations.
    "Limited historical context:Due to summarization,the model's access to the complete conversation history may be limite
    d,potentially impacting the depth of understanding.
    *Reduced granularity:The summarized form may lack the fine-grained information present in the original conversation,po
    tentially affecting the accuracy of responses in certain scenarios.
'''</span>

conversation <span class="token operator">=</span> ConversationChain<span class="token punctuation">(</span>
    llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    memory<span class="token operator">=</span>ConversationSummaryMemory<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
<span class="token comment" spellcheck="true"># Let's have a look at the prompt template that is being sent to the LLM</span>
<span class="token triple-quoted-string string">'''
template:
    The following is a friendly conversation between a human and an AI. 
    The AI is talkative and provides lots of specific details from its context. 
    If the AI does not know the answer to a question, it truthfully says it does not know.
'''</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'template:\n\t{conversation.prompt.template}'</span><span class="token punctuation">)</span>

conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"Good morning AI"</span><span class="token punctuation">)</span>
conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"My name is Steve"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 如果名称小写, ai可能不认</span>
conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"My sister is Sandy"</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">'''
memory:
    
The human greets the AI and the AI responds with the current time and conditions in its server room. 
The AI then asks how it can assist the human, addressing them by name. 
The human reveals their sister's name and the AI greets her by name, providing the current time and conditions in the server room. 
The AI then asks how it can assist the human today.
'''</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'memory:\n\t{conversation.memory.buffer}'</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># Your name is [insert name here]. How can I assist you today?</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"What is my name?"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% ConversationTokenBufferMemory</span>
<span class="token keyword">import</span> tiktoken
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>memory <span class="token keyword">import</span> ConversationTokenBufferMemory

<span class="token triple-quoted-string string">'''
ConversationTokenBufferMemory is a memory mechanism that stores recent interactions in a buffer within the system's memory.
Unlike other methods that rely on the number of interactions,this memory system determines when to clear or flush interactions based on the length of tokens
used.

Tokens are units of text,like words or characters,and the buffer is cleared when the token count exceeds a certain threshold.By using token length as a
criterion,the memory system ensures that the buffer remains manageable in terms of memory usage.
This approach helps maintain efficient memory management and enables the system to handle conversations of varying lengths effectively.

&lt;font color="blue">
    &lt;b>Pros of ConversationTokenBufferMemory:&lt;/b>

    *Efficient memory management: By using token length instead of the number of interactions, the memory system optimizes memory usage and prevents excessive memory consumption.
    *Flexible buffer size: The system adapts to conversations of varying lengths, ensuring that the buffer remains manageable and scalable.
    *Accurate threshold determination: Flushing interactions based on token count provides a more precise measure of memory usage, resulting in a better balance between memory efficiency and retaining relevant context.
    *Improved system performance: With efficient memory utilization, the overall performance of the system, including response times and processing speed, can be enhanced.
    
&lt;b>Cons of ConversationTokenBufferMemory:&lt;/b>

    *Potential loss of context: Flushing interactions based on token length may result in the removal of earlier interactions that could contain important context or information, potentially affecting the accuracy of responses.
    *Complexity in threshold setting: Determining the appropriate token count threshold for flushing interactions may require careful consideration and experimentation to find the optimal balance between memory usage and context retention.
    *Difficulty in long-term context retention: Due to the dynamic nature of token-based flushing, retaining long-term context in the conversation may pose challenges as older interactions are more likely to be removed from the buffer.
    *Impact on response quality: In situations where high-context conversations are required, the token-based flushing approach may lead to a reduction in the depth of understanding and the quality of responses.
&lt;font>
'''</span>

conversation <span class="token operator">=</span> ConversationChain<span class="token punctuation">(</span>
    llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># ConversationTokenBufferMemory 会在内存中保留最近的对话内容，并使用token长度而不是对话数量来决定何时刷新对话。</span>
    memory<span class="token operator">=</span>ConversationTokenBufferMemory<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> max_token_limit<span class="token operator">=</span><span class="token number">60</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %%</span>
<span class="token comment" spellcheck="true"># Let's have a look at the prompt template that is being sent to the LLM</span>
<span class="token triple-quoted-string string">'''
template:
The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.

Current conversation:
{history}
Human: {input}
AI: 
'''</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'template:\n\t{conversation.prompt.template}'</span><span class="token punctuation">)</span>

conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"Good morning AI"</span><span class="token punctuation">)</span>
conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"My name is Steve"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 如果名称小写, ai可能不认</span>
conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"My sister is Sandy"</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">'''
memory:
    Human: My sister is Sandy 
'''</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'memory:\n\t{conversation.memory.buffer}'</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># Your name is Steve. Did you forget?</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"What is my name?"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h1 id="12-Project-5-ChatGPT-Clone-with-Summarization-Option"><a href="#12-Project-5-ChatGPT-Clone-with-Summarization-Option" class="headerlink" title="12. Project #5 - ChatGPT Clone with Summarization Option"></a>12. Project #5 - ChatGPT Clone with Summarization Option</h1><h2 id="1-ChatGPT-Clone-Demo"><a href="#1-ChatGPT-Clone-Demo" class="headerlink" title="1. ChatGPT Clone Demo"></a>1. ChatGPT Clone Demo</h2><p><img src="596e2706.png"><img src="cfaa706f.png"><img src="caaa37d4.png"></p>
<h2 id="2-Setting-up-the-Project"><a href="#2-Setting-up-the-Project" class="headerlink" title="2. Setting up the Project"></a>2. Setting up the Project</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %% import</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> ConversationChain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>conversation<span class="token punctuation">.</span>memory <span class="token keyword">import</span> <span class="token punctuation">(</span>
    ConversationBufferMemory<span class="token punctuation">,</span> ConversationSummaryMemory<span class="token punctuation">,</span> ConversationBufferWindowMemory
<span class="token punctuation">)</span>
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAI

<span class="token comment" spellcheck="true"># %% env     </span>
<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_KEY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"sk-dsO3Z1fD9nrDFq1SF7C35437A2F74c1aA769F006A57eA65f"</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_BASE'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"https://oneapi.xty.app/v1"</span>

<span class="token comment" spellcheck="true"># %% model</span>
<span class="token comment" spellcheck="true"># llm = OpenAI(temperature=0, model_name='gpt-4')</span>
llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% conversation</span>
conversation <span class="token operator">=</span> ConversationChain<span class="token punctuation">(</span>
    llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># ConversationBufferMemory，它只是 ChatMessageHistory 的一个包装器，用于提取变量中的消息</span>
    memory<span class="token operator">=</span>ConversationBufferMemory<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

conversation<span class="token punctuation">(</span><span class="token string">"Good morning AI"</span><span class="token punctuation">)</span>
conversation<span class="token punctuation">(</span><span class="token string">"My name is Steve"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"I stay in hyderabad, India"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>memory<span class="token punctuation">.</span>buffer<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"Who is my sister?"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>requirements.txt</p>
<pre class=" language-text"><code class="language-text">langchain
streamlit
</code></pre>
<h2 id="3-Implementing-the-Frontend"><a href="#3-Implementing-the-Frontend" class="headerlink" title="3. Implementing the Frontend"></a>3. Implementing the Frontend</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %% import</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> ConversationChain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>conversation<span class="token punctuation">.</span>memory <span class="token keyword">import</span> <span class="token punctuation">(</span>
    ConversationBufferMemory<span class="token punctuation">,</span> ConversationSummaryMemory<span class="token punctuation">,</span> ConversationBufferWindowMemory
<span class="token punctuation">)</span>
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAI

<span class="token comment" spellcheck="true"># %%</span>
<span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st

st<span class="token punctuation">.</span>set_page_config<span class="token punctuation">(</span>page_title<span class="token operator">=</span><span class="token string">"Chat GPT Clone"</span><span class="token punctuation">,</span> page_icon<span class="token operator">=</span><span class="token string">":robot_face:"</span><span class="token punctuation">)</span>
st<span class="token punctuation">.</span>markdown<span class="token punctuation">(</span><span class="token string">"&lt;h1 style='text-align: center;'>How can I assist you? &lt;/h1>"</span><span class="token punctuation">,</span> unsafe_allow_html<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"😎"</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 侧边栏的输入框用来接收key</span>
api_key <span class="token operator">=</span> st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">"What's your API key?"</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token string">"password"</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># api_base = st.sidebar.text_input("What's your API base?", type="default")</span>
<span class="token comment" spellcheck="true"># 设计: 当我们点击这个按钮, 将会保存对话摘要</span>
summarise_button <span class="token operator">=</span> st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Summarise the conversation"</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token string">'summarise'</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 点击按钮</span>
<span class="token keyword">if</span> summarise_button<span class="token punctuation">:</span>
    summarise_placeholder <span class="token operator">=</span> st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Nice chatting with you my friend ❤:\n\n"</span> <span class="token operator">+</span> <span class="token string">"Hello friend"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% env</span>
<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_KEY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"sk-dsO3Z1fD9nrDFq1SF7C35437A2F74c1aA769F006A57eA65f"</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_BASE'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"https://oneapi.xty.app/v1"</span>

<span class="token comment" spellcheck="true"># %% model</span>
<span class="token comment" spellcheck="true"># llm = OpenAI(temperature=0, model_name='gpt-4')</span>
llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% conversation</span>
conversation <span class="token operator">=</span> ConversationChain<span class="token punctuation">(</span>
    llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># ConversationBufferMemory，它只是 ChatMessageHistory 的一个包装器，用于提取变量中的消息</span>
    memory<span class="token operator">=</span>ConversationBufferMemory<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span> 

<span class="token comment" spellcheck="true"># %%</span>
<span class="token comment" spellcheck="true"># 存放回复</span>
response_container <span class="token operator">=</span> st<span class="token punctuation">.</span>container<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 存放用户的输入</span>
container <span class="token operator">=</span> st<span class="token punctuation">.</span>container<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> container<span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># clear_on_submit 提交会清空内容</span>
    <span class="token keyword">with</span> st<span class="token punctuation">.</span>form<span class="token punctuation">(</span>key<span class="token operator">=</span><span class="token string">'my_form'</span><span class="token punctuation">,</span> clear_on_submit<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        user_input <span class="token operator">=</span> st<span class="token punctuation">.</span>text_area<span class="token punctuation">(</span><span class="token string">"Your question goes here:"</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token string">'input'</span><span class="token punctuation">,</span> height<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
        submit_btn <span class="token operator">=</span> st<span class="token punctuation">.</span>form_submit_button<span class="token punctuation">(</span><span class="token string">'Send'</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> response_container<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Response container"</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="4-Modularizing-the-Code"><a href="#4-Modularizing-the-Code" class="headerlink" title="4. Modularizing the Code"></a>4. Modularizing the Code</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">###</span>
<span class="token comment" spellcheck="true"># %% env</span>
<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_KEY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"sk-dsO3Z1fD9nrDFq1SF7C35437A2F74c1aA769F006A57eA65f"</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_BASE'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"https://oneapi.xty.app/v1"</span>


<span class="token comment" spellcheck="true"># %% model</span>
<span class="token keyword">def</span> <span class="token function">get_response</span><span class="token punctuation">(</span>userInput<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># llm = OpenAI(temperature=0, model_name='gpt-4')</span>
    llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># conversation</span>
    conversation <span class="token operator">=</span> ConversationChain<span class="token punctuation">(</span>
        llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
        verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        <span class="token comment" spellcheck="true"># ConversationBufferMemory，它只是 ChatMessageHistory 的一个包装器，用于提取变量中的消息</span>
        memory<span class="token operator">=</span>ConversationBufferMemory<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># conversation("Good morning AI")</span>
    <span class="token comment" spellcheck="true"># conversation("My name is Steve")</span>
    <span class="token comment" spellcheck="true"># print(conversation.predict(input="I stay in hyderabad, India"))</span>
    <span class="token comment" spellcheck="true"># print(conversation.memory.buffer)</span>
    res <span class="token operator">=</span> conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span>userInput<span class="token punctuation">)</span>

    <span class="token keyword">return</span> res


<span class="token comment" spellcheck="true"># %%</span>
<span class="token comment" spellcheck="true"># 存放回复</span>
response_container <span class="token operator">=</span> st<span class="token punctuation">.</span>container<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 存放用户的输入</span>
container <span class="token operator">=</span> st<span class="token punctuation">.</span>container<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 提交container后, container被挤到下方, 原本的位置在响应结束后变为response container, 内容为ai的回答</span>
<span class="token keyword">with</span> container<span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># clear_on_submit 提交会清空内容</span>
    <span class="token keyword">with</span> st<span class="token punctuation">.</span>form<span class="token punctuation">(</span>key<span class="token operator">=</span><span class="token string">'my_form'</span><span class="token punctuation">,</span> clear_on_submit<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        user_input <span class="token operator">=</span> st<span class="token punctuation">.</span>text_area<span class="token punctuation">(</span><span class="token string">"Your question goes here:"</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token string">'input'</span><span class="token punctuation">,</span> height<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
        submit_btn <span class="token operator">=</span> st<span class="token punctuation">.</span>form_submit_button<span class="token punctuation">(</span><span class="token string">'Send'</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> submit_btn<span class="token punctuation">:</span>
            answer <span class="token operator">=</span> get_response<span class="token punctuation">(</span>user_input<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># 回显</span>
            <span class="token keyword">with</span> response_container<span class="token punctuation">:</span>
                st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>answer<span class="token punctuation">)</span>
</code></pre>
<h2 id="5-Passing-Dynamic-Data"><a href="#5-Passing-Dynamic-Data" class="headerlink" title="5. Passing Dynamic Data"></a>5. Passing Dynamic Data</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 创建session, 保存conversation</span>
<span class="token keyword">if</span> <span class="token string">'conversation'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'conversation'</span><span class="token punctuation">]</span> <span class="token operator">=</span> None
 
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

<span class="token comment" spellcheck="true"># %% model</span>
<span class="token keyword">def</span> <span class="token function">get_response</span><span class="token punctuation">(</span>userInput<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 如果没有会话, 则创建会话, 防止每次调用都重新创建, 导致清空之前的记录</span>
    <span class="token keyword">if</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'conversation'</span><span class="token punctuation">]</span> <span class="token keyword">is</span> None<span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># llm = OpenAI(temperature=0, model_name='gpt-4')</span>
        llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># conversation</span>
        st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'conversation'</span><span class="token punctuation">]</span> <span class="token operator">=</span> ConversationChain<span class="token punctuation">(</span>
            llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
            verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            <span class="token comment" spellcheck="true"># ConversationBufferMemory，它只是 ChatMessageHistory 的一个包装器，用于提取变量中的消息</span>
            memory<span class="token operator">=</span>ConversationBufferMemory<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># conversation("Good morning AI")</span>
    <span class="token comment" spellcheck="true"># conversation("My name is Steve")</span>
    <span class="token comment" spellcheck="true"># print(conversation.predict(input="I stay in hyderabad, India"))</span>
    <span class="token comment" spellcheck="true"># print(conversation.memory.buffer)</span>
    res <span class="token operator">=</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'conversation'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span>userInput<span class="token punctuation">)</span>

    <span class="token keyword">return</span> res
</code></pre>
<h2 id="6-Implementing-Chatbot-Conversational-View"><a href="#6-Implementing-Chatbot-Conversational-View" class="headerlink" title="6. Implementing Chatbot Conversational View"></a>6. Implementing Chatbot Conversational View</h2><p><img src="84501f16.png"></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 创建session, 保存历史消息</span>
<span class="token keyword">if</span> <span class="token string">'messages'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'messages'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    
<span class="token comment" spellcheck="true"># </span>

<span class="token comment" spellcheck="true"># 提交container后, container被挤到下方, 原本的位置在响应结束后变为response container, 内容为ai的回答</span>
<span class="token keyword">with</span> container<span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># clear_on_submit 提交会清空内容</span>
    <span class="token keyword">with</span> st<span class="token punctuation">.</span>form<span class="token punctuation">(</span>key<span class="token operator">=</span><span class="token string">'my_form'</span><span class="token punctuation">,</span> clear_on_submit<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true">#</span>
        <span class="token keyword">if</span> submit_btn<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true">#</span>
            <span class="token comment" spellcheck="true"># 显示历史消息 到 container</span>
            <span class="token comment" spellcheck="true"># st.write(st.session_state['messages'])</span>

            <span class="token comment" spellcheck="true"># 回显</span>
            <span class="token keyword">with</span> response_container<span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># st.write(answer)</span>
                <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'messages'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    <span class="token comment" spellcheck="true"># from streamlit_chat import message</span>
                    <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">%</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                        message<span class="token punctuation">(</span>st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'messages'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> is_user<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> key<span class="token operator">=</span>str<span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'_user'</span><span class="token punctuation">)</span>
                    <span class="token keyword">else</span><span class="token punctuation">:</span>
                        message<span class="token punctuation">(</span>st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'messages'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> key<span class="token operator">=</span>str<span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'_AI'</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="7-Conversation-Summarization-amp-API-key-feature"><a href="#7-Conversation-Summarization-amp-API-key-feature" class="headerlink" title="7. Conversation Summarization &amp; API key feature"></a>7. Conversation Summarization &amp; API key feature</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %% import</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> ConversationChain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>conversation<span class="token punctuation">.</span>memory <span class="token keyword">import</span> <span class="token punctuation">(</span>
    ConversationBufferMemory<span class="token punctuation">,</span> ConversationSummaryMemory<span class="token punctuation">,</span> ConversationBufferWindowMemory
<span class="token punctuation">)</span>
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAI
<span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st
<span class="token keyword">from</span> streamlit_chat <span class="token keyword">import</span> message

<span class="token comment" spellcheck="true"># 创建session, 保存conversation</span>
<span class="token keyword">if</span> <span class="token string">'conversation'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'conversation'</span><span class="token punctuation">]</span> <span class="token operator">=</span> None
<span class="token comment" spellcheck="true"># 创建session, 保存历史消息</span>
<span class="token keyword">if</span> <span class="token string">'messages'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'messages'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">if</span> <span class="token string">'API_Key'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'API_Key'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span>

<span class="token comment" spellcheck="true"># %%</span>
st<span class="token punctuation">.</span>set_page_config<span class="token punctuation">(</span>page_title<span class="token operator">=</span><span class="token string">"Chat GPT Clone"</span><span class="token punctuation">,</span> page_icon<span class="token operator">=</span><span class="token string">":robot_face:"</span><span class="token punctuation">)</span>
st<span class="token punctuation">.</span>markdown<span class="token punctuation">(</span><span class="token string">"&lt;h1 style='text-align: center;'>How can I assist you? &lt;/h1>"</span><span class="token punctuation">,</span> unsafe_allow_html<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"😎"</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 侧边栏的输入框用来接收key</span>
<span class="token comment" spellcheck="true"># api_key = st.sidebar.text_input("What's your API key?", type="password")</span>
st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'API_Key'</span><span class="token punctuation">]</span> <span class="token operator">=</span> st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">"What's your API key?"</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token string">"password"</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># api_base = st.sidebar.text_input("What's your API base?", type="default")</span>
<span class="token comment" spellcheck="true"># 设计: 当我们点击这个按钮, 将会保存对话摘要</span>
summarise_button <span class="token operator">=</span> st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Summarise the conversation"</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token string">'summarise'</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 点击按钮</span>
<span class="token keyword">if</span> summarise_button<span class="token punctuation">:</span>
    summarise_placeholder <span class="token operator">=</span> st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Nice chatting with you my friend ❤:\n\n"</span> <span class="token operator">+</span>
                                             st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'conversation'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>memory<span class="token punctuation">.</span>buffer<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% env</span>
<span class="token keyword">import</span> os

<span class="token comment" spellcheck="true"># os.environ['OPENAI_API_KEY'] = "sk-dsO3Z1fD9nrDFq1SF7C35437A2F74c1aA769F006A57eA65f"</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_BASE'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"https://oneapi.xty.app/v1"</span>


<span class="token comment" spellcheck="true"># %% model</span>
<span class="token keyword">def</span> <span class="token function">get_response</span><span class="token punctuation">(</span>userInput<span class="token punctuation">,</span> api_key<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 如果没有会话, 则创建会话, 防止每次调用都重新创建, 导致清空之前的记录</span>
    <span class="token keyword">if</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'conversation'</span><span class="token punctuation">]</span> <span class="token keyword">is</span> None<span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># llm = OpenAI(temperature=0, model_name='gpt-4')</span>
        llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> api_key<span class="token operator">=</span>api_key<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># conversation</span>
        st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'conversation'</span><span class="token punctuation">]</span> <span class="token operator">=</span> ConversationChain<span class="token punctuation">(</span>
            llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
            verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            memory<span class="token operator">=</span>ConversationSummaryMemory<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
 
    res <span class="token operator">=</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'conversation'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>predict<span class="token punctuation">(</span>input<span class="token operator">=</span>userInput<span class="token punctuation">)</span>

    <span class="token keyword">return</span> res


<span class="token comment" spellcheck="true"># %%</span>
<span class="token comment" spellcheck="true"># 存放回复</span>
response_container <span class="token operator">=</span> st<span class="token punctuation">.</span>container<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 存放用户的输入</span>
container <span class="token operator">=</span> st<span class="token punctuation">.</span>container<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 提交container后, container被挤到下方, 原本的位置在响应结束后变为response container, 内容为ai的回答</span>
<span class="token keyword">with</span> container<span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># clear_on_submit 提交会清空内容</span>
    <span class="token keyword">with</span> st<span class="token punctuation">.</span>form<span class="token punctuation">(</span>key<span class="token operator">=</span><span class="token string">'my_form'</span><span class="token punctuation">,</span> clear_on_submit<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        user_input <span class="token operator">=</span> st<span class="token punctuation">.</span>text_area<span class="token punctuation">(</span><span class="token string">"Your question goes here:"</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token string">'input'</span><span class="token punctuation">,</span> height<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
        submit_btn <span class="token operator">=</span> st<span class="token punctuation">.</span>form_submit_button<span class="token punctuation">(</span><span class="token string">'Send'</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> submit_btn<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 保存用户输入到历史信息</span>
            st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'messages'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>user_input<span class="token punctuation">)</span>
            answer <span class="token operator">=</span> get_response<span class="token punctuation">(</span>user_input<span class="token punctuation">,</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'API_Key'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 保存AI回复到历史信息</span>
            st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'messages'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>answer<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 显示历史消息 到 container</span>
            <span class="token comment" spellcheck="true"># st.write(st.session_state['messages'])</span>

            <span class="token comment" spellcheck="true"># 回显</span>
            <span class="token keyword">with</span> response_container<span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># st.write(answer)</span>
                <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'messages'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    <span class="token comment" spellcheck="true"># from streamlit_chat import message</span>
                    <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">%</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                        message<span class="token punctuation">(</span>st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'messages'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> is_user<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> key<span class="token operator">=</span>str<span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'_user'</span><span class="token punctuation">)</span>
                    <span class="token keyword">else</span><span class="token punctuation">:</span>
                        message<span class="token punctuation">(</span>st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'messages'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> key<span class="token operator">=</span>str<span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'_AI'</span><span class="token punctuation">)</span>
</code></pre>
<h1 id="13-Langchain-Data-Connection-Module-Concept"><a href="#13-Langchain-Data-Connection-Module-Concept" class="headerlink" title="13. Langchain - Data Connection Module Concept"></a>13. Langchain - Data Connection Module Concept</h1><h2 id="1-Data-Connnection-Module-Introduction"><a href="#1-Data-Connnection-Module-Introduction" class="headerlink" title="1. Data Connnection Module Introduction"></a>1. Data Connnection Module Introduction</h2><p><img src="27fc9938.png"><img src="f7fb7d8e.png"><img src="2bb27fef.png"><img src="14565b43.png"></p>
<h2 id="2-Data-Connection-Module-Python-Implementation-Part-1"><a href="#2-Data-Connection-Module-Python-Implementation-Part-1" class="headerlink" title="2. Data Connection Module - Python Implementation Part 1"></a>2. Data Connection Module - Python Implementation Part 1</h2><p><img src="b8887a3c.png"></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %% import</span>
<span class="token comment" spellcheck="true"># pip install chromadb sentence_transformers</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> TextLoader
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>text_splitter <span class="token keyword">import</span> CharacterTextSplitter
<span class="token keyword">from</span> langchain_openai<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> OpenAIEmbeddings
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Chroma
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> RetrievalQA
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>embeddings<span class="token punctuation">.</span>sentence_transformer <span class="token keyword">import</span> SentenceTransformerEmbeddings

<span class="token comment" spellcheck="true"># %% document loaders</span>
loader <span class="token operator">=</span> TextLoader<span class="token punctuation">(</span><span class="token string">'Sample.txt'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
documents <span class="token operator">=</span> loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 整个文件被视为一个整体</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 1</span>
<span class="token comment" spellcheck="true"># %% Document transformers</span>
<span class="token comment" spellcheck="true"># 文档切分为小块, 防止一次性发送超过llm限制</span>
text_splitter <span class="token operator">=</span> CharacterTextSplitter<span class="token punctuation">(</span>
    <span class="token comment" spellcheck="true"># 每块的大小</span>
    chunk_size<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>
    <span class="token comment" spellcheck="true"># 折叠, 下一块的开头会和上一块的结尾重叠</span>
    chunk_overlap<span class="token operator">=</span><span class="token number">0</span>
<span class="token punctuation">)</span>

texts <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span>split_documents<span class="token punctuation">(</span>documents<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>texts<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 19</span>

<span class="token comment" spellcheck="true"># %% Text embedding models</span>
<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_KEY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"sk-dsO3Z1fD9nrDFq1SF7C35437A2F74c1aA769F006A57eA65f"</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_BASE'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"https://oneapi.xty.app/v1"</span>
embeddings <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># os.environ['HUGGINGFACEHUB_API_TOKEN'] = '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'</span>
<span class="token comment" spellcheck="true"># huggingface SentenceTransformerEmbeddings sentence_transformers</span>
<span class="token comment" spellcheck="true"># embeddings = SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>embeddings<span class="token punctuation">)</span>
</code></pre>
<h2 id="3-Data-Connection-Module-Python-Implementation-Part-2"><a href="#3-Data-Connection-Module-Python-Implementation-Part-2" class="headerlink" title="3. Data Connection Module - Python Implementation Part 2"></a>3. Data Connection Module - Python Implementation Part 2</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %% Vector stores -> Store and search over embedded data</span>
<span class="token comment" spellcheck="true"># Load Embeddings of Text into Chroma</span>
db <span class="token operator">=</span> Chroma<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>texts<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># text -> vector</span>
<span class="token comment" spellcheck="true"># Let's have a look at embeddings -Numeric representation</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>db<span class="token punctuation">.</span>_collection<span class="token punctuation">.</span>get<span class="token punctuation">(</span>include<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'embeddings'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% Retrievers</span>
<span class="token comment" spellcheck="true"># Query your data</span>
retriever <span class="token operator">=</span> db<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span>search_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"k"</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># k:2 -> 返回两个结果</span>
<span class="token comment" spellcheck="true"># vectorstore=&lt;langchain_community.vectorstores.chroma.Chroma object at 0x000001DE2C751E20> search_kwargs={'k': 1}</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>retriever<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% question</span>
<span class="token comment" spellcheck="true"># 1</span>
<span class="token comment" spellcheck="true"># [Document(page_content='Delhi is the capital of India', metadata={'source': 'Sample.txt'})]</span>
<span class="token comment" spellcheck="true"># 如果 k:2 -> 返回两个Document</span>
docs <span class="token operator">=</span> retriever<span class="token punctuation">.</span>get_relevant_documents<span class="token punctuation">(</span><span class="token string">"What is the capital of india?"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>docs<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 2</span>
<span class="token comment" spellcheck="true"># [Document(page_content='The Indian rupee is the official currency in the Republic of India. The rupee is subdivided into 100 paise. The issuance of the currency is controlled by the Reserve Bank of India.', metadata={'source': 'Sample.txt'})]</span>
docs <span class="token operator">=</span> retriever<span class="token punctuation">.</span>get_relevant_documents<span class="token punctuation">(</span><span class="token string">"What is the currency of india?"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>docs<span class="token punctuation">)</span>
</code></pre>
<h1 id="14-✅Intermediate-level"><a href="#14-✅Intermediate-level" class="headerlink" title="14. ✅Intermediate level"></a>14. ✅Intermediate level</h1><h1 id="15-Project-6-Quiz-MCQ-Creator-App"><a href="#15-Project-6-Quiz-MCQ-Creator-App" class="headerlink" title="15. Project #6 - Quiz MCQ Creator App"></a>15. Project #6 - Quiz MCQ Creator App</h1><h2 id="1-Loading-Documents-amp-Creating-Chunks"><a href="#1-Loading-Documents-amp-Creating-Chunks" class="headerlink" title="1. Loading Documents &amp; Creating Chunks"></a>1. Loading Documents &amp; Creating Chunks</h2><p><img src="eb89d2b9.png"><img src="0c2c6e8d.png"></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %%</span>
<span class="token comment" spellcheck="true"># pip install unstructured tiktoken pinecone-client pypdf</span>

<span class="token comment" spellcheck="true"># import dependencies</span>
<span class="token keyword">import</span> openai
<span class="token keyword">import</span> pinecone
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> PyPDFDirectoryLoader
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>text_splitter <span class="token keyword">import</span> RecursiveCharacterTextSplitter
<span class="token keyword">from</span> langchain_openai<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> OpenAIEmbeddings
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Pinecone
<span class="token keyword">from</span> langchain_openai<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>embeddings<span class="token punctuation">.</span>sentence_transformer <span class="token keyword">import</span> SentenceTransformerEmbeddings

<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_KEY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"sk-dsO3Z1fD9nrDFq1SF7C35437A2F74c1aA769F006A57eA65f"</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_BASE'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"https://oneapi.xty.app/v1"</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HUGGINGFACEHUB_API_TOKEN'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'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'</span>


<span class="token comment" spellcheck="true"># %% load documents</span>
<span class="token comment" spellcheck="true"># function to read documents</span>
<span class="token keyword">def</span> <span class="token function">load_docs</span><span class="token punctuation">(</span>directory<span class="token punctuation">)</span><span class="token punctuation">:</span>
    loader <span class="token operator">=</span> PyPDFDirectoryLoader<span class="token punctuation">(</span>directory<span class="token punctuation">)</span>
    docs <span class="token operator">=</span> loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> docs


<span class="token comment" spellcheck="true"># passing the directory to the 'load_docs' function</span>
directory <span class="token operator">=</span> <span class="token string">'Docs/'</span>
documents <span class="token operator">=</span> load_docs<span class="token punctuation">(</span>directory<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 3, 每页pdf视为1</span>


<span class="token comment" spellcheck="true"># %% transform documents</span>
<span class="token comment" spellcheck="true"># split docs into chunks</span>
<span class="token keyword">def</span> <span class="token function">split_docs</span><span class="token punctuation">(</span>documents<span class="token punctuation">,</span> chunk_size<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> chunk_overlap<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    分割文档
    :param documents:
    :param chunk_size: 每块大小
    :param chunk_overlap: 块和块之间重叠的数量
    :return:
    """</span>
    splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">(</span>
        chunk_size<span class="token operator">=</span>chunk_size<span class="token punctuation">,</span>
        chunk_overlap<span class="token operator">=</span>chunk_overlap
    <span class="token punctuation">)</span>
    docs <span class="token operator">=</span> splitter<span class="token punctuation">.</span>split_documents<span class="token punctuation">(</span>documents<span class="token punctuation">)</span>
    <span class="token keyword">return</span> docs


docs <span class="token operator">=</span> split_docs<span class="token punctuation">(</span>documents<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>docs<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 7</span>
</code></pre>
<h2 id="2-Generate-Embeddings-amp-Store-Them"><a href="#2-Generate-Embeddings-amp-Store-Them" class="headerlink" title="2. Generate Embeddings &amp; Store Them"></a>2. Generate Embeddings &amp; Store Them</h2><p><img src="a428436d.png"><img src="40094129.png"><img src="9e5c3432.png"><img src="d6a4f1c3.png"><br>pinecone 破坏性更新api<br><img src="9ddde5c5.png"></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %% vector store</span>
<span class="token triple-quoted-string string">'''
AttributeError: init is no longer a top-level attribute of the pinecone package.

Please create an instance of the Pinecone class instead.
'''</span>
<span class="token comment" spellcheck="true"># pinecone.init(</span>
<span class="token comment" spellcheck="true">#     api_key="752a3862-5a0d-4403-b952-7465c3fa087d",</span>
<span class="token comment" spellcheck="true">#     # environment=</span>
<span class="token comment" spellcheck="true"># )</span>
<span class="token comment" spellcheck="true">#</span>
<span class="token comment" spellcheck="true"># index_name = "mcq-creator"</span>
<span class="token comment" spellcheck="true">#</span>
<span class="token comment" spellcheck="true"># index = Pinecone.from_documents(docs, embeddings, index_name=index_name)</span>

db <span class="token operator">=</span> Chroma<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>docs<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># text -> vector</span>
<span class="token comment" spellcheck="true"># Let's have a look at embeddings -Numeric representation</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>db<span class="token punctuation">.</span>_collection<span class="token punctuation">.</span>get<span class="token punctuation">(</span>include<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'embeddings'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="3-Retrieving-Answer"><a href="#3-Retrieving-Answer" class="headerlink" title="3. Retrieving Answer"></a>3. Retrieving Answer</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %% Retrieve Answers</span>
<span class="token comment" spellcheck="true"># This function will help us in fetching the top relevent documents from our vector store - Pinecone</span>
<span class="token keyword">def</span> <span class="token function">get_similiar_docs</span><span class="token punctuation">(</span>query<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    retriever <span class="token operator">=</span> db<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span>search_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"k"</span><span class="token punctuation">:</span> k<span class="token punctuation">}</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># k:2 -> 返回两个结果 </span>
    docs <span class="token operator">=</span> retriever<span class="token punctuation">.</span>get_relevant_documents<span class="token punctuation">(</span>query<span class="token punctuation">)</span>
    <span class="token keyword">return</span> docs
</code></pre>
<h2 id="4-Creating-Structured-Output"><a href="#4-Creating-Structured-Output" class="headerlink" title="4. Creating Structured Output"></a>4. Creating Structured Output</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %% Creating Structured Output</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>question_answering <span class="token keyword">import</span> load_qa_chain
<span class="token keyword">from</span> langchain <span class="token keyword">import</span> HuggingFaceHub

<span class="token comment" spellcheck="true"># llm=HuggingFaceHub(repo_id="bigscience/bloom", model_kwargs={"temperature":1e-10})</span>
<span class="token comment" spellcheck="true"># llm</span>
llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span>
chain <span class="token operator">=</span> load_qa_chain<span class="token punctuation">(</span>llm<span class="token punctuation">,</span> chain_type<span class="token operator">=</span><span class="token string">"stuff"</span><span class="token punctuation">)</span>


<span class="token comment" spellcheck="true"># This function will help us get the answer to the question that we raise</span>
<span class="token keyword">def</span> <span class="token function">get_answer</span><span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">:</span>
    relevant_docs <span class="token operator">=</span> get_similiar_docs<span class="token punctuation">(</span>query<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>relevant_docs<span class="token punctuation">)</span>
    response <span class="token operator">=</span> chain<span class="token punctuation">.</span>run<span class="token punctuation">(</span>input_documents<span class="token operator">=</span>relevant_docs<span class="token punctuation">,</span> question<span class="token operator">=</span>query<span class="token punctuation">)</span>
    <span class="token keyword">return</span> response


our_query <span class="token operator">=</span> <span class="token string">"How is India's economy?"</span>
answer <span class="token operator">=</span> get_answer<span class="token punctuation">(</span>our_query<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>answer<span class="token punctuation">)</span>
</code></pre>
<h1 id="16-Langchain-Chains-Module-Concept"><a href="#16-Langchain-Chains-Module-Concept" class="headerlink" title="16. Langchain - Chains Module Concept"></a>16. Langchain - Chains Module Concept</h1><h2 id="1-Chains-Overview"><a href="#1-Chains-Overview" class="headerlink" title="1. Chains Overview"></a>1. Chains Overview</h2><p><img src="bd2b3df8.png"><img src="fee8b408.png"></p>
<h2 id="2-Generic-Chains"><a href="#2-Generic-Chains" class="headerlink" title="2. Generic Chains"></a>2. Generic Chains</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %% import</span>
<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_KEY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"sk-dsO3Z1fD9nrDFq1SF7C35437A2F74c1aA769F006A57eA65f"</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_BASE'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"https://oneapi.xty.app/v1"</span>

<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> LLMChain

<span class="token comment" spellcheck="true"># %%</span>
llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span>
prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'place'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    template<span class="token operator">=</span><span class="token string">"Best places to visit in {place}?"</span>
<span class="token punctuation">)</span>

chain <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>prompt<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># run the chain only specifying the input variables</span>
<span class="token triple-quoted-string string">''' 
LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. 
Use invoke instead.
'''</span>
<span class="token comment" spellcheck="true"># print(chain.run("India"))</span>
<span class="token comment" spellcheck="true"># print(chain.invoke({'place': 'India'}))</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'place'</span><span class="token punctuation">:</span> <span class="token string">'India'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"text"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% simple sequential chains</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> SimpleSequentialChain

<span class="token comment" spellcheck="true"># from langchain import HuggingFaceHub</span>

template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""You have to suggest 5 best places to visit in {place}?

YOUR RESPONSE:
"""</span>
prompt_template <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'place'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    template<span class="token operator">=</span>template
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># HF_11m = HuggingFaceHub(repo_id="google/flan-t5-large")</span>
place_chain <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>prompt_template<span class="token punctuation">)</span>

template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""Given a list a places, please estimate the expenses to visit all of them in local currency and also the days needed
{expenses}

YOUR RESPONSE:
"""</span>
prompt_template <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'expenses'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    template<span class="token operator">=</span>template
<span class="token punctuation">)</span>

llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span>

expense_chain <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>prompt_template<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># place_chain的输出是expense_chain的输入</span>
<span class="token comment" spellcheck="true"># verbose=True 可以查看内部情况</span>
final_chain <span class="token operator">=</span> SimpleSequentialChain<span class="token punctuation">(</span>chains<span class="token operator">=</span><span class="token punctuation">[</span>place_chain<span class="token punctuation">,</span> expense_chain<span class="token punctuation">]</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># review=final_chain.run("India")</span>
review <span class="token operator">=</span> final_chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'input'</span><span class="token punctuation">:</span> <span class="token string">'India'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"text"</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="3-Utility-Chains"><a href="#3-Utility-Chains" class="headerlink" title="3. Utility Chains"></a>3. Utility Chains</h2><p><img src="38561e19.png"></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># utility chains overview</span>
<span class="token comment" spellcheck="true"># %% load_summarization_chain</span>
<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_KEY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"sk-dsO3Z1fD9nrDFq1SF7C35437A2F74c1aA769F006A57eA65f"</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_BASE'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"https://oneapi.xty.app/v1"</span>

<span class="token keyword">from</span> langchain_openai<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>summarize <span class="token keyword">import</span> load_summarize_chain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>text_splitter <span class="token keyword">import</span> CharacterTextSplitter
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>docstore<span class="token punctuation">.</span>document <span class="token keyword">import</span> Document

<span class="token comment" spellcheck="true"># %%</span>
llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># reading the document</span>
<span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"Sample.txt"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    data <span class="token operator">=</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># split txt</span>
text_splitter <span class="token operator">=</span> CharacterTextSplitter<span class="token punctuation">(</span><span class="token punctuation">)</span>
texts <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span>split_text<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># create multiple documents</span>
docs <span class="token operator">=</span> <span class="token punctuation">[</span>Document<span class="token punctuation">(</span>page_content<span class="token operator">=</span>t<span class="token punctuation">)</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> texts<span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>docs<span class="token punctuation">)</span>

chain <span class="token operator">=</span> load_summarize_chain<span class="token punctuation">(</span>llm<span class="token punctuation">,</span> chain_type<span class="token operator">=</span><span class="token string">'map_reduce'</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># chain.run(docs)</span>
<span class="token comment" spellcheck="true"># 输出摘要</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>docs<span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'output_text'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># %% http request</span>
<span class="token comment" spellcheck="true">## llm requests chain</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> LLMRequestsChain<span class="token punctuation">,</span> LLMChain

template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
Extract the answer to the question '{query}' or say "not found" if the information is not available.
{requests_result}
"""</span>

PROMPT <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"query"</span><span class="token punctuation">,</span> <span class="token string">"requests_result"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    template<span class="token operator">=</span>template<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span>
chain <span class="token operator">=</span> LLMRequestsChain<span class="token punctuation">(</span>llm_chain<span class="token operator">=</span>LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>PROMPT<span class="token punctuation">)</span><span class="token punctuation">)</span>

question <span class="token operator">=</span> <span class="token string">"What is the capital of india?"</span>
inputs <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">'query'</span><span class="token punctuation">:</span> question<span class="token punctuation">,</span>
    <span class="token string">'url'</span><span class="token punctuation">:</span> <span class="token string">"https://cn.bing.com/search?q="</span> <span class="token operator">+</span> question<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">,</span> <span class="token string">"+"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>chain<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">import</span> inspect

<span class="token keyword">print</span><span class="token punctuation">(</span>inspect<span class="token punctuation">.</span>getsource<span class="token punctuation">(</span>chain<span class="token punctuation">.</span>_call<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h1 id="17-Langchain-Agents-Module-Concept"><a href="#17-Langchain-Agents-Module-Concept" class="headerlink" title="17. Langchain - Agents Module Concept"></a>17. Langchain - Agents Module Concept</h1><h2 id="1-Agents-Overview"><a href="#1-Agents-Overview" class="headerlink" title="1. Agents Overview"></a>1. Agents Overview</h2><p>大型语言模型（LLMs） 非常强大，但它们缺乏“最笨”的计算机程序可以轻松处理的特定能力。逻辑、计算和搜索是计算机通常擅长的领域，但<br>LLMs 却遇到了困难。 计算机可以解决非常复杂的数学问题，但如果我们让 GPT-4 告诉我们 4.1 * 7.9 的答案，它就失败了</p>
<p>要求 GPT-4 执行简单的计算通常会得到一个错误的答案。一个简单的计算器可以毫无问题地执行相同的计算。</p>
<p>根据一个简单的计算器，答案是 19.357，保留三位小数。一个简单的计算器程序可以做到这一点，但一个非常复杂的 AI 引擎却失败了，这是不是很有趣？</p>
<p>GPT-4 无法告诉我们关于 LangChain 的信息，这是因为它与外部世界没有联系。它的唯一知识来自于它的训练数据，而训练数据在 2021<br>年末截止。</p>
<p>在当今的 LLMs 一代中存在重大缺陷，我们必须找到解决这些问题的方法。一种“解决方案套件”以“代理 (Agents) ”形式提供。</p>
<p>这些代理 (Agents) 不仅解决了我们上面看到的问题，还解决了 许多 其他问题。事实上，添加代理 (Agents) 在增强 LLMs 的能力方面几乎没有上限。</p>
<p>什么是代理 (Agents) ?<br>我们可以将代理 (Agents) 视为 LLMs 的工具 (Tools) 。就像人类使用计算器进行数学计算或在 Google 中搜索信息一样，代理 (Agents)<br>允许 LLM 做同样的事情</p>
<p><img src="cbd063a2.png"><img src="d01aec4d.png"><img src="9395d370.png"><img src="1a863eaa.png"><img src="043e8662.png"></p>
<h1 id="18-Project-7-CSV-Data-Analysis-Tool"><a href="#18-Project-7-CSV-Data-Analysis-Tool" class="headerlink" title="18. Project #7 - CSV Data Analysis Tool"></a>18. Project #7 - CSV Data Analysis Tool</h1><h2 id="1-CSV-Data-Analysis-Tool-Demo"><a href="#1-CSV-Data-Analysis-Tool-Demo" class="headerlink" title="1. CSV Data Analysis Tool Demo"></a>1. CSV Data Analysis Tool Demo</h2><p><img src="25602527.png"></p>
<h2 id="2-CSV-Data-Analysis-Tool-Frontend"><a href="#2-CSV-Data-Analysis-Tool-Frontend" class="headerlink" title="2. CSV Data Analysis Tool - Frontend"></a>2. CSV Data Analysis Tool - Frontend</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># %% use env</span>
<span class="token keyword">from</span> dotenv <span class="token keyword">import</span> load_dotenv

load_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st

<span class="token comment" spellcheck="true"># %%</span>
st<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Let's do some analysis on your CSV"</span><span class="token punctuation">)</span>
st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">"Please upload your CSV file here:"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Capture the CSV file 上传文件组件</span>
data <span class="token operator">=</span> st<span class="token punctuation">.</span>file_uploader<span class="token punctuation">(</span><span class="token string">"Upload CSV file"</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token string">"csv"</span><span class="token punctuation">)</span>

query <span class="token operator">=</span> st<span class="token punctuation">.</span>text_area<span class="token punctuation">(</span><span class="token string">"Enter your query"</span><span class="token punctuation">)</span>
button <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Generate Response"</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> button<span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># Get Response </span>
    st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'answer'</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="3-CSV-Data-Analysis-Tool-Backend"><a href="#3-CSV-Data-Analysis-Tool-Backend" class="headerlink" title="3. CSV Data Analysis Tool - Backend"></a>3. CSV Data Analysis Tool - Backend</h2><blockquote>
<p>utils.py</p>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token triple-quoted-string string">'''
ImportError: create_pandas_dataframe_agent has been moved to langchain experimental. See https://github.com/langchain-ai/langchain/discussions/11680for more information.
Please update your import statement from: `langchain.agents.create_pandas_dataframe_agent` to `langchain_experimental.agents.create_pandas_dataframe_agent`.
'''</span>
<span class="token comment" spellcheck="true"># from langchain.agents import create_pandas_dataframe_agent</span>
<span class="token keyword">from</span> langchain_openai<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain_experimental<span class="token punctuation">.</span>agents <span class="token keyword">import</span> create_pandas_dataframe_agent
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd


<span class="token keyword">def</span> <span class="token function">query_agent</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> query<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># parse the csv file and create a pandas dataframe from its contents</span>
    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

    llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># create a pandas dataframe agent</span>
    agent <span class="token operator">=</span> create_pandas_dataframe_agent<span class="token punctuation">(</span>llm<span class="token punctuation">,</span> df<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Python REPL:A Python shell used to evaluating and executing Python commands.</span>
    <span class="token comment" spellcheck="true"># It takes python code as input and outputs the result.The input python code can be generated from another tool in the Langchain</span>
    <span class="token keyword">return</span> agent<span class="token punctuation">.</span>run<span class="token punctuation">(</span>query<span class="token punctuation">)</span>
</code></pre>
<blockquote>
<p>app.py</p>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token keyword">if</span> button<span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># Get Response</span>
    answer <span class="token operator">=</span> query_agent<span class="token punctuation">(</span>data<span class="token punctuation">,</span> query<span class="token punctuation">)</span>
    st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>answer<span class="token punctuation">)</span>
</code></pre>
<p>q: can you please name the columns<br>a: [‘EMPLOYEE_ID’, ‘FIRST_NAME’, ‘LAST_NAME’, ‘EMAIL’, ‘PHONE_NUMBER’, ‘HIRE_DATE’, ‘JOB_ID’, ‘SALARY’, ‘COMMISSION_PCT’, ‘MANAGER_ID’, ‘DEPARTMENT_ID’]<br>q: how many unique managers are there?<br>a: 14<br>q: give the average of salary column<br>a: The average salary is 6182.32.</p>
<p>根据问题执行pd操作<br><img src="60c6147c.png"></p>
<h1 id="19-✅Advanced-level"><a href="#19-✅Advanced-level" class="headerlink" title="19. ✅Advanced level"></a>19. ✅Advanced level</h1><h1 id="20-Project-8-Youtube-Script-Writing-Tool"><a href="#20-Project-8-Youtube-Script-Writing-Tool" class="headerlink" title="20. Project #8 - Youtube Script Writing Tool"></a>20. Project #8 - Youtube Script Writing Tool</h1><h2 id="1-Youtube-Script-Writing-Tool-Demo"><a href="#1-Youtube-Script-Writing-Tool-Demo" class="headerlink" title="1. Youtube Script Writing Tool Demo"></a>1. Youtube Script Writing Tool Demo</h2><blockquote>
<p>生成视频标题和简介</p>
</blockquote>
<p><img src="45e3dcc3.png"><img src="1b8c2e98.png"></p>
<h2 id="2-Youtube-Script-Writing-tool-Frontend"><a href="#2-Youtube-Script-Writing-tool-Frontend" class="headerlink" title="2. Youtube Script Writing tool - Frontend"></a>2. Youtube Script Writing tool - Frontend</h2><blockquote>
<p>requirements.txt</p>
</blockquote>
<pre class=" language-text"><code class="language-text">langchain
streamlit
openai
tiktoken
python-dotenv
pinecone-client
duckduckgo_search
</code></pre>
<blockquote>
<p>app.py</p>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st

<span class="token comment" spellcheck="true"># Applying Styling</span>
st<span class="token punctuation">.</span>markdown<span class="token punctuation">(</span><span class="token triple-quoted-string string">"""
&lt;style>
div.stButton > button:first-child {
    background-color: #0099ff;
    color:#ffffff;
}
div.stButton > button:hover {
    background-color: #00ff00;
    color:#FFFFFF;
    }
&lt;/style>"""</span><span class="token punctuation">,</span> unsafe_allow_html<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Creating Session State Variable</span>
<span class="token keyword">if</span> <span class="token string">'API_Key'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'API_Key'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span>

st<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'❤️ YouTube Script Writing Tool'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Sidebar to capture the OpenAi API key</span>
st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"😎🗝️"</span><span class="token punctuation">)</span>
st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'API_Key'</span><span class="token punctuation">]</span> <span class="token operator">=</span> st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">"What's your API key?"</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token string">"password"</span><span class="token punctuation">)</span>
st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>image<span class="token punctuation">(</span><span class="token string">'./Youtube.jpg'</span><span class="token punctuation">,</span> width<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> use_column_width<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Captures User Inputs</span>
prompt <span class="token operator">=</span> st<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">'Please provide the topic of the video'</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token string">"prompt"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># The box for the text prompt</span>
video_length <span class="token operator">=</span> st<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">'Expected Video Length 🕒 (in minutes)'</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token string">"video_length"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># The box for the text prompt</span>
creativity <span class="token operator">=</span> st<span class="token punctuation">.</span>slider<span class="token punctuation">(</span><span class="token string">'Words limit ✨ - (0 LOW || 1 HIGH)'</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> step<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>

submit <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Generate Script for me"</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> submit<span class="token punctuation">:</span>

    <span class="token keyword">if</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'API_Key'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># Let's generate the script</span>
        st<span class="token punctuation">.</span>success<span class="token punctuation">(</span><span class="token string">'Hope you like this script ❤️'</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Display Title</span>
        st<span class="token punctuation">.</span>subheader<span class="token punctuation">(</span><span class="token string">"Title:🔥"</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Display Video Script</span>
        st<span class="token punctuation">.</span>subheader<span class="token punctuation">(</span><span class="token string">"Your Video Script:📝"</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Display Search Engine Result</span>
        st<span class="token punctuation">.</span>subheader<span class="token punctuation">(</span><span class="token string">"Check Out - DuckDuckGo Search:🔍"</span><span class="token punctuation">)</span>
        <span class="token keyword">with</span> st<span class="token punctuation">.</span>expander<span class="token punctuation">(</span><span class="token string">'Show me 👀'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            st<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">'Search data'</span><span class="token punctuation">)</span>

    <span class="token keyword">else</span><span class="token punctuation">:</span>
        st<span class="token punctuation">.</span>error<span class="token punctuation">(</span><span class="token string">"Ooopssss!!! Please provide API key....."</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="3-Youtube-Script-Writing-tool-Backend"><a href="#3-Youtube-Script-Writing-tool-Backend" class="headerlink" title="3. Youtube Script Writing tool - Backend"></a>3. Youtube Script Writing tool - Backend</h2><blockquote>
<p>utils.py</p>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> langchain_openai<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> LLMChain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>tools <span class="token keyword">import</span> DuckDuckGoSearchRun


<span class="token comment" spellcheck="true"># Function to generate video script</span>
<span class="token keyword">def</span> <span class="token function">generate_script</span><span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> video_length<span class="token punctuation">,</span> creativity<span class="token punctuation">,</span> api_key<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># Template for generating 'Title'</span>
    title_template <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
        input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'subject'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        template<span class="token operator">=</span><span class="token string">'Please come up with a title for a YouTube video on the  {subject}.'</span>
    <span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Template for generating 'Video Script' using search engine</span>
    script_template <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
        input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">,</span> <span class="token string">'DuckDuckGo_Search'</span><span class="token punctuation">,</span> <span class="token string">'duration'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        template<span class="token operator">=</span><span class="token string">'Create a script for a YouTube video based on this title for me. TITLE: {title} of duration: {duration} minutes using this search data {DuckDuckGo_Search} '</span>
    <span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Setting up OpenAI LLM</span>
    llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span>creativity<span class="token punctuation">,</span> openai_api_key<span class="token operator">=</span>api_key<span class="token punctuation">,</span> model_name<span class="token operator">=</span><span class="token string">'gpt-3.5-turbo'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Creating chain for 'Title' &amp; 'Video Script'</span>
    title_chain <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>title_template<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    script_chain <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>script_template<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># https://python.langchain.com/docs/modules/agents/tools/integrations/ddg</span>
    search <span class="token operator">=</span> DuckDuckGoSearchRun<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Executing the chains we created for 'Title'</span>
    title <span class="token operator">=</span> title_chain<span class="token punctuation">.</span>run<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Executing the chains we created for 'Video Script' by taking help of search engine 'DuckDuckGo'</span>
    search_result <span class="token operator">=</span> search<span class="token punctuation">.</span>run<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>
    script <span class="token operator">=</span> script_chain<span class="token punctuation">.</span>run<span class="token punctuation">(</span>title<span class="token operator">=</span>title<span class="token punctuation">,</span> DuckDuckGo_Search<span class="token operator">=</span>search_result<span class="token punctuation">,</span> duration<span class="token operator">=</span>video_length<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Returning the output</span>
    <span class="token keyword">return</span> search_result<span class="token punctuation">,</span> title<span class="token punctuation">,</span> script
</code></pre>
<h2 id="4-Youtube-Script-Writing-tool-Integration"><a href="#4-Youtube-Script-Writing-tool-Integration" class="headerlink" title="4. Youtube Script Writing tool - Integration"></a>4. Youtube Script Writing tool - Integration</h2><blockquote>
<p>utils.py</p>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> langchain_openai<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> LLMChain<span class="token punctuation">,</span> LLMRequestsChain
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>tools <span class="token keyword">import</span> DuckDuckGoSearchRun


<span class="token comment" spellcheck="true"># Function to generate video script</span>
<span class="token keyword">def</span> <span class="token function">generate_script</span><span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> video_length<span class="token punctuation">,</span> creativity<span class="token punctuation">,</span> api_key<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># Template for generating 'Title'</span>
    title_template <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
        input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'subject'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        template<span class="token operator">=</span><span class="token string">'Please come up with a title for a YouTube video on the  {subject}.'</span>
    <span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Template for generating 'Video Script' using search engine</span>
    script_template <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
        input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">,</span> <span class="token string">'DuckDuckGo_Search'</span><span class="token punctuation">,</span> <span class="token string">'duration'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        template<span class="token operator">=</span><span class="token string">'Create a script for a YouTube video based on this title for me. TITLE: {title} of duration: {duration} minutes using this search data {DuckDuckGo_Search} '</span>
    <span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Setting up OpenAI LLM</span>
    <span class="token comment" spellcheck="true"># llm = OpenAI(temperature=creativity, openai_api_key=api_key, model_name='gpt-3.5-turbo')</span>
    llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span>creativity<span class="token punctuation">,</span> openai_api_key<span class="token operator">=</span>api_key<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Creating chain for 'Title' &amp; 'Video Script'</span>
    title_chain <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>title_template<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    script_chain <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>script_template<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># https://python.langchain.com/docs/modules/agents/tools/integrations/ddg</span>
    <span class="token comment" spellcheck="true"># search = DuckDuckGoSearchRun()</span>

    <span class="token comment" spellcheck="true"># Executing the chains we created for 'Title'</span>
    title <span class="token operator">=</span> title_chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'subject'</span><span class="token punctuation">:</span> prompt<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"text"</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Executing the chains we created for 'Video Script' by taking help of search engine 'DuckDuckGo'</span>
    <span class="token comment" spellcheck="true"># search_result = search.run(prompt)</span>

    <span class="token comment" spellcheck="true"># DuckDuckGoSearchRun 有bug, 改用 bing + langchain request</span>
    llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span>
    template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
    Extract the answer to the question '{query}' or say "not found" if the information is not available.
    {requests_result}
    """</span>
    PROMPT <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
        input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"query"</span><span class="token punctuation">,</span> <span class="token string">"requests_result"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        template<span class="token operator">=</span>template<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    chain <span class="token operator">=</span> LLMRequestsChain<span class="token punctuation">(</span>llm_chain<span class="token operator">=</span>LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>PROMPT<span class="token punctuation">)</span><span class="token punctuation">)</span>

    inputs <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token string">'query'</span><span class="token punctuation">:</span> prompt<span class="token punctuation">,</span>
        <span class="token string">'url'</span><span class="token punctuation">:</span> <span class="token string">"https://cn.bing.com/search?q="</span> <span class="token operator">+</span> prompt<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">,</span> <span class="token string">"+"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span>
    search_result <span class="token operator">=</span> chain<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># ------------------------------</span>

    script <span class="token operator">=</span> script_chain<span class="token punctuation">.</span>run<span class="token punctuation">(</span>title<span class="token operator">=</span>title<span class="token punctuation">,</span> DuckDuckGo_Search<span class="token operator">=</span>search_result<span class="token punctuation">,</span> duration<span class="token operator">=</span>video_length<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Returning the output</span>
    <span class="token keyword">return</span> search_result<span class="token punctuation">,</span> title<span class="token punctuation">,</span> script
</code></pre>
<blockquote>
<p>app.py</p>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token keyword">if</span> submit<span class="token punctuation">:</span>

    <span class="token keyword">if</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'API_Key'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        search_result<span class="token punctuation">,</span> title<span class="token punctuation">,</span> script <span class="token operator">=</span> generate_script<span class="token punctuation">(</span>
            prompt<span class="token punctuation">,</span> video_length<span class="token punctuation">,</span> creativity<span class="token punctuation">,</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'API_Key'</span><span class="token punctuation">]</span>
        <span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Let's generate the script</span>
        st<span class="token punctuation">.</span>success<span class="token punctuation">(</span><span class="token string">'Hope you like this script ❤️'</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Display Title</span>
        st<span class="token punctuation">.</span>subheader<span class="token punctuation">(</span><span class="token string">"Title:🔥"</span><span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>title<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Display Video Script</span>
        st<span class="token punctuation">.</span>subheader<span class="token punctuation">(</span><span class="token string">"Your Video Script:📝"</span><span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>script<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Display Search Engine Result</span>
        st<span class="token punctuation">.</span>subheader<span class="token punctuation">(</span><span class="token string">"Check Out - DuckDuckGo Search:🔍"</span><span class="token punctuation">)</span>
        <span class="token keyword">with</span> st<span class="token punctuation">.</span>expander<span class="token punctuation">(</span><span class="token string">'Show me 👀'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            st<span class="token punctuation">.</span>info<span class="token punctuation">(</span>search_result<span class="token punctuation">)</span>

    <span class="token keyword">else</span><span class="token punctuation">:</span>
        st<span class="token punctuation">.</span>error<span class="token punctuation">(</span><span class="token string">"Ooopssss!!! Please provide API key....."</span><span class="token punctuation">)</span>
</code></pre>
<h1 id="21-Project-9-Support-Chat-Bot-For-Your-Website"><a href="#21-Project-9-Support-Chat-Bot-For-Your-Website" class="headerlink" title="21. Project #9 - Support Chat Bot For Your Website"></a>21. Project #9 - Support Chat Bot For Your Website</h1><h2 id="1-Support-Chat-Bot-For-Your-Website-Demo"><a href="#1-Support-Chat-Bot-For-Your-Website-Demo" class="headerlink" title="1. Support Chat Bot For Your Website Demo"></a>1. Support Chat Bot For Your Website Demo</h2><p><img src="f2562ee7.png"><img src="8a7a79bd.png"></p>
<h2 id="3-Implement-Frontend-for-Pushing-Data-to-Pinecone"><a href="#3-Implement-Frontend-for-Pushing-Data-to-Pinecone" class="headerlink" title="3. Implement Frontend for Pushing Data to Pinecone"></a>3. Implement Frontend for Pushing Data to Pinecone</h2><blockquote>
<p>requirements.txt</p>
</blockquote>
<pre class=" language-text"><code class="language-text">langchain
pinecone-client
openai
tiktoken
nest_asyncio
</code></pre>
<p><img src="74fd3913.png"></p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st

<span class="token comment" spellcheck="true"># Creating Session State Variable</span>
<span class="token keyword">if</span> <span class="token string">'HuggingFace_API_Key'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'HuggingFace_API_Key'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span>
<span class="token keyword">if</span> <span class="token string">'Pinecone_API_Key'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'Pinecone_API_Key'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span>

<span class="token comment" spellcheck="true">#</span>
st<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'🤖 AI Assistance For Website'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># ********SIDE BAR Funtionality started*******</span>

<span class="token comment" spellcheck="true"># Sidebar to capture the API keys</span>
st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"😎🗝️"</span><span class="token punctuation">)</span>
st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'HuggingFace_API_Key'</span><span class="token punctuation">]</span> <span class="token operator">=</span> st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">"What's your HuggingFace API key?"</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token string">"password"</span><span class="token punctuation">)</span>
st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'Pinecone_API_Key'</span><span class="token punctuation">]</span> <span class="token operator">=</span> st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">"What's your Pinecone API key?"</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token string">"password"</span><span class="token punctuation">)</span>

load_button <span class="token operator">=</span> st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Load data to Pinecone"</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token string">"load_button"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># If the bove button is clicked, pushing the data to Pinecone...</span>
<span class="token keyword">if</span> load_button<span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># Proceed only if API keys are provided</span>
    <span class="token keyword">if</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'HuggingFace_API_Key'</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">""</span> <span class="token operator">and</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'Pinecone_API_Key'</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">""</span><span class="token punctuation">:</span>

        <span class="token comment" spellcheck="true"># Fetch data from site</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Data pull done..."</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Split data into chunks</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Spliting data done..."</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Creating embeddings instance</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Embeddings instance creation done..."</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Push data to Pinecone</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Pushing data to Pinecone done..."</span><span class="token punctuation">)</span>

        st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>success<span class="token punctuation">(</span><span class="token string">"Data pushed to Pinecone successfully!"</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>error<span class="token punctuation">(</span><span class="token string">"Ooopssss!!! Please provide API keys....."</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># ********SIDE BAR Funtionality ended*******</span>
</code></pre>
<h2 id="4-Implementing-Backend-for-Scraping-the-Data"><a href="#4-Implementing-Backend-for-Scraping-the-Data" class="headerlink" title="4. Implementing Backend for Scraping the Data"></a>4. Implementing Backend for Scraping the Data</h2><p><img src="3fe8690a.png"></p>
<blockquote>
<p>app.py</p>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># If the bove button is clicked, pushing the data to Pinecone...</span>
<span class="token keyword">if</span> load_button<span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># Proceed only if API keys are provided</span>
    <span class="token keyword">if</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'HuggingFace_API_Key'</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">""</span> <span class="token operator">and</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'Pinecone_API_Key'</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">""</span><span class="token punctuation">:</span>

        <span class="token comment" spellcheck="true"># Fetch data from site</span>
        <span class="token comment" spellcheck="true"># 获取网站信息</span>
        site_data <span class="token operator">=</span> get_website_data<span class="token punctuation">(</span><span class="token string">"https://jobs.excelcult.com/wp-sitemap-posts-post-1.xml"</span><span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Data pull done..."</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Split data into chunks</span>
        <span class="token comment" spellcheck="true"># 切分网站信息</span>
        chunks_data <span class="token operator">=</span> split_data<span class="token punctuation">(</span>site_data<span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Spliting data done..."</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Creating embeddings instance</span>
        embeddings <span class="token operator">=</span> create_embeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Embeddings instance creation done..."</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Push data to Pinecone</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Pushing data to Pinecone done..."</span><span class="token punctuation">)</span>

        st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>success<span class="token punctuation">(</span><span class="token string">"Data pushed to Pinecone successfully!"</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>error<span class="token punctuation">(</span><span class="token string">"Ooopssss!!! Please provide API keys....."</span><span class="token punctuation">)</span>
</code></pre>
<blockquote>
<p>utils.py</p>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>text_splitter <span class="token keyword">import</span> RecursiveCharacterTextSplitter
<span class="token comment" spellcheck="true"># from langchain.vectorstores import Pinecone</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>embeddings<span class="token punctuation">.</span>sentence_transformer <span class="token keyword">import</span> SentenceTransformerEmbeddings
<span class="token comment" spellcheck="true"># import pinecone</span>
<span class="token keyword">import</span> asyncio
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>document_loaders<span class="token punctuation">.</span>sitemap <span class="token keyword">import</span> SitemapLoader
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores<span class="token punctuation">.</span>chroma <span class="token keyword">import</span> Chroma
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAIEmbeddings

<span class="token comment" spellcheck="true"># %% Retrieve Answers</span>
<span class="token comment" spellcheck="true"># db - Chroma</span>
db <span class="token operator">=</span> None
persist_directory <span class="token operator">=</span> <span class="token string">'db'</span>


<span class="token comment" spellcheck="true"># This function will help us in fetching the top relevent documents from our vector store - Pinecone</span>
<span class="token keyword">def</span> <span class="token function">from_existing_index</span><span class="token punctuation">(</span>query<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    docs <span class="token operator">=</span> None
    <span class="token keyword">if</span> db <span class="token operator">!=</span> None<span class="token punctuation">:</span>
        retriever <span class="token operator">=</span> db<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span>search_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"k"</span><span class="token punctuation">:</span> k<span class="token punctuation">}</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># k:2 -> 返回两个结果</span>
        docs <span class="token operator">=</span> retriever<span class="token punctuation">.</span>get_relevant_documents<span class="token punctuation">(</span>query<span class="token punctuation">)</span>
    <span class="token keyword">return</span> docs


<span class="token comment" spellcheck="true"># Function to fetch data from website</span>
<span class="token comment" spellcheck="true"># https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/sitemap</span>
<span class="token keyword">def</span> <span class="token function">get_website_data</span><span class="token punctuation">(</span>sitemap_url<span class="token punctuation">)</span><span class="token punctuation">:</span>
    loop <span class="token operator">=</span> asyncio<span class="token punctuation">.</span>new_event_loop<span class="token punctuation">(</span><span class="token punctuation">)</span>
    asyncio<span class="token punctuation">.</span>set_event_loop<span class="token punctuation">(</span>loop<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># SitemapLoader 加载网站的sitemap(包含网站信息)</span>
    loader <span class="token operator">=</span> SitemapLoader<span class="token punctuation">(</span>
        sitemap_url
    <span class="token punctuation">)</span>

    docs <span class="token operator">=</span> loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> docs


<span class="token comment" spellcheck="true"># Function to split data into smaller chunks</span>
<span class="token keyword">def</span> <span class="token function">split_data</span><span class="token punctuation">(</span>docs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    text_splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">(</span>
        chunk_size<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>
        chunk_overlap<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>
        length_function<span class="token operator">=</span>len<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    docs_chunks <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span>split_documents<span class="token punctuation">(</span>docs<span class="token punctuation">)</span>
    <span class="token keyword">return</span> docs_chunks


<span class="token comment" spellcheck="true"># Function to create embeddings instance</span>
<span class="token keyword">def</span> <span class="token function">create_embeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    embeddings <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># embeddings = SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")</span>
    <span class="token keyword">return</span> embeddings


<span class="token comment" spellcheck="true"># Function to push data to Pinecone</span>
<span class="token keyword">def</span> <span class="token function">push_to_pinecone</span><span class="token punctuation">(</span>pinecone_apikey<span class="token punctuation">,</span> pinecone_environment<span class="token punctuation">,</span> pinecone_index_name<span class="token punctuation">,</span> embeddings<span class="token punctuation">,</span> docs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># pinecone.init(</span>
    <span class="token comment" spellcheck="true">#     api_key=pinecone_apikey,</span>
    <span class="token comment" spellcheck="true">#     environment=pinecone_environment</span>
    <span class="token comment" spellcheck="true"># )</span>

    index_name <span class="token operator">=</span> pinecone_index_name

    <span class="token comment" spellcheck="true"># index = Pinecone.from_documents(docs, embeddings, index_name=index_name)</span>
    db <span class="token operator">=</span> Chroma<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>docs<span class="token punctuation">,</span> embeddings<span class="token punctuation">,</span> persist_directory<span class="token operator">=</span>persist_directory<span class="token punctuation">)</span>
    db<span class="token punctuation">.</span>persist<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 持久化</span>
    <span class="token keyword">return</span> db


<span class="token comment" spellcheck="true"># Function to pull index data from Pinecone</span>
<span class="token keyword">def</span> <span class="token function">pull_from_pinecone</span><span class="token punctuation">(</span>pinecone_apikey<span class="token punctuation">,</span> pinecone_environment<span class="token punctuation">,</span> pinecone_index_name<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># pinecone.init(</span>
    <span class="token comment" spellcheck="true">#     api_key=pinecone_apikey,</span>
    <span class="token comment" spellcheck="true">#     environment=pinecone_environment</span>
    <span class="token comment" spellcheck="true"># )</span>

    index_name <span class="token operator">=</span> pinecone_index_name

    <span class="token comment" spellcheck="true"># index = Pinecone.from_existing_index(index_name, embeddings)</span>
    db <span class="token operator">=</span> Chroma<span class="token punctuation">(</span>persist_directory<span class="token operator">=</span>persist_directory<span class="token punctuation">,</span> embedding_function<span class="token operator">=</span>embeddings<span class="token punctuation">)</span>
    <span class="token keyword">return</span> db


<span class="token comment" spellcheck="true"># This function will help us in fetching the top relevent documents from our vector store - Pinecone Index</span>
<span class="token keyword">def</span> <span class="token function">get_similar_docs</span><span class="token punctuation">(</span>index<span class="token punctuation">,</span> query<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># db - index</span>
    similar_docs <span class="token operator">=</span> index<span class="token punctuation">.</span>similarity_search<span class="token punctuation">(</span>query<span class="token punctuation">,</span> k<span class="token operator">=</span>k<span class="token punctuation">)</span>
    <span class="token keyword">return</span> similar_docs
</code></pre>
<h2 id="5-Implementing-Backend-for-Pushing-the-Data-to-Pinecone"><a href="#5-Implementing-Backend-for-Pushing-the-Data-to-Pinecone" class="headerlink" title="5. Implementing Backend for Pushing the Data to Pinecone"></a>5. Implementing Backend for Pushing the Data to Pinecone</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">if</span> load_button<span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># Proceed only if API keys are provided</span>
    <span class="token keyword">if</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'HuggingFace_API_Key'</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">""</span> <span class="token operator">and</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'Pinecone_API_Key'</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">""</span><span class="token punctuation">:</span>

        <span class="token comment" spellcheck="true"># Fetch data from site</span>
        <span class="token comment" spellcheck="true"># 获取网站信息</span>
        site_data <span class="token operator">=</span> get_website_data<span class="token punctuation">(</span><span class="token string">"https://jobs.excelcult.com/wp-sitemap-posts-post-1.xml"</span><span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Data pull done..."</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Split data into chunks</span>
        <span class="token comment" spellcheck="true"># 切分网站信息</span>
        chunks_data <span class="token operator">=</span> split_data<span class="token punctuation">(</span>site_data<span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Spliting data done..."</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Creating embeddings instance</span>
        embeddings <span class="token operator">=</span> create_embeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Embeddings instance creation done..."</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Push data to Pinecone</span>
        push_to_pinecone<span class="token punctuation">(</span>pinecone_index_name<span class="token operator">=</span><span class="token string">'chatbot'</span><span class="token punctuation">,</span> embeddings<span class="token operator">=</span>embeddings<span class="token punctuation">,</span> docs<span class="token operator">=</span>chunks_data<span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Pushing data to Pinecone done..."</span><span class="token punctuation">)</span>

        st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>success<span class="token punctuation">(</span><span class="token string">"Data pushed to Pinecone successfully!"</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>error<span class="token punctuation">(</span><span class="token string">"Ooopssss!!! Please provide API keys....."</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="6-Handling-the-Hardcoded-Values"><a href="#6-Handling-the-Hardcoded-Values" class="headerlink" title="6. Handling the Hardcoded Values"></a>6. Handling the Hardcoded Values</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># constants.py</span>
WEBSITE_URL<span class="token operator">=</span><span class="token string">"https://jobs.excelcult.com/wp-sitemap-posts-post-1.xml"</span>
PINECONE_ENVIRONMENT<span class="token operator">=</span><span class="token string">"us-west1-gcp-free"</span>
PINECONE_INDEX<span class="token operator">=</span><span class="token string">"chatbot"</span>
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># app.py</span>
<span class="token comment" spellcheck="true"># If the bove button is clicked, pushing the data to Pinecone...</span>
<span class="token keyword">if</span> load_button<span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># Proceed only if API keys are provided</span>
    <span class="token keyword">if</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'HuggingFace_API_Key'</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">""</span> <span class="token operator">and</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'Pinecone_API_Key'</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">""</span><span class="token punctuation">:</span>

        <span class="token comment" spellcheck="true"># Fetch data from site</span>
        <span class="token comment" spellcheck="true"># 获取网站信息</span>
        site_data <span class="token operator">=</span> get_website_data<span class="token punctuation">(</span>WEBSITE_URL<span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Data pull done..."</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Split data into chunks</span>
        <span class="token comment" spellcheck="true"># 切分网站信息</span>
        chunks_data <span class="token operator">=</span> split_data<span class="token punctuation">(</span>site_data<span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Spliting data done..."</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Creating embeddings instance</span>
        embeddings <span class="token operator">=</span> create_embeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Embeddings instance creation done..."</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Push data to Pinecone</span>
        push_to_pinecone<span class="token punctuation">(</span>pinecone_index_name<span class="token operator">=</span>PINECONE_INDEX<span class="token punctuation">,</span> embeddings<span class="token operator">=</span>embeddings<span class="token punctuation">,</span> docs<span class="token operator">=</span>chunks_data<span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Pushing data to Pinecone done..."</span><span class="token punctuation">)</span>

        st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>success<span class="token punctuation">(</span><span class="token string">"Data pushed to Pinecone successfully!"</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>error<span class="token punctuation">(</span><span class="token string">"Ooopssss!!! Please provide API keys....."</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="7-Implementing-Information-Retrieval-System"><a href="#7-Implementing-Information-Retrieval-System" class="headerlink" title="7. Implementing Information Retrieval System"></a>7. Implementing Information Retrieval System</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Captures User Inputs</span>
prompt <span class="token operator">=</span> st<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">'How can I help you my friend ❓'</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token string">"prompt"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># The box for the text prompt</span>
document_count <span class="token operator">=</span> st<span class="token punctuation">.</span>slider<span class="token punctuation">(</span><span class="token string">'No.Of links to return 🔗 - (0 LOW || 5 HIGH)'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> step<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

submit <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Search"</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> submit<span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># Proceed only if API keys are provided</span>
    <span class="token keyword">if</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'HuggingFace_API_Key'</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">""</span> <span class="token operator">and</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'Pinecone_API_Key'</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">""</span><span class="token punctuation">:</span>

        <span class="token comment" spellcheck="true"># Creating embeddings instance</span>
        embeddings <span class="token operator">=</span> create_embeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Embeddings instance creation done..."</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Pull index data from Pinecone</span>
        index <span class="token operator">=</span> pull_from_pinecone<span class="token punctuation">(</span><span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"Pinecone index retrieval done..."</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Fetch relavant documents from Pinecone index</span>
        relavant_docs <span class="token operator">=</span> get_similar_docs<span class="token punctuation">(</span>index<span class="token punctuation">,</span> prompt<span class="token punctuation">,</span> document_count<span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>relavant_docs<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Displaying search results</span>
        st<span class="token punctuation">.</span>success<span class="token punctuation">(</span><span class="token string">"Please find the search results :"</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># Displaying search results</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"search results list...."</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> document <span class="token keyword">in</span> relavant_docs<span class="token punctuation">:</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"👉**Result : "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>relavant_docs<span class="token punctuation">.</span>index<span class="token punctuation">(</span>document<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"**"</span><span class="token punctuation">)</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"**Info**: "</span> <span class="token operator">+</span> document<span class="token punctuation">.</span>page_content<span class="token punctuation">)</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"**Link**: "</span> <span class="token operator">+</span> document<span class="token punctuation">.</span>metadata<span class="token punctuation">[</span><span class="token string">'source'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


    <span class="token keyword">else</span><span class="token punctuation">:</span>
        st<span class="token punctuation">.</span>sidebar<span class="token punctuation">.</span>error<span class="token punctuation">(</span><span class="token string">"Ooopssss!!! Please provide API keys....."</span><span class="token punctuation">)</span>
</code></pre>
<h1 id="22-Project-10-Automatic-Ticket-Classification-Tool"><a href="#22-Project-10-Automatic-Ticket-Classification-Tool" class="headerlink" title="22. Project #10 - Automatic Ticket Classification Tool"></a>22. Project #10 - Automatic Ticket Classification Tool</h1><h2 id="1-Automatic-Ticket-Classification-Tool-Demo"><a href="#1-Automatic-Ticket-Classification-Tool-Demo" class="headerlink" title="1. Automatic Ticket Classification Tool - Demo"></a>1. Automatic Ticket Classification Tool - Demo</h2><p><img src="bf8fcd73.png"><img src="22673216.png"><img src="b23465c5.png"><img src="763d7071.png"><img src="1458c057.png"><img src="6fb3c4d6.png"><br><img src="8ef75814.png"><img src="6d07b02c.png"><img src="419d79d7.png"></p>
<h2 id="2-Upload-Documents-To-Pinecone-Frontend-amp-Backend"><a href="#2-Upload-Documents-To-Pinecone-Frontend-amp-Backend" class="headerlink" title="2. Upload Documents To Pinecone - Frontend &amp; Backend"></a>2. Upload Documents To Pinecone - Frontend &amp; Backend</h2><p><img src="4541e94b.png"><img src="b5f5a512.png"><img src="6faa45e7.png"></p>
<blockquote>
<p>requirements.txt</p>
</blockquote>
<pre class=" language-text"><code class="language-text">langchain
streamlit
openai
tiktoken
python-dotenv
pinecone-client
pypdf
joblib
pandas
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Load_Data_Store.py</span>
<span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st
<span class="token keyword">from</span> dotenv <span class="token keyword">import</span> load_dotenv
<span class="token keyword">from</span> admin_utils <span class="token keyword">import</span> <span class="token operator">*</span>


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    load_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span>
    st<span class="token punctuation">.</span>set_page_config<span class="token punctuation">(</span>page_title<span class="token operator">=</span><span class="token string">"Dump PDF to Pinecone - Vector Store"</span><span class="token punctuation">)</span>
    st<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Please upload your files...📁 "</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Upload the pdf file</span>
    pdf <span class="token operator">=</span> st<span class="token punctuation">.</span>file_uploader<span class="token punctuation">(</span><span class="token string">"Only PDF files allowed"</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"pdf"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Extract the whole text from the uploaded pdf file</span>
    <span class="token keyword">if</span> pdf <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
        <span class="token keyword">with</span> st<span class="token punctuation">.</span>spinner<span class="token punctuation">(</span><span class="token string">'Wait for it...'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            text <span class="token operator">=</span> read_pdf_data<span class="token punctuation">(</span>pdf<span class="token punctuation">)</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"👉Reading PDF done"</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Create chunks</span>
            docs_chunks <span class="token operator">=</span> split_data<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># st.write(docs_chunks)</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"👉Splitting data into chunks done"</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Create the embeddings</span>
            embeddings <span class="token operator">=</span> create_embeddings_load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"👉Creating embeddings instance done"</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Build the vector store (Push the PDF data embeddings)</span>
            push_to_pinecone<span class="token punctuation">(</span>embeddings<span class="token punctuation">,</span> docs_chunks<span class="token punctuation">)</span>

        st<span class="token punctuation">.</span>success<span class="token punctuation">(</span><span class="token string">"Successfully pushed the embeddings to Pinecone"</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    main<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># admin_utils.py</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores<span class="token punctuation">.</span>chroma <span class="token keyword">import</span> Chroma
<span class="token keyword">from</span> pypdf <span class="token keyword">import</span> PdfReader
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>text_splitter <span class="token keyword">import</span> RecursiveCharacterTextSplitter
<span class="token keyword">from</span> langchain_openai<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> OpenAIEmbeddings
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>embeddings<span class="token punctuation">.</span>sentence_transformer <span class="token keyword">import</span> SentenceTransformerEmbeddings
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI
<span class="token keyword">import</span> pinecone
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Pinecone
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split

<span class="token comment" spellcheck="true"># db - Chroma</span>
db <span class="token operator">=</span> None
persist_directory <span class="token operator">=</span> <span class="token string">'db'</span>


<span class="token comment" spellcheck="true"># **********Functions to help you load documents to PINECONE***********</span>

<span class="token comment" spellcheck="true"># Read PDF data</span>
<span class="token keyword">def</span> <span class="token function">read_pdf_data</span><span class="token punctuation">(</span>pdf_file<span class="token punctuation">)</span><span class="token punctuation">:</span>
    pdf_page <span class="token operator">=</span> PdfReader<span class="token punctuation">(</span>pdf_file<span class="token punctuation">)</span>
    text <span class="token operator">=</span> <span class="token string">""</span>
    <span class="token keyword">for</span> page <span class="token keyword">in</span> pdf_page<span class="token punctuation">.</span>pages<span class="token punctuation">:</span>
        text <span class="token operator">+=</span> page<span class="token punctuation">.</span>extract_text<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> text


<span class="token comment" spellcheck="true"># Split data into chunks</span>
<span class="token keyword">def</span> <span class="token function">split_data</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    text_splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">(</span>chunk_size<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> chunk_overlap<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span>
    docs <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span>split_text<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
    docs_chunks <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span>create_documents<span class="token punctuation">(</span>docs<span class="token punctuation">)</span>
    <span class="token keyword">return</span> docs_chunks


<span class="token comment" spellcheck="true"># Create embeddings instance</span>
<span class="token keyword">def</span> <span class="token function">create_embeddings_load_data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    embeddings <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># embeddings = SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")</span>
    <span class="token keyword">return</span> embeddings


<span class="token comment" spellcheck="true"># Function to push data to Pinecone</span>
<span class="token comment" spellcheck="true"># def push_to_pinecone(pinecone_apikey, pinecone_environment, pinecone_index_name, embeddings, docs):</span>
<span class="token keyword">def</span> <span class="token function">push_to_pinecone</span><span class="token punctuation">(</span>embeddings<span class="token punctuation">,</span> docs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># pinecone.init(</span>
    <span class="token comment" spellcheck="true">#     api_key=pinecone_apikey,</span>
    <span class="token comment" spellcheck="true">#     environment=pinecone_environment</span>
    <span class="token comment" spellcheck="true"># )</span>

    <span class="token comment" spellcheck="true"># index_name = pinecone_index_name</span>
    <span class="token comment" spellcheck="true"># index = Pinecone.from_documents(docs, embeddings, index_name=index_name)</span>
    <span class="token comment" spellcheck="true"># return index</span>
    db <span class="token operator">=</span> Chroma<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>docs<span class="token punctuation">,</span> embeddings<span class="token punctuation">,</span> persist_directory<span class="token operator">=</span>persist_directory<span class="token punctuation">)</span>
    db<span class="token punctuation">.</span>persist<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 持久化</span>
    <span class="token keyword">return</span> db


<span class="token comment" spellcheck="true"># *********Functions for dealing with Model related tasks...************</span>

<span class="token comment" spellcheck="true"># Read dataset for model creation</span>
<span class="token keyword">def</span> <span class="token function">read_data</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>data<span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">,</span> header<span class="token operator">=</span>None<span class="token punctuation">)</span>
    <span class="token keyword">return</span> df


<span class="token comment" spellcheck="true"># Create embeddings instance</span>
<span class="token keyword">def</span> <span class="token function">get_embeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    embeddings <span class="token operator">=</span> SentenceTransformerEmbeddings<span class="token punctuation">(</span>model_name<span class="token operator">=</span><span class="token string">"all-MiniLM-L6-v2"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> embeddings


<span class="token comment" spellcheck="true"># Generating embeddings for our input dataset</span>
<span class="token keyword">def</span> <span class="token function">create_embeddings</span><span class="token punctuation">(</span>df<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span><span class="token punctuation">:</span>
    df<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> embeddings<span class="token punctuation">.</span>embed_query<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> df


<span class="token comment" spellcheck="true"># Splitting the data into train &amp; test</span>
<span class="token keyword">def</span> <span class="token function">split_train_test__data</span><span class="token punctuation">(</span>df_sample<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># Split into training and testing sets</span>
    sentences_train<span class="token punctuation">,</span> sentences_test<span class="token punctuation">,</span> labels_train<span class="token punctuation">,</span> labels_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>
        list<span class="token punctuation">(</span>df_sample<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> list<span class="token punctuation">(</span>df_sample<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>sentences_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> sentences_train<span class="token punctuation">,</span> sentences_test<span class="token punctuation">,</span> labels_train<span class="token punctuation">,</span> labels_test


<span class="token comment" spellcheck="true"># Get the accuracy score on test data</span>
<span class="token keyword">def</span> <span class="token function">get_score</span><span class="token punctuation">(</span>svm_classifier<span class="token punctuation">,</span> sentences_test<span class="token punctuation">,</span> labels_test<span class="token punctuation">)</span><span class="token punctuation">:</span>
    score <span class="token operator">=</span> svm_classifier<span class="token punctuation">.</span>score<span class="token punctuation">(</span>sentences_test<span class="token punctuation">,</span> labels_test<span class="token punctuation">)</span>
    <span class="token keyword">return</span> score
</code></pre>
<h2 id="3-Chatbot-Interaction-Frontend-amp-Backend"><a href="#3-Chatbot-Interaction-Frontend-amp-Backend" class="headerlink" title="3. Chatbot Interaction- Frontend &amp; Backend"></a>3. Chatbot Interaction- Frontend &amp; Backend</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># app.py</span>
<span class="token keyword">from</span> dotenv <span class="token keyword">import</span> load_dotenv
<span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st
<span class="token keyword">from</span> user_utils <span class="token keyword">import</span> <span class="token operator">*</span>


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    load_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span>

    st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">"Automatic Ticket Classification Tool"</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># Capture user input</span>
    st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"We are here to help you, please ask your question:"</span><span class="token punctuation">)</span>
    user_input <span class="token operator">=</span> st<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">"🔍"</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> user_input<span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># creating embeddings instance</span>
        embeddings <span class="token operator">=</span> create_embeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Function to pull index data from Pinecone</span>
        index <span class="token operator">=</span> pull_from_pinecone<span class="token punctuation">(</span>embeddings<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># This function will help us in fetching the top relevent documents from our vector store - Pinecone Index</span>
        relavant_docs <span class="token operator">=</span> get_similar_docs<span class="token punctuation">(</span>index<span class="token punctuation">,</span> user_input<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># This will return the fine tuned response by LLM</span>
        response <span class="token operator">=</span> get_answer<span class="token punctuation">(</span>relavant_docs<span class="token punctuation">,</span> user_input<span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>response<span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    main<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># user_utils.py</span>
<span class="token keyword">import</span> pinecone
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Pinecone
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>embeddings<span class="token punctuation">.</span>sentence_transformer <span class="token keyword">import</span> SentenceTransformerEmbeddings
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> get_openai_callback
<span class="token keyword">from</span> langchain_openai<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> OpenAIEmbeddings
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>question_answering <span class="token keyword">import</span> load_qa_chain
<span class="token keyword">import</span> joblib
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores<span class="token punctuation">.</span>chroma <span class="token keyword">import</span> Chroma

persist_directory <span class="token operator">=</span> <span class="token string">'db'</span>


<span class="token comment" spellcheck="true"># Function to pull index data from Pinecone</span>
<span class="token comment" spellcheck="true"># def pull_from_pinecone(pinecone_apikey,pinecone_environment,pinecone_index_name,embeddings):</span>
<span class="token keyword">def</span> <span class="token function">pull_from_pinecone</span><span class="token punctuation">(</span>embeddings<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># pinecone.init(</span>
    <span class="token comment" spellcheck="true">#     api_key=pinecone_apikey,</span>
    <span class="token comment" spellcheck="true">#     environment=pinecone_environment</span>
    <span class="token comment" spellcheck="true"># )</span>
    <span class="token comment" spellcheck="true">#</span>
    <span class="token comment" spellcheck="true"># index_name = pinecone_index_name</span>
    <span class="token comment" spellcheck="true">#</span>
    <span class="token comment" spellcheck="true"># index = Pinecone.from_existing_index(index_name, embeddings)</span>
    <span class="token comment" spellcheck="true"># return index</span>
    db <span class="token operator">=</span> Chroma<span class="token punctuation">(</span>persist_directory<span class="token operator">=</span>persist_directory<span class="token punctuation">,</span> embedding_function<span class="token operator">=</span>embeddings<span class="token punctuation">)</span>
    <span class="token keyword">return</span> db


<span class="token keyword">def</span> <span class="token function">create_embeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># embeddings = SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")</span>
    embeddings <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> embeddings


<span class="token comment" spellcheck="true"># This function will help us in fetching the top relevent documents from our vector store - Pinecone Index</span>
<span class="token keyword">def</span> <span class="token function">get_similar_docs</span><span class="token punctuation">(</span>index<span class="token punctuation">,</span> query<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    similar_docs <span class="token operator">=</span> index<span class="token punctuation">.</span>similarity_search<span class="token punctuation">(</span>query<span class="token punctuation">,</span> k<span class="token operator">=</span>k<span class="token punctuation">)</span>
    <span class="token keyword">return</span> similar_docs


<span class="token keyword">def</span> <span class="token function">get_answer</span><span class="token punctuation">(</span>docs<span class="token punctuation">,</span> user_input<span class="token punctuation">)</span><span class="token punctuation">:</span>
    chain <span class="token operator">=</span> load_qa_chain<span class="token punctuation">(</span>OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> chain_type<span class="token operator">=</span><span class="token string">"stuff"</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> get_openai_callback<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cb<span class="token punctuation">:</span>
        response <span class="token operator">=</span> chain<span class="token punctuation">.</span>run<span class="token punctuation">(</span>input_documents<span class="token operator">=</span>docs<span class="token punctuation">,</span> question<span class="token operator">=</span>user_input<span class="token punctuation">)</span>
    <span class="token keyword">return</span> response


<span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>query_result<span class="token punctuation">)</span><span class="token punctuation">:</span>
    Fitmodel <span class="token operator">=</span> joblib<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'modelsvm.pk1'</span><span class="token punctuation">)</span>
    result <span class="token operator">=</span> Fitmodel<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>query_result<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> result<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</code></pre>
<h2 id="4-Organizing-Different-Pages-in-Streamlit"><a href="#4-Organizing-Different-Pages-in-Streamlit" class="headerlink" title="4. Organizing Different Pages in Streamlit"></a>4. Organizing Different Pages in Streamlit</h2><p>pages下的文件会显示在侧边栏<br><img src="b55d3848.png"><img src="ee68f840.png"><img src="57c76fa8.png"></p>
<h2 id="5-Classification-Model-Creation-amp-6-Model-Training-Process"><a href="#5-Classification-Model-Creation-amp-6-Model-Training-Process" class="headerlink" title="5. Classification Model Creation &amp; 6. Model Training Process"></a>5. Classification Model Creation &amp; 6. Model Training Process</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># pages/Create_ML_Model.py</span>
<span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st
<span class="token comment" spellcheck="true"># from pages.admin_utils import *</span>
<span class="token keyword">from</span> pages<span class="token punctuation">.</span>admin_utils <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVC
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> make_pipeline
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler
<span class="token keyword">import</span> joblib

<span class="token keyword">if</span> <span class="token string">'cleaned_data'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'cleaned_data'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span>
<span class="token keyword">if</span> <span class="token string">'sentences_train'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'sentences_train'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span>
<span class="token keyword">if</span> <span class="token string">'sentences_test'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'sentences_test'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span>
<span class="token keyword">if</span> <span class="token string">'labels_train'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'labels_train'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span>
<span class="token keyword">if</span> <span class="token string">'labels_test'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'labels_test'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span>
<span class="token keyword">if</span> <span class="token string">'svm_classifier'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'svm_classifier'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span>

st<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Let's build our Model..."</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Create tabs</span>
tab_titles <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Data Preprocessing'</span><span class="token punctuation">,</span> <span class="token string">'Model Training'</span><span class="token punctuation">,</span> <span class="token string">'Model Evaluation'</span><span class="token punctuation">,</span> <span class="token string">"Save Model"</span><span class="token punctuation">]</span>
tabs <span class="token operator">=</span> st<span class="token punctuation">.</span>tabs<span class="token punctuation">(</span>tab_titles<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Adding content to each tab</span>

<span class="token comment" spellcheck="true"># Data Preprocessing TAB</span>
<span class="token keyword">with</span> tabs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">'Data Preprocessing'</span><span class="token punctuation">)</span>
    st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'Here we preprocess the data...'</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Capture the CSV file</span>
    data <span class="token operator">=</span> st<span class="token punctuation">.</span>file_uploader<span class="token punctuation">(</span><span class="token string">"Upload CSV file"</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token string">"csv"</span><span class="token punctuation">)</span>

    button <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Load data"</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token string">"data"</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> button<span class="token punctuation">:</span>
        <span class="token keyword">with</span> st<span class="token punctuation">.</span>spinner<span class="token punctuation">(</span><span class="token string">'Wait for it...'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            our_data <span class="token operator">=</span> read_data<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
            embeddings <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
            st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'cleaned_data'</span><span class="token punctuation">]</span> <span class="token operator">=</span> create_embeddings<span class="token punctuation">(</span>our_data<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>success<span class="token punctuation">(</span><span class="token string">'Done!'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Model Training TAB</span>
<span class="token keyword">with</span> tabs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">'Model Training'</span><span class="token punctuation">)</span>
    st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'Here we train the model...'</span><span class="token punctuation">)</span>
    button <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Train model"</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token string">"model"</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> button<span class="token punctuation">:</span>
        <span class="token keyword">with</span> st<span class="token punctuation">.</span>spinner<span class="token punctuation">(</span><span class="token string">'Wait for it...'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'sentences_train'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'sentences_test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'labels_train'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> \
            st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'labels_test'</span><span class="token punctuation">]</span> <span class="token operator">=</span> split_train_test__data<span class="token punctuation">(</span>st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'cleaned_data'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Initialize a support vector machine, with class_weight='balanced' because</span>
            <span class="token comment" spellcheck="true"># our training set has roughly an equal amount of positive and negative</span>
            <span class="token comment" spellcheck="true"># sentiment sentences</span>
            st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'svm_classifier'</span><span class="token punctuation">]</span> <span class="token operator">=</span> make_pipeline<span class="token punctuation">(</span>StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> SVC<span class="token punctuation">(</span>class_weight<span class="token operator">=</span><span class="token string">'balanced'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># fit the support vector machine</span>
            st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'svm_classifier'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'sentences_train'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                   st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'labels_train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>success<span class="token punctuation">(</span><span class="token string">'Done!'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Model Evaluation TAB</span>
<span class="token keyword">with</span> tabs<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">'Model Evaluation'</span><span class="token punctuation">)</span>
    st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'Here we evaluate the model...'</span><span class="token punctuation">)</span>
    button <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Evaluate model"</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token string">"Evaluation"</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> button<span class="token punctuation">:</span>
        <span class="token keyword">with</span> st<span class="token punctuation">.</span>spinner<span class="token punctuation">(</span><span class="token string">'Wait for it...'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            accuracy_score <span class="token operator">=</span> get_score<span class="token punctuation">(</span>st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'svm_classifier'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'sentences_test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                       st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'labels_test'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            st<span class="token punctuation">.</span>success<span class="token punctuation">(</span>f<span class="token string">"Validation accuracy is {100 * accuracy_score}%!"</span><span class="token punctuation">)</span>

            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"A sample run:"</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># text="lack of communication regarding policy updates salary, can we please look into it?"</span>
            text <span class="token operator">=</span> <span class="token string">"Rude driver with scary driving"</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"***Our issue*** : "</span> <span class="token operator">+</span> text<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Converting out TEXT to NUMERICAL representaion</span>
            embeddings <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
            query_result <span class="token operator">=</span> embeddings<span class="token punctuation">.</span>embed_query<span class="token punctuation">(</span>text<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Sample prediction using our trained model</span>
            result <span class="token operator">=</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'svm_classifier'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>query_result<span class="token punctuation">]</span><span class="token punctuation">)</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"***Department it belongs to*** : "</span> <span class="token operator">+</span> result<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        st<span class="token punctuation">.</span>success<span class="token punctuation">(</span><span class="token string">'Done!'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Save model TAB</span>
<span class="token keyword">with</span> tabs<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">'Save model'</span><span class="token punctuation">)</span>
    st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'Here we save the model...'</span><span class="token punctuation">)</span>

    button <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Save model"</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token string">"save"</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> button<span class="token punctuation">:</span>
        <span class="token keyword">with</span> st<span class="token punctuation">.</span>spinner<span class="token punctuation">(</span><span class="token string">'Wait for it...'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            joblib<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'svm_classifier'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'modelsvm.pk1'</span><span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>success<span class="token punctuation">(</span><span class="token string">'Done!'</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="7-Ticket-Raising-Feature-Implementation"><a href="#7-Ticket-Raising-Feature-Implementation" class="headerlink" title="7. Ticket Raising Feature Implementation"></a>7. Ticket Raising Feature Implementation</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># user_utils.py</span>

<span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>query_result<span class="token punctuation">)</span><span class="token punctuation">:</span>
    Fitmodel <span class="token operator">=</span> joblib<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'modelsvm.pk1'</span><span class="token punctuation">)</span>
    result <span class="token operator">=</span> Fitmodel<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>query_result<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> result<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># app.py</span>

<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    load_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span>

    st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">"Automatic Ticket Classification Tool"</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># Capture user input</span>
    st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"We are here to help you, please ask your question:"</span><span class="token punctuation">)</span>
    user_input <span class="token operator">=</span> st<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">"🔍"</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> user_input<span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true">###</span>

        <span class="token comment" spellcheck="true"># This will return the fine tuned response by LLM</span>
        response <span class="token operator">=</span> get_answer<span class="token punctuation">(</span>relavant_docs<span class="token punctuation">,</span> user_input<span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>response<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Button to create a ticket with respective department</span>
        button <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Submit ticket?"</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> button<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># Get Response</span>

            embeddings <span class="token operator">=</span> create_embeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
            query_result <span class="token operator">=</span> embeddings<span class="token punctuation">.</span>embed_query<span class="token punctuation">(</span>user_input<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># loading the ML model, so that we can use it to predit the class to which this compliant belongs to...</span>
            department_value <span class="token operator">=</span> predict<span class="token punctuation">(</span>query_result<span class="token punctuation">)</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"your ticket has been sumbitted to : "</span> <span class="token operator">+</span> department_value<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Appending the tickets to below list, so that we can view/use them later on...</span>
            <span class="token keyword">if</span> department_value <span class="token operator">==</span> <span class="token string">"HR"</span><span class="token punctuation">:</span>
                st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'HR_tickets'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>user_input<span class="token punctuation">)</span>
            <span class="token keyword">elif</span> department_value <span class="token operator">==</span> <span class="token string">"IT"</span><span class="token punctuation">:</span>
                st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'IT_tickets'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>user_input<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'Transport_tickets'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>user_input<span class="token punctuation">)</span>
</code></pre>
<h2 id="8-Viewing-Pending-Tickets-Tab"><a href="#8-Viewing-Pending-Tickets-Tab" class="headerlink" title="8. Viewing Pending Tickets Tab"></a>8. Viewing Pending Tickets Tab</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># pages/Pending_tickets.py</span>
<span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st

st<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Departments'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Create tabs</span>
tab_titles <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'HR Support'</span><span class="token punctuation">,</span> <span class="token string">'IT Support'</span><span class="token punctuation">,</span> <span class="token string">'Transportation Support'</span><span class="token punctuation">]</span>
tabs <span class="token operator">=</span> st<span class="token punctuation">.</span>tabs<span class="token punctuation">(</span>tab_titles<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Add content to each tab</span>
<span class="token keyword">with</span> tabs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">'HR Support tickets'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> ticket <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'HR_tickets'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>str<span class="token punctuation">(</span>st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'HR_tickets'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>index<span class="token punctuation">(</span>ticket<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">" : "</span> <span class="token operator">+</span> ticket<span class="token punctuation">)</span>

<span class="token keyword">with</span> tabs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">'IT Support tickets'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> ticket <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'IT_tickets'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>str<span class="token punctuation">(</span>st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'IT_tickets'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>index<span class="token punctuation">(</span>ticket<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">" : "</span> <span class="token operator">+</span> ticket<span class="token punctuation">)</span>

<span class="token keyword">with</span> tabs<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">'Transportation Support tickets'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> ticket <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'Transport_tickets'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>str<span class="token punctuation">(</span>st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'Transport_tickets'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>index<span class="token punctuation">(</span>ticket<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">" : "</span> <span class="token operator">+</span> ticket<span class="token punctuation">)</span>
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># app.py</span>

<span class="token comment" spellcheck="true">#Creating session variables</span>
<span class="token keyword">if</span> <span class="token string">'HR_tickets'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'HR_tickets'</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">if</span> <span class="token string">'IT_tickets'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'IT_tickets'</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">if</span> <span class="token string">'Transport_tickets'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'Transport_tickets'</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
</code></pre>
<h1 id="23-Project-11-HR-Resume-Screening-Assistance"><a href="#23-Project-11-HR-Resume-Screening-Assistance" class="headerlink" title="23. Project #11 - HR - Resume Screening  Assistance"></a>23. Project #11 - HR - Resume Screening  Assistance</h1><h2 id="1-HR-Resume-Screening-Assistance-Demo"><a href="#1-HR-Resume-Screening-Assistance-Demo" class="headerlink" title="1. HR - Resume Screening  Assistance - Demo"></a>1. HR - Resume Screening  Assistance - Demo</h2><p><img src="33e0ea70.png"><img src="4484a4db.png"></p>
<h2 id="3-Resume-Screening-Assistance-Frontend"><a href="#3-Resume-Screening-Assistance-Frontend" class="headerlink" title="3. Resume Screening Assistance Frontend"></a>3. Resume Screening Assistance Frontend</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># app.py</span>
<span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st
<span class="token keyword">from</span> dotenv <span class="token keyword">import</span> load_dotenv
<span class="token keyword">import</span> uuid

<span class="token keyword">if</span> <span class="token string">'unique_id'</span> <span class="token operator">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'unique_id'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span>


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    load_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span>

    st<span class="token punctuation">.</span>set_page_config<span class="token punctuation">(</span>page_title<span class="token operator">=</span><span class="token string">"Resume Screening Assistance"</span><span class="token punctuation">)</span>
    st<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"HR - Resume Screening Assistance...💁 "</span><span class="token punctuation">)</span>
    st<span class="token punctuation">.</span>subheader<span class="token punctuation">(</span><span class="token string">"I can help you in resume screening process"</span><span class="token punctuation">)</span>

    job_description <span class="token operator">=</span> st<span class="token punctuation">.</span>text_area<span class="token punctuation">(</span><span class="token string">"Please paste the 'JOB DESCRIPTION' here..."</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token string">"1"</span><span class="token punctuation">)</span>
    document_count <span class="token operator">=</span> st<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">"No.of 'RESUMES' to return"</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token string">"2"</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># Upload the Resumes (pdf files)</span>
    pdf <span class="token operator">=</span> st<span class="token punctuation">.</span>file_uploader<span class="token punctuation">(</span><span class="token string">"Upload resumes here, only PDF files allowed"</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"pdf"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> accept_multiple_files<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    submit <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Help me with the analysis"</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> submit<span class="token punctuation">:</span>
        <span class="token keyword">with</span> st<span class="token punctuation">.</span>spinner<span class="token punctuation">(</span><span class="token string">'Wait for it...'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"our process"</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># Creating a unique ID, so that we can use to query and get only the user uploaded documents from PINECONE vector store</span>
            st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'unique_id'</span><span class="token punctuation">]</span> <span class="token operator">=</span> uuid<span class="token punctuation">.</span>uuid4<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>hex
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'unique_id'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Create a documents list out of all the user uploaded pdf files</span>
            
            <span class="token comment" spellcheck="true"># Displaying the count of resumes that have been uploaded</span>

            <span class="token comment" spellcheck="true"># Create embeddings instance</span>

            <span class="token comment" spellcheck="true"># Push data to PINECONE</span>

            <span class="token comment" spellcheck="true"># Fecth relavant documents from PINECONE</span>

            <span class="token comment" spellcheck="true"># t.write(relavant_docs)</span>

            <span class="token comment" spellcheck="true"># Introducing a line separator</span>

            <span class="token comment" spellcheck="true"># For each item in relavant docs - we are displaying some info of it on the UI</span>

        st<span class="token punctuation">.</span>success<span class="token punctuation">(</span><span class="token string">"Hope I was able to save your time❤️"</span><span class="token punctuation">)</span>


<span class="token comment" spellcheck="true"># Invoking main function</span>
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    main<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="4-Loading-Documents-and-Adding-Metadata"><a href="#4-Loading-Documents-and-Adding-Metadata" class="headerlink" title="4. Loading Documents and Adding Metadata"></a>4. Loading Documents and Adding Metadata</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># utils.py</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>embeddings<span class="token punctuation">.</span>openai <span class="token keyword">import</span> OpenAIEmbeddings
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Pinecone
<span class="token keyword">from</span> langchain_openai<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>embeddings<span class="token punctuation">.</span>sentence_transformer <span class="token keyword">import</span> SentenceTransformerEmbeddings
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>schema <span class="token keyword">import</span> Document
<span class="token keyword">import</span> pinecone
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores<span class="token punctuation">.</span>chroma <span class="token keyword">import</span> Chroma
<span class="token keyword">from</span> pypdf <span class="token keyword">import</span> PdfReader
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>llms<span class="token punctuation">.</span>openai <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>summarize <span class="token keyword">import</span> load_summarize_chain
<span class="token keyword">from</span> langchain <span class="token keyword">import</span> HuggingFaceHub


<span class="token comment" spellcheck="true"># Extract Information from PDF file</span>
<span class="token keyword">def</span> <span class="token function">get_pdf_text</span><span class="token punctuation">(</span>pdf_doc<span class="token punctuation">)</span><span class="token punctuation">:</span>
    text <span class="token operator">=</span> <span class="token string">""</span>
    pdf_reader <span class="token operator">=</span> PdfReader<span class="token punctuation">(</span>pdf_doc<span class="token punctuation">)</span>
    <span class="token keyword">for</span> page <span class="token keyword">in</span> pdf_reader<span class="token punctuation">.</span>pages<span class="token punctuation">:</span>
        text <span class="token operator">+=</span> page<span class="token punctuation">.</span>extract_text<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> text


<span class="token comment" spellcheck="true"># iterate over files in</span>
<span class="token comment" spellcheck="true"># that user uploaded PDF files, one by one</span>
<span class="token keyword">def</span> <span class="token function">create_docs</span><span class="token punctuation">(</span>user_pdf_list<span class="token punctuation">,</span> unique_id<span class="token punctuation">)</span><span class="token punctuation">:</span>
    docs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> filename <span class="token keyword">in</span> user_pdf_list<span class="token punctuation">:</span>
        chunks <span class="token operator">=</span> get_pdf_text<span class="token punctuation">(</span>filename<span class="token punctuation">)</span> 

        <span class="token comment" spellcheck="true"># Adding items to our list - Adding data &amp; its metadata</span>
        docs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Document<span class="token punctuation">(</span>
            page_content<span class="token operator">=</span>chunks<span class="token punctuation">,</span>
            <span class="token comment" spellcheck="true"># 添加一些额外信息</span>
            metadata<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"name"</span><span class="token punctuation">:</span> filename<span class="token punctuation">.</span>name<span class="token punctuation">,</span>
                      <span class="token comment" spellcheck="true"># 'UploadedFile' object has no attribute 'id'</span>
                      <span class="token string">"id"</span><span class="token punctuation">:</span> filename<span class="token punctuation">.</span>file_id<span class="token punctuation">,</span>
                      <span class="token string">"type="</span><span class="token punctuation">:</span> filename<span class="token punctuation">.</span>type<span class="token punctuation">,</span>
                      <span class="token string">"size"</span><span class="token punctuation">:</span> filename<span class="token punctuation">.</span>size<span class="token punctuation">,</span>
                      <span class="token string">"unique_id"</span><span class="token punctuation">:</span> unique_id<span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> docs


<span class="token comment" spellcheck="true"># Create embeddings instance</span>
<span class="token keyword">def</span> <span class="token function">create_embeddings_load_data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    embeddings <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> embeddings


<span class="token comment" spellcheck="true"># db - Chroma</span>
persist_directory <span class="token operator">=</span> <span class="token string">'db'</span>


<span class="token comment" spellcheck="true"># Function to push data to Pinecone</span>
<span class="token comment" spellcheck="true"># def push_to_pinecone(pinecone_apikey, pinecone_environment, pinecone_index_name, embeddings, docs):</span>
<span class="token keyword">def</span> <span class="token function">push_to_pinecone</span><span class="token punctuation">(</span>docs<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># pinecone.init(</span>
    <span class="token comment" spellcheck="true">#     api_key=pinecone_apikey,</span>
    <span class="token comment" spellcheck="true">#     environment=pinecone_environment</span>
    <span class="token comment" spellcheck="true"># )</span>

    <span class="token comment" spellcheck="true"># index_name = pinecone_index_name</span>
    <span class="token comment" spellcheck="true"># index = Pinecone.from_documents(docs, embeddings, index_name=index_name)</span>
    <span class="token comment" spellcheck="true"># return index</span>
    db <span class="token operator">=</span> Chroma<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>docs<span class="token punctuation">,</span> embeddings<span class="token punctuation">,</span> persist_directory<span class="token operator">=</span>persist_directory<span class="token punctuation">)</span>
    db<span class="token punctuation">.</span>persist<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 持久化</span>
    <span class="token keyword">return</span> db


<span class="token comment" spellcheck="true"># Function to pull index data from Pinecone</span>
<span class="token comment" spellcheck="true"># def pull_from_pinecone(pinecone_apikey,pinecone_environment,pinecone_index_name,embeddings):</span>
<span class="token keyword">def</span> <span class="token function">pull_from_pinecone</span><span class="token punctuation">(</span>embeddings<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># pinecone.init(</span>
    <span class="token comment" spellcheck="true">#     api_key=pinecone_apikey,</span>
    <span class="token comment" spellcheck="true">#     environment=pinecone_environment</span>
    <span class="token comment" spellcheck="true"># )</span>
    <span class="token comment" spellcheck="true">#</span>
    <span class="token comment" spellcheck="true"># index_name = pinecone_index_name</span>
    <span class="token comment" spellcheck="true">#</span>
    <span class="token comment" spellcheck="true"># index = Pinecone.from_existing_index(index_name, embeddings)</span>
    <span class="token comment" spellcheck="true"># return index</span>
    db <span class="token operator">=</span> Chroma<span class="token punctuation">(</span>persist_directory<span class="token operator">=</span>persist_directory<span class="token punctuation">,</span> embedding_function<span class="token operator">=</span>embeddings<span class="token punctuation">)</span>
    <span class="token keyword">return</span> db


<span class="token comment" spellcheck="true"># Function to help us get relavant documents from vector store - based on user input</span>
<span class="token comment" spellcheck="true"># def similar_docs(query,k,pinecone_apikey,pinecone_environment,pinecone_index_name,embeddings,unique_id):</span>
<span class="token keyword">def</span> <span class="token function">similar_docs</span><span class="token punctuation">(</span>query<span class="token punctuation">,</span> k<span class="token punctuation">,</span> embeddings<span class="token punctuation">,</span> unique_id<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># pinecone.init(</span>
    <span class="token comment" spellcheck="true"># api_key=pinecone_apikey,</span>
    <span class="token comment" spellcheck="true"># environment=pinecone_environment</span>
    <span class="token comment" spellcheck="true"># )</span>

    <span class="token comment" spellcheck="true"># index_name = pinecone_index_name</span>

    <span class="token comment" spellcheck="true"># index = pull_from_pinecone(pinecone_apikey,pinecone_environment,index_name,embeddings)</span>
    index <span class="token operator">=</span> pull_from_pinecone<span class="token punctuation">(</span>embeddings<span class="token punctuation">)</span>
    similar_docs <span class="token operator">=</span> index<span class="token punctuation">.</span>similarity_search_with_score<span class="token punctuation">(</span>query<span class="token punctuation">,</span> int<span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">"unique_id"</span><span class="token punctuation">:</span> unique_id<span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># print(similar_docs)</span>
    <span class="token keyword">return</span> similar_docs


<span class="token comment" spellcheck="true"># Helps us get the summary of a document</span>
<span class="token keyword">def</span> <span class="token function">get_summary</span><span class="token punctuation">(</span>current_doc<span class="token punctuation">)</span><span class="token punctuation">:</span>
    llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># llm = HuggingFaceHub(repo_id="bigscience/bloom", model_kwargs={"temperature":1e-10})</span>
    chain <span class="token operator">=</span> load_summarize_chain<span class="token punctuation">(</span>llm<span class="token punctuation">,</span> chain_type<span class="token operator">=</span><span class="token string">"map_reduce"</span><span class="token punctuation">)</span>
    summary <span class="token operator">=</span> chain<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span>current_doc<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> summary
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># app.py</span>

    <span class="token keyword">if</span> submit<span class="token punctuation">:</span>
        <span class="token keyword">with</span> st<span class="token punctuation">.</span>spinner<span class="token punctuation">(</span><span class="token string">'Wait for it...'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"our process"</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># Creating a unique ID, so that we can use to query and get only the user uploaded documents from PINECONE vector store</span>
            st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'unique_id'</span><span class="token punctuation">]</span> <span class="token operator">=</span> uuid<span class="token punctuation">.</span>uuid4<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>hex
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'unique_id'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Create a documents list out of all the user uploaded pdf files</span>
            docs <span class="token operator">=</span> create_docs<span class="token punctuation">(</span>pdf<span class="token punctuation">,</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'unique_id'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>docs<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Displaying the count of resumes that have been uploaded</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>len<span class="token punctuation">(</span>docs<span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Create embeddings instance</span>

            <span class="token comment" spellcheck="true"># Push data to PINECONE</span>

            <span class="token comment" spellcheck="true"># Fecth relavant documents from PINECONE</span>

            <span class="token comment" spellcheck="true"># t.write(relavant_docs)</span>

            <span class="token comment" spellcheck="true"># Introducing a line separator</span>

            <span class="token comment" spellcheck="true"># For each item in relavant docs - we are displaying some info of it on the UI</span>

            st<span class="token punctuation">.</span>success<span class="token punctuation">(</span><span class="token string">"Hope I was able to save your time❤️"</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="5-Push-amp-Pull-Data-From-Pinecone"><a href="#5-Push-amp-Pull-Data-From-Pinecone" class="headerlink" title="5. Push &amp; Pull Data From Pinecone"></a>5. Push &amp; Pull Data From Pinecone</h2><p><img src="7804c413.png"></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># app.py</span>

    <span class="token keyword">if</span> submit<span class="token punctuation">:</span>
        <span class="token keyword">with</span> st<span class="token punctuation">.</span>spinner<span class="token punctuation">(</span><span class="token string">'Wait for it...'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"our process"</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># Creating a unique ID, so that we can use to query and get only the user uploaded documents from PINECONE vector store</span>
            st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'unique_id'</span><span class="token punctuation">]</span> <span class="token operator">=</span> uuid<span class="token punctuation">.</span>uuid4<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>hex

            <span class="token comment" spellcheck="true"># Create a documents list out of all the user uploaded pdf files</span>
            docs <span class="token operator">=</span> create_docs<span class="token punctuation">(</span>pdf<span class="token punctuation">,</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'unique_id'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Displaying the count of resumes that have been uploaded</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>len<span class="token punctuation">(</span>docs<span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Create embeddings instance</span>
            embeddings <span class="token operator">=</span> create_embeddings_load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Push data to PINECONE</span>
            push_to_pinecone<span class="token punctuation">(</span>docs<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Fecth relavant documents from PINECONE</span>
            relavant_docs <span class="token operator">=</span> similar_docs<span class="token punctuation">(</span>
                job_description<span class="token punctuation">,</span> document_count<span class="token punctuation">,</span> embeddings<span class="token punctuation">,</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'unique_id'</span><span class="token punctuation">]</span>
            <span class="token punctuation">)</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>relavant_docs<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Introducing a line separator -----</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">":heavy_minus_sign:"</span> <span class="token operator">*</span> <span class="token number">30</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># For each item in relavant docs - we are displaying some info of it on the UI</span>

            st<span class="token punctuation">.</span>success<span class="token punctuation">(</span><span class="token string">"Hope I was able to save your time❤️"</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="6-Draft"><a href="#6-Draft" class="headerlink" title="6. Draft"></a>6. Draft</h2><h2 id="7-Finetuning-Output"><a href="#7-Finetuning-Output" class="headerlink" title="7. Finetuning Output"></a>7. Finetuning Output</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># app.py</span>

    <span class="token keyword">if</span> submit<span class="token punctuation">:</span>
        <span class="token keyword">with</span> st<span class="token punctuation">.</span>spinner<span class="token punctuation">(</span><span class="token string">'Wait for it...'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># st.write("our process")</span>
            <span class="token comment" spellcheck="true"># Creating a unique ID, so that we can use to query and get only the user uploaded documents from PINECONE vector store</span>
            st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'unique_id'</span><span class="token punctuation">]</span> <span class="token operator">=</span> uuid<span class="token punctuation">.</span>uuid4<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>hex

            <span class="token comment" spellcheck="true"># Create a documents list out of all the user uploaded pdf files</span>
            docs <span class="token operator">=</span> create_docs<span class="token punctuation">(</span>pdf<span class="token punctuation">,</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'unique_id'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Displaying the count of resumes that have been uploaded</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>len<span class="token punctuation">(</span>docs<span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Create embeddings instance</span>
            embeddings <span class="token operator">=</span> create_embeddings_load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Push data to PINECONE</span>
            push_to_pinecone<span class="token punctuation">(</span>docs<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Fecth relavant documents from PINECONE</span>
            relavant_docs <span class="token operator">=</span> similar_docs<span class="token punctuation">(</span>
                job_description<span class="token punctuation">,</span> document_count<span class="token punctuation">,</span> embeddings<span class="token punctuation">,</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">[</span><span class="token string">'unique_id'</span><span class="token punctuation">]</span>
            <span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Introducing a line separator -----</span>
            st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">":heavy_minus_sign:"</span> <span class="token operator">*</span> <span class="token number">30</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># For each item in relavant docs - we are displaying some info of it on the UI</span>
            <span class="token keyword">for</span> item <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>relavant_docs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

                st<span class="token punctuation">.</span>subheader<span class="token punctuation">(</span><span class="token string">"👉 "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>item <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

                <span class="token comment" spellcheck="true"># Displaying Filepath</span>
                st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"**File** : "</span> <span class="token operator">+</span> relavant_docs<span class="token punctuation">[</span>item<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>metadata<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

                <span class="token comment" spellcheck="true"># Introducing Expander feature</span>
                <span class="token keyword">with</span> st<span class="token punctuation">.</span>expander<span class="token punctuation">(</span><span class="token string">'Show me 👀'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    st<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"**Match Score** : "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>relavant_docs<span class="token punctuation">[</span>item<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                    <span class="token comment" spellcheck="true"># st.write("***"+relavant_docs[item][0].page_content)</span>

                    <span class="token comment" spellcheck="true"># Gets the summary of the current item using 'get_summary' function that we have created which uses LLM &amp; Langchain chain</span>
                    summary <span class="token operator">=</span> get_summary<span class="token punctuation">(</span>relavant_docs<span class="token punctuation">[</span>item<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                    st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"**Summary** : "</span> <span class="token operator">+</span> summary<span class="token punctuation">)</span>

        st<span class="token punctuation">.</span>success<span class="token punctuation">(</span><span class="token string">"Hope I was able to save your time❤️"</span><span class="token punctuation">)</span>
</code></pre>
<h1 id="24-LLAMA-2-Introduction"><a href="#24-LLAMA-2-Introduction" class="headerlink" title="24. LLAMA 2 Introduction"></a>24. LLAMA 2 Introduction</h1><h2 id="1-LLAMA-2-Introduction-amp-Download-Guide"><a href="#1-LLAMA-2-Introduction-amp-Download-Guide" class="headerlink" title="1. LLAMA 2 Introduction &amp; Download Guide"></a>1. LLAMA 2 Introduction &amp; Download Guide</h2><p><img src="cd71266a.png"><img src="5f25e717.png"><img src="8edcb261.png"><img src="e4752743.png"><img src="b1bf9f32.png"></p>
<h1 id="25-Project-12-Email-Generator-Using-LLAMA-2-Streamlit-App"><a href="#25-Project-12-Email-Generator-Using-LLAMA-2-Streamlit-App" class="headerlink" title="25. Project #12 - Email Generator Using LLAMA 2  Streamlit App"></a>25. Project #12 - Email Generator Using LLAMA 2  Streamlit App</h1><h2 id="1-Email-Generator-Front-End-amp-Module-Creation"><a href="#1-Email-Generator-Front-End-amp-Module-Creation" class="headerlink" title="1. Email Generator Front End &amp; Module Creation"></a>1. Email Generator Front End &amp; Module Creation</h2><p><img src="42838b22.png"></p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st
<span class="token keyword">from</span> langchain_openai<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> CTransformers
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate 


st<span class="token punctuation">.</span>set_page_config<span class="token punctuation">(</span>
    page_title<span class="token operator">=</span><span class="token string">'Generate Emails'</span><span class="token punctuation">,</span>
    page_icon<span class="token operator">=</span><span class="token string">'📧'</span><span class="token punctuation">,</span>
    layout<span class="token operator">=</span><span class="token string">'centered'</span><span class="token punctuation">,</span>
    initial_sidebar_state<span class="token operator">=</span><span class="token string">'collapsed'</span>
<span class="token punctuation">)</span>
st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">"Generate Emails 📧"</span><span class="token punctuation">)</span>

form_input <span class="token operator">=</span> st<span class="token punctuation">.</span>text_area<span class="token punctuation">(</span><span class="token string">'Enter the email topic'</span><span class="token punctuation">,</span> height<span class="token operator">=</span><span class="token number">275</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Creating columns for the UI -To receive inputs from user</span>
col1<span class="token punctuation">,</span> col2<span class="token punctuation">,</span> col3 <span class="token operator">=</span> st<span class="token punctuation">.</span>columns<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> col1<span class="token punctuation">:</span>
    email_sender <span class="token operator">=</span> st<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">"Sender Name"</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> col2<span class="token punctuation">:</span>
    email_recipient <span class="token operator">=</span> st<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">"Recipient Name"</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> col3<span class="token punctuation">:</span>
    email_style <span class="token operator">=</span> st<span class="token punctuation">.</span>selectbox<span class="token punctuation">(</span>
        <span class="token string">"Writing Style"</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"Formal"</span><span class="token punctuation">,</span> <span class="token string">"Appreciation"</span><span class="token punctuation">,</span> <span class="token string">"Not Satisfied"</span><span class="token punctuation">,</span> <span class="token string">"Neutral"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token number">0</span>
    <span class="token punctuation">)</span>

submit <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Generate"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># When 'Generate' button is clicked,execute the below code</span>
<span class="token keyword">if</span> submit<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'Response'</span><span class="token punctuation">)</span> 
</code></pre>
<h2 id="2-Using-LLAMA-2-as-LLM-amp-Execution"><a href="#2-Using-LLAMA-2-as-LLM-amp-Execution" class="headerlink" title="2. Using LLAMA 2 as LLM &amp; Execution"></a>2. Using LLAMA 2 as LLM &amp; Execution</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st
<span class="token keyword">import</span> box
<span class="token keyword">import</span> yaml
<span class="token keyword">from</span> langchain_experimental<span class="token punctuation">.</span>chat_models <span class="token keyword">import</span> Llama2Chat
<span class="token keyword">from</span> langchain_openai<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> CTransformers
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate


<span class="token comment" spellcheck="true"># function to get the response</span>
<span class="token keyword">def</span> <span class="token function">getLLMResponse</span><span class="token punctuation">(</span>form_input<span class="token punctuation">,</span> email_sender<span class="token punctuation">,</span> email_recipient<span class="token punctuation">,</span> email_style<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># llm = OpenAI(temperature=0.9)</span>

    <span class="token comment" spellcheck="true"># Wrapper for Llama-2-7B-Chat,Running Llama 2 on CPU</span>

    <span class="token comment" spellcheck="true"># Quantization is reducing model precision by converting weights from 16-bit floats to 8-bit integers,</span>
    <span class="token comment" spellcheck="true"># enabling efficient deployment on resource-limited devices,reducing model size,and maintaining performance.</span>

    <span class="token comment" spellcheck="true"># C Transformers offers support for various open-source models,</span>
    <span class="token comment" spellcheck="true"># among them popular ones like Llama,GPT4A11-J,MPT,and Falcon.</span>

    <span class="token comment" spellcheck="true"># C Transformers is the Python library that provides bindings</span>
    <span class="token comment" spellcheck="true"># FileNotFoundError 'D:\\NIVDIA\\development\\bin'</span>
    <span class="token comment" spellcheck="true"># for transformer models implemented in C/C++ using the 6GML library</span>
    llm <span class="token operator">=</span> CTransformers<span class="token punctuation">(</span>
        model<span class="token operator">=</span><span class="token string">'models/llama-2-7b-chat.ggmlv3.q3_K_S.bin'</span><span class="token punctuation">,</span>
        model_type<span class="token operator">=</span><span class="token string">'llama'</span><span class="token punctuation">,</span>
        config<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'max_new_tokens'</span><span class="token punctuation">:</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token string">'temperature'</span><span class="token punctuation">:</span> <span class="token number">0.01</span><span class="token punctuation">}</span>
    <span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Template for building the PROMPT.</span>
    template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
    Write a email with {style} style and includes topic :{email_topic}.\n\nSender: {sender}\nRecipient: {recipient}
    \n\nEmail Text:
    
    """</span>

    <span class="token comment" spellcheck="true"># Creating the final PROMPT</span>
    prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
        input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'style'</span><span class="token punctuation">,</span> <span class="token string">'email_topic'</span><span class="token punctuation">,</span> <span class="token string">'sender'</span><span class="token punctuation">,</span> <span class="token string">'recipient'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        template<span class="token operator">=</span>template
    <span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Generating the response</span>
    response <span class="token operator">=</span> llm<span class="token punctuation">(</span>prompt<span class="token punctuation">.</span>format<span class="token punctuation">(</span>
        email_topic<span class="token operator">=</span>form_input<span class="token punctuation">,</span> sender<span class="token operator">=</span>email_sender<span class="token punctuation">,</span> recipient<span class="token operator">=</span>email_recipient<span class="token punctuation">,</span> style<span class="token operator">=</span>email_style
    <span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> response


st<span class="token punctuation">.</span>set_page_config<span class="token punctuation">(</span>
    page_title<span class="token operator">=</span><span class="token string">'Generate Emails'</span><span class="token punctuation">,</span>
    page_icon<span class="token operator">=</span><span class="token string">'📧'</span><span class="token punctuation">,</span>
    layout<span class="token operator">=</span><span class="token string">'centered'</span><span class="token punctuation">,</span>
    initial_sidebar_state<span class="token operator">=</span><span class="token string">'collapsed'</span>
<span class="token punctuation">)</span>
st<span class="token punctuation">.</span>header<span class="token punctuation">(</span><span class="token string">"Generate Emails 📧"</span><span class="token punctuation">)</span>

form_input <span class="token operator">=</span> st<span class="token punctuation">.</span>text_area<span class="token punctuation">(</span><span class="token string">'Enter the email topic'</span><span class="token punctuation">,</span> height<span class="token operator">=</span><span class="token number">275</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Creating columns for the UI -To receive inputs from user</span>
col1<span class="token punctuation">,</span> col2<span class="token punctuation">,</span> col3 <span class="token operator">=</span> st<span class="token punctuation">.</span>columns<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> col1<span class="token punctuation">:</span>
    email_sender <span class="token operator">=</span> st<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">"Sender Name"</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> col2<span class="token punctuation">:</span>
    email_recipient <span class="token operator">=</span> st<span class="token punctuation">.</span>text_input<span class="token punctuation">(</span><span class="token string">"Recipient Name"</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> col3<span class="token punctuation">:</span>
    email_style <span class="token operator">=</span> st<span class="token punctuation">.</span>selectbox<span class="token punctuation">(</span>
        <span class="token string">"Writing Style"</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"Formal"</span><span class="token punctuation">,</span> <span class="token string">"Appreciation"</span><span class="token punctuation">,</span> <span class="token string">"Not Satisfied"</span><span class="token punctuation">,</span> <span class="token string">"Neutral"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token number">0</span>
    <span class="token punctuation">)</span>

submit <span class="token operator">=</span> st<span class="token punctuation">.</span>button<span class="token punctuation">(</span><span class="token string">"Generate"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># When 'Generate' button is clicked,execute the below code</span>
<span class="token keyword">if</span> submit<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>write<span class="token punctuation">(</span>getLLMResponse<span class="token punctuation">(</span>form_input<span class="token punctuation">,</span> email_sender<span class="token punctuation">,</span> email_recipient<span class="token punctuation">,</span> email_style<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>

            </div>
            <hr/>

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff;
        background-color: #22AB38;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff;
        background-color: #019FE8;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a class="reward-link btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs">
                        <li class="tab wechat-tab waves-effect waves-light"><a class="active" href="#wechat">微信</a></li>
                        <li class="tab alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                    </ul>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('#reward .reward-link').on('click', function () {
            $('#rewardModal').openModal();
        });

        $('#rewardModal .close').on('click', function () {
            $('#rewardModal').closeModal();
        });
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            <div class="reprint">
                <p>
                    <span class="reprint-tip">
                        <i class="fa fa-exclamation-circle"></i>&nbsp;&nbsp;转载请注明:
                    </span>
                    <a href="https://malred.github.io" class="b-link-green">malred-blog</a>
                    <i class="fa fa-angle-right fa-lg fa-fw text-color"></i>
                    <a href="/2024/01/25/ai/langchain/langchain-masterclass-build-12-openai-llm-apps-using-python/4ae2c677/" class="b-link-green">LangChain MasterClass-Build 12 OpenAI LLM Apps using Python</a>
                </p>
            </div>
        </div>
    </div>

    
        <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '676b06df8b7379e50e35',
        clientSecret: '9159b4de0f716ba7bdab9bc02151a90e6961246b',
        repo: 'comment_repo',
        owner: 'malred',
        admin: "malred",
        id: '2024-01-25T18-48-38',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    
        <link rel="stylesheet" href="/libs/gitment/gitment-default.css">
<link rel="stylesheet" href="/css/gitment.css">

<div class="gitment-card card" data-aos="fade-up">
    <div id="gitment-content" class="card-content"></div>
</div>

<script src="/libs/gitment/gitment.js"></script>
<script>
var gitment = new Gitment({
    id: 'Thu Jan 25 2024 18:48:38 GMT+0800',
    owner: 'malred',
    repo: 'comment_repo',
    oauth: {
        client_id: '676b06df8b7379e50e35',
        client_secret: '9159b4de0f716ba7bdab9bc02151a90e6961246b'
    }
});

gitment.render('gitment-content');
</script>
    

    
        <div class="disqus-card card" data-aos="fade-up">
    <div id="disqus_thread" class="card-content">
        <noscript>Please enable JavaScript to view the
            <a target="_blank" rel="noopener" href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
    </div>
</div>

<script type="text/javascript">
    disqus_config = function () {
        this.page.url = 'https://malred.github.io/2024/01/25/ai/langchain/langchain-masterclass-build-12-openai-llm-apps-using-python/4ae2c677/';
        this.page.identifier = '/2024/01/25/ai/langchain/langchain-masterclass-build-12-openai-llm-apps-using-python/4ae2c677/';
        this.page.title = 'LangChain MasterClass-Build 12 OpenAI LLM Apps using Python';
    };
    let disqus_shortname = '';

    (function () { // DON'T EDIT BELOW THIS LINE
        let d = document, s = d.createElement('script');
        // 如：s.src = 'https://blinkfox.disqus.com/embed.js';
        s.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
    

    

    
        <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }

    #vcomments input[type=text],
    #vcomments input[type=email],
    #vcomments input[type=url],
    #vcomments textarea {
        box-sizing: border-box;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #42b983;
        font-weight: 500;
        text-decoration: underline;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div id="vcomments" class="card-content"></div>
</div>

<script src="/libs/valine/av-min.js"></script>
<script src="/libs/valine/Valine.min.js"></script>
<script>
    new Valine({
        el: '#vcomments',
        appId: 'mipjlux8dRwbE7yY1zP3v13z-gzGzoHsz',
        appKey: 'cIy0pwvRAK8cuOCZRjuoHHfy',
        notify: 'false' === 'true',
        verify: 'false' === 'true',
        visitor: 'true' === 'true',
        avatar: 'mm',
        pageSize: '10',
        lang: 'zh-cn',
        placeholder: '留下友善的评论~'
    });
</script>
    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2024/01/25/ai/langchain/langchain-legends-build-legendary-ai-apps-with-javascript/4ae2c677/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/11.jpg" class="responsive-img" alt="Langchain Legends Build legendary AI apps with Javascript">
                        
                        <span class="card-title">Langchain Legends Build legendary AI apps with Javascript</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary">1. Introduction1. Course Foundation Langchain, OpenAI &amp; Pinecone with Javascript
2. Skills You’re Building
3. Course</div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2024-01-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/ai/" class="post-category" target="_blank">
                                    ai
                                </a>
                            
                            <a href="/categories/ai/langChain/" class="post-category" target="_blank">
                                    langChain
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/ai/" target="_blank">
                        <span class="chip bg-color">ai</span>
                    </a>
                    
                    <a href="/tags/langChain/" target="_blank">
                        <span class="chip bg-color">langChain</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2024/01/24/backend/scala/scala-functional-programming-essentials-rock-the-jvm/4ae2c677/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/20.jpg" class="responsive-img" alt="Scala & Functional Programming Essentials  Rock the JVM">
                        
                        <span class="card-title">Scala & Functional Programming Essentials  Rock the JVM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary">1. Getting Started!
//src/playground/javaPlayground.java
package org.malred.playground;

public class javaPlayground {
 </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2024-01-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/scala/" class="post-category" target="_blank">
                                    scala
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/scala/" target="_blank">
                        <span class="chip bg-color">scala</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>


    </div>
    <div class="col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });
    });
</script>
    

</main>


<footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            本站由&copy;<a href="https://blinkfox.github.io/" target="_blank">Blinkfox</a>基于
            <a href="https://hexo.io/" target="_blank">Hexo</a> 的
            <a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">hexo-theme-matery</a>主题搭建.

            
                &nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp;
                <span class="white-color">770.5k</span>
            

            
			
                <br>
                
                <span id="busuanzi_container_site_pv">
                    <i class="fa fa-heart-o"></i>
                    本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span>
                </span>
                
                
                <span id="busuanzi_container_site_uv">
                    <i class="fa fa-users"></i>
                    次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.
                </span>
                
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/malred" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fa fa-github"></i>
    </a>



    <a href="mailto:malguy2022@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fa fa-envelope-open"></i>
    </a>



    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2725953379" class="tooltipped" data-tooltip="QQ联系我: 2725953379" data-position="top" data-delay="50">
        <i class="fa fa-qq"></i>
    </a>


</div>
    </div>
</footer>

<div class="progress-bar"></div>


<!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input" autofocus="">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
</script>
<!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


<script src="/libs/materialize/js/materialize.min.js"></script>
<script src="/libs/masonry/masonry.pkgd.min.js"></script>
<script src="/libs/aos/aos.js"></script>
<script src="/libs/scrollprogress/scrollProgress.min.js"></script>
<script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
<!--动态线条背景-->
<script type="text/javascript" color="122 103 238" opacity='0.7' zIndex="-2" count="200"
    src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js">
    </script>
<script src="/js/matery.js"></script>
<script src="/js/snow.js"></script>

<!-- 引用Aplayer和metingjs -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css">
<script src="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@1.2.0/dist/Meting.min.js"></script>
<div id="my-aplayer" class="aplayer" data-id="7363940489" data-server="netease" data-type="playlist" data-fixed="true"
    // 吸底模式可以固定播放器于页面底部 data-autoplay="true" data-order="list" data-volume="0.55" data-theme="#cc543a"
    data-preload="auto"></div>  
<!-- <script src="https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js"></script> -->
<!-- <script src="https://cdn.bootcss.com/jquery.pjax/2.0.1/jquery.pjax.min.js"></script>
<script>
    // 对所有链接跳转事件绑定pjax容器container
    $(document).pjax('a[target!=_blank]', '.container', { fragment: '.container', timeout: 8000 })
</script> -->


<!-- Global site tag (gtag.js) - Google Analytics -->

<script async src="https://www.googletagmanager.com/gtag/js?id=G-MSEYRC5EW5"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());
    gtag('config', 'G-MSEYRC5EW5');
</script>



    <script src="/libs/others/clicklove.js"></script>


    <script async src="/libs/others/busuanzi.pure.mini.js"></script>


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>